{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fernsrea/flow_matching/blob/main/CIFAR_10_Discreet_Reduced_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jRnYLF-sE8H",
        "outputId": "71fa265f-5a5f-408c-95e1-e2ba2f2d3077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'flow_matching'...\n",
            "remote: Enumerating objects: 246, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 246 (delta 41), reused 21 (delta 21), pack-reused 165 (from 1)\u001b[K\n",
            "Receiving objects: 100% (246/246), 3.21 MiB | 32.83 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n",
            "/content/flow_matching/examples/image/flow_matching/examples/image/flow_matching\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Fernsrea/flow_matching.git\n",
        "%cd flow_matching"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd examples/image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1R7FXmqsYCR",
        "outputId": "46e46008-0de2-4e24-ca02-d86e2e5d97d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flow_matching/examples/image/flow_matching/examples/image/flow_matching/examples/image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzyJxPEasbeA",
        "outputId": "2a48ea32-6646-43cf-ea01-3effd2463c5f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: submitit in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Requirement already satisfied: torchmetrics[image] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.7.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (0.14.3)\n",
            "Requirement already satisfied: torch-fidelity<=0.4.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (1.15.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics[image]->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdiffeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSbE2uw71gz3",
        "outputId": "9db50687-4caa-40e4-a9a9-fcaa4a23b47e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.11/dist-packages (0.2.5)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.4.0->torchdiffeq) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flow_matching"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4SivJfO2boL",
        "outputId": "89b5eed1-c612-4e35-f160-aa114f7075f1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flow_matching in /usr/local/lib/python3.11/dist-packages (1.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from flow_matching) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flow_matching) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.11/dist-packages (from flow_matching) (0.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flow_matching) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq->flow_matching) (1.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flow_matching) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "--dataset=cifar10 \\\n",
        "--batch_size=64 \\\n",
        "--accum_iter=1 \\\n",
        "--eval_frequency=100 \\\n",
        "--epochs=3000 \\\n",
        "--use_ema \\\n",
        "--discrete_flow_matching"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rzsI7hIC7hI",
        "outputId": "5d6580f4-0f89-4d20-dc8d-5988fea6b873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using distributed mode\n",
            "2025-05-01 18:18:21 INFO     job dir: /content/flow_matching/examples/image/flow_matching/examples/image/flow_matching/examples/image\n",
            "2025-05-01 18:18:21 INFO     Namespace(batch_size=64,\n",
            "epochs=3000,\n",
            "accum_iter=1,\n",
            "lr=0.0001,\n",
            "optimizer_betas=[0.9,\n",
            "0.95],\n",
            "decay_lr=False,\n",
            "class_drop_prob=0.2,\n",
            "skewed_timesteps=False,\n",
            "edm_schedule=False,\n",
            "use_ema=True,\n",
            "dataset='cifar10',\n",
            "data_path='./data/image_generation',\n",
            "output_dir='./output_dir',\n",
            "ode_method='midpoint',\n",
            "ode_options={'step_size': 0.01},\n",
            "sym=0.0,\n",
            "temp=1.0,\n",
            "sym_func=False,\n",
            "sampling_dtype='float32',\n",
            "cfg_scale=0.2,\n",
            "fid_samples=50000,\n",
            "device='cuda',\n",
            "seed=0,\n",
            "resume='',\n",
            "start_epoch=0,\n",
            "eval_only=False,\n",
            "eval_frequency=100,\n",
            "compute_fid=False,\n",
            "save_fid_samples=False,\n",
            "num_workers=10,\n",
            "pin_mem=True,\n",
            "world_size=1,\n",
            "local_rank=-1,\n",
            "dist_on_itp=False,\n",
            "dist_url='env://',\n",
            "test_run=False,\n",
            "discrete_flow_matching=True,\n",
            "discrete_fm_steps=1024,\n",
            "distributed=False)\n",
            "2025-05-01 18:18:21 INFO     Saving args to output_dir/args.json\n",
            "2025-05-01 18:18:21 INFO     Initializing Dataset: cifar10\n",
            "100% 170M/170M [00:18<00:00, 9.06MB/s]\n",
            "2025-05-01 18:18:44 INFO     Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data/image_generation\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 RandomHorizontalFlip(p=0.5)\n",
            "                 ToDtype(scale=True)\n",
            "           )\n",
            "2025-05-01 18:18:44 INFO     Intializing DataLoader\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2025-05-01 18:18:44 INFO     <torch.utils.data.distributed.DistributedSampler object at 0x7d6f3618a410>\n",
            "2025-05-01 18:18:44 INFO     Initializing Model\n",
            "2025-05-01 18:18:44 INFO     EMA(\n",
            "  (model): DiscreteUNetModel(vocab_size=257, in_channels=3, model_channels=48, out_channels=3, num_res_blocks=2, attention_resolutions=[2], dropout=0.4, channel_mult=[2, 2, 2], conv_resample=False, dims=2, num_classes=None, use_checkpoint=False, num_heads=-1, num_head_channels=32, num_heads_upsample=-1, use_scale_shift_norm=True, resblock_updown=False, use_new_attention_order=True, with_fourier_features=False)\n",
            "  (shadow_params): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 257x32 (cuda:0)]\n",
            "      (1): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (2): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (3): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (4): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (5): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (6): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (7): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (8): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (9): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (10): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (11): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (12): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (13): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (14): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (15): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (16): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (17): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (18): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (19): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (20): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (21): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (22): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (23): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (24): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (25): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (26): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (27): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (28): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (29): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (30): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (31): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (32): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (33): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (34): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (35): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (36): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (37): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (38): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (39): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (40): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (41): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (42): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (43): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (44): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (45): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (46): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (47): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (48): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (49): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (50): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (51): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (52): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (53): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (54): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (55): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (56): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (57): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (58): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (59): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (60): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (61): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (62): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (63): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (64): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (65): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (66): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (67): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (68): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (69): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (70): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (71): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (72): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (73): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (74): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (75): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (76): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (77): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (78): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (79): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (80): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (81): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (82): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (83): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (84): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (85): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (86): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (87): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (88): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (89): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (90): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (91): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (92): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (93): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (94): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (95): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (96): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (97): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (98): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (99): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (100): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (101): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (102): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (103): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (104): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (105): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (106): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (107): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (108): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (109): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (110): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (111): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (112): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (113): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (114): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (115): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (116): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (117): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (118): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (119): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (120): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (121): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (122): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (123): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (124): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (125): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (126): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (127): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (128): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (129): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (130): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (131): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (132): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (133): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (134): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (135): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (136): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (137): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (138): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (139): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (140): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (141): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (142): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (143): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (144): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (145): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (146): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (147): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (148): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (149): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (150): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (151): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (152): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (153): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (154): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (155): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (156): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (157): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (158): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (159): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (160): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (161): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (162): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (163): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (164): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (165): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (166): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (167): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (168): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (169): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (170): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (171): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (172): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (173): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (174): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (175): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (176): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (177): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (178): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (179): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (180): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (181): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (182): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (183): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (184): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (185): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (186): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (187): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (188): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (189): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (190): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (191): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (192): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (193): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (194): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (195): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (196): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (197): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (198): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (199): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (200): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (201): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (202): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (203): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (204): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (205): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (206): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (207): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (208): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (209): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (210): Parameter containing: [torch.float32 of size 771x96x3x3 (cuda:0)]\n",
            "      (211): Parameter containing: [torch.float32 of size 771 (cuda:0)]\n",
            "  )\n",
            ")\n",
            "2025-05-01 18:18:44 INFO     Learning rate: 1.00e-04\n",
            "2025-05-01 18:18:44 INFO     Accumulate grad iterations: 1\n",
            "2025-05-01 18:18:44 INFO     Effective batch size: 64\n",
            "2025-05-01 18:18:44 INFO     Optimizer: AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: [0.9, 0.95]\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "2025-05-01 18:18:44 INFO     Learning-Rate Schedule: <torch.optim.lr_scheduler.ConstantLR object at 0x7d6f34d88250>\n",
            "/content/flow_matching/examples/image/flow_matching/examples/image/flow_matching/examples/image/training/grad_scaler.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self._scaler = torch.cuda.amp.GradScaler()\n",
            "2025-05-01 18:18:44 INFO     Start from 0 to 3000 epochs\n",
            "2025-05-01 18:18:50 INFO     Epoch 0 [0/781]: loss = 5.548991680145264, lr = 0.0001\n",
            "2025-05-01 18:19:03 INFO     Epoch 0 [50/781]: loss = 5.385597229003906, lr = 0.0001\n",
            "2025-05-01 18:19:16 INFO     Epoch 0 [100/781]: loss = 5.32176399230957, lr = 0.0001\n",
            "2025-05-01 18:19:28 INFO     Epoch 0 [150/781]: loss = 5.2469801902771, lr = 0.0001\n",
            "2025-05-01 18:19:42 INFO     Epoch 0 [200/781]: loss = 5.13742208480835, lr = 0.0001\n",
            "2025-05-01 18:19:55 INFO     Epoch 0 [250/781]: loss = 5.089448928833008, lr = 0.0001\n",
            "2025-05-01 18:20:08 INFO     Epoch 0 [300/781]: loss = 4.942837238311768, lr = 0.0001\n",
            "2025-05-01 18:20:22 INFO     Epoch 0 [350/781]: loss = 4.879464626312256, lr = 0.0001\n",
            "2025-05-01 18:20:36 INFO     Epoch 0 [400/781]: loss = 4.969214916229248, lr = 0.0001\n",
            "2025-05-01 18:20:49 INFO     Epoch 0 [450/781]: loss = 4.725052356719971, lr = 0.0001\n",
            "2025-05-01 18:21:03 INFO     Epoch 0 [500/781]: loss = 4.8684401512146, lr = 0.0001\n",
            "2025-05-01 18:21:17 INFO     Epoch 0 [550/781]: loss = 4.7813944816589355, lr = 0.0001\n",
            "2025-05-01 18:21:30 INFO     Epoch 0 [600/781]: loss = 4.659125804901123, lr = 0.0001\n",
            "2025-05-01 18:21:44 INFO     Epoch 0 [650/781]: loss = 4.557187557220459, lr = 0.0001\n",
            "2025-05-01 18:21:57 INFO     Epoch 0 [700/781]: loss = 4.562864780426025, lr = 0.0001\n",
            "2025-05-01 18:22:11 INFO     Epoch 0 [750/781]: loss = 4.497585773468018, lr = 0.0001\n",
            "2025-05-01 18:22:20 INFO     Epoch 1 [0/781]: loss = 4.543722629547119, lr = 0.0001\n",
            "2025-05-01 18:22:34 INFO     Epoch 1 [50/781]: loss = 4.3499650955200195, lr = 0.0001\n",
            "2025-05-01 18:22:48 INFO     Epoch 1 [100/781]: loss = 4.384108543395996, lr = 0.0001\n",
            "2025-05-01 18:23:01 INFO     Epoch 1 [150/781]: loss = 4.577381134033203, lr = 0.0001\n",
            "2025-05-01 18:23:15 INFO     Epoch 1 [200/781]: loss = 4.388683795928955, lr = 0.0001\n",
            "2025-05-01 18:23:29 INFO     Epoch 1 [250/781]: loss = 4.3674187660217285, lr = 0.0001\n",
            "2025-05-01 18:23:42 INFO     Epoch 1 [300/781]: loss = 4.199315547943115, lr = 0.0001\n",
            "2025-05-01 18:23:56 INFO     Epoch 1 [350/781]: loss = 4.216507434844971, lr = 0.0001\n",
            "2025-05-01 18:24:09 INFO     Epoch 1 [400/781]: loss = 4.1783061027526855, lr = 0.0001\n",
            "2025-05-01 18:24:23 INFO     Epoch 1 [450/781]: loss = 4.148352146148682, lr = 0.0001\n",
            "2025-05-01 18:24:37 INFO     Epoch 1 [500/781]: loss = 3.877666711807251, lr = 0.0001\n",
            "2025-05-01 18:24:50 INFO     Epoch 1 [550/781]: loss = 4.213423252105713, lr = 0.0001\n",
            "2025-05-01 18:25:04 INFO     Epoch 1 [600/781]: loss = 4.035062313079834, lr = 0.0001\n",
            "2025-05-01 18:25:18 INFO     Epoch 1 [650/781]: loss = 3.981663942337036, lr = 0.0001\n",
            "2025-05-01 18:25:31 INFO     Epoch 1 [700/781]: loss = 4.143365383148193, lr = 0.0001\n",
            "2025-05-01 18:25:45 INFO     Epoch 1 [750/781]: loss = 4.034078598022461, lr = 0.0001\n",
            "2025-05-01 18:25:54 INFO     Epoch 2 [0/781]: loss = 3.938478708267212, lr = 0.0001\n",
            "2025-05-01 18:26:08 INFO     Epoch 2 [50/781]: loss = 3.961930513381958, lr = 0.0001\n",
            "2025-05-01 18:26:22 INFO     Epoch 2 [100/781]: loss = 4.132368564605713, lr = 0.0001\n",
            "2025-05-01 18:26:35 INFO     Epoch 2 [150/781]: loss = 3.964323043823242, lr = 0.0001\n",
            "2025-05-01 18:26:49 INFO     Epoch 2 [200/781]: loss = 3.9565181732177734, lr = 0.0001\n",
            "2025-05-01 18:27:03 INFO     Epoch 2 [250/781]: loss = 4.0294365882873535, lr = 0.0001\n",
            "2025-05-01 18:27:16 INFO     Epoch 2 [300/781]: loss = 3.677565574645996, lr = 0.0001\n",
            "2025-05-01 18:27:30 INFO     Epoch 2 [350/781]: loss = 3.9863779544830322, lr = 0.0001\n",
            "2025-05-01 18:27:44 INFO     Epoch 2 [400/781]: loss = 3.8316171169281006, lr = 0.0001\n",
            "2025-05-01 18:27:57 INFO     Epoch 2 [450/781]: loss = 3.913356065750122, lr = 0.0001\n",
            "2025-05-01 18:28:11 INFO     Epoch 2 [500/781]: loss = 3.7620179653167725, lr = 0.0001\n",
            "2025-05-01 18:28:25 INFO     Epoch 2 [550/781]: loss = 3.810817003250122, lr = 0.0001\n",
            "2025-05-01 18:28:38 INFO     Epoch 2 [600/781]: loss = 3.783104658126831, lr = 0.0001\n",
            "2025-05-01 18:28:52 INFO     Epoch 2 [650/781]: loss = 3.4462063312530518, lr = 0.0001\n",
            "2025-05-01 18:29:05 INFO     Epoch 2 [700/781]: loss = 4.176662445068359, lr = 0.0001\n",
            "2025-05-01 18:29:19 INFO     Epoch 2 [750/781]: loss = 3.752434015274048, lr = 0.0001\n",
            "2025-05-01 18:29:28 INFO     Epoch 3 [0/781]: loss = 3.3406074047088623, lr = 0.0001\n",
            "2025-05-01 18:29:42 INFO     Epoch 3 [50/781]: loss = 3.6199512481689453, lr = 0.0001\n",
            "2025-05-01 18:29:56 INFO     Epoch 3 [100/781]: loss = 3.6457059383392334, lr = 0.0001\n",
            "2025-05-01 18:30:09 INFO     Epoch 3 [150/781]: loss = 3.7247235774993896, lr = 0.0001\n",
            "2025-05-01 18:30:23 INFO     Epoch 3 [200/781]: loss = 3.4688892364501953, lr = 0.0001\n",
            "2025-05-01 18:30:37 INFO     Epoch 3 [250/781]: loss = 4.069803237915039, lr = 0.0001\n",
            "2025-05-01 18:30:50 INFO     Epoch 3 [300/781]: loss = 3.5057179927825928, lr = 0.0001\n",
            "2025-05-01 18:31:04 INFO     Epoch 3 [350/781]: loss = 3.7499332427978516, lr = 0.0001\n",
            "2025-05-01 18:31:18 INFO     Epoch 3 [400/781]: loss = 3.7521908283233643, lr = 0.0001\n",
            "2025-05-01 18:31:31 INFO     Epoch 3 [450/781]: loss = 3.5829927921295166, lr = 0.0001\n",
            "2025-05-01 18:31:45 INFO     Epoch 3 [500/781]: loss = 3.7386770248413086, lr = 0.0001\n",
            "2025-05-01 18:31:59 INFO     Epoch 3 [550/781]: loss = 3.814819574356079, lr = 0.0001\n",
            "2025-05-01 18:32:12 INFO     Epoch 3 [600/781]: loss = 3.6660470962524414, lr = 0.0001\n",
            "2025-05-01 18:32:26 INFO     Epoch 3 [650/781]: loss = 3.577444314956665, lr = 0.0001\n",
            "2025-05-01 18:32:40 INFO     Epoch 3 [700/781]: loss = 3.7031707763671875, lr = 0.0001\n",
            "2025-05-01 18:32:53 INFO     Epoch 3 [750/781]: loss = 3.766087293624878, lr = 0.0001\n",
            "2025-05-01 18:33:03 INFO     Epoch 4 [0/781]: loss = 3.809899091720581, lr = 0.0001\n",
            "2025-05-01 18:33:16 INFO     Epoch 4 [50/781]: loss = 3.6121666431427, lr = 0.0001\n",
            "2025-05-01 18:33:30 INFO     Epoch 4 [100/781]: loss = 3.4501256942749023, lr = 0.0001\n",
            "2025-05-01 18:33:43 INFO     Epoch 4 [150/781]: loss = 3.4902026653289795, lr = 0.0001\n",
            "2025-05-01 18:33:57 INFO     Epoch 4 [200/781]: loss = 3.293800115585327, lr = 0.0001\n",
            "2025-05-01 18:34:11 INFO     Epoch 4 [250/781]: loss = 3.4293301105499268, lr = 0.0001\n",
            "2025-05-01 18:34:24 INFO     Epoch 4 [300/781]: loss = 3.493873357772827, lr = 0.0001\n",
            "2025-05-01 18:34:38 INFO     Epoch 4 [350/781]: loss = 3.601710081100464, lr = 0.0001\n",
            "2025-05-01 18:34:52 INFO     Epoch 4 [400/781]: loss = 3.4318950176239014, lr = 0.0001\n",
            "2025-05-01 18:35:05 INFO     Epoch 4 [450/781]: loss = 3.5322306156158447, lr = 0.0001\n",
            "2025-05-01 18:35:19 INFO     Epoch 4 [500/781]: loss = 3.5774595737457275, lr = 0.0001\n",
            "2025-05-01 18:35:32 INFO     Epoch 4 [550/781]: loss = 3.5958175659179688, lr = 0.0001\n",
            "2025-05-01 18:35:46 INFO     Epoch 4 [600/781]: loss = 3.358443021774292, lr = 0.0001\n",
            "2025-05-01 18:36:00 INFO     Epoch 4 [650/781]: loss = 3.337961435317993, lr = 0.0001\n",
            "2025-05-01 18:36:14 INFO     Epoch 4 [700/781]: loss = 3.5129165649414062, lr = 0.0001\n",
            "2025-05-01 18:36:27 INFO     Epoch 4 [750/781]: loss = 3.628432273864746, lr = 0.0001\n",
            "2025-05-01 18:36:37 INFO     Epoch 5 [0/781]: loss = 3.285876512527466, lr = 0.0001\n",
            "2025-05-01 18:36:50 INFO     Epoch 5 [50/781]: loss = 3.429468870162964, lr = 0.0001\n",
            "2025-05-01 18:37:04 INFO     Epoch 5 [100/781]: loss = 3.8120996952056885, lr = 0.0001\n",
            "2025-05-01 18:37:18 INFO     Epoch 5 [150/781]: loss = 3.8703317642211914, lr = 0.0001\n",
            "2025-05-01 18:37:31 INFO     Epoch 5 [200/781]: loss = 3.428056478500366, lr = 0.0001\n",
            "2025-05-01 18:37:45 INFO     Epoch 5 [250/781]: loss = 3.7158219814300537, lr = 0.0001\n",
            "2025-05-01 18:37:59 INFO     Epoch 5 [300/781]: loss = 3.5173919200897217, lr = 0.0001\n",
            "2025-05-01 18:38:12 INFO     Epoch 5 [350/781]: loss = 3.472223997116089, lr = 0.0001\n",
            "2025-05-01 18:38:26 INFO     Epoch 5 [400/781]: loss = 3.4763004779815674, lr = 0.0001\n",
            "2025-05-01 18:38:40 INFO     Epoch 5 [450/781]: loss = 3.4529917240142822, lr = 0.0001\n",
            "2025-05-01 18:38:53 INFO     Epoch 5 [500/781]: loss = 3.6166303157806396, lr = 0.0001\n",
            "2025-05-01 18:39:07 INFO     Epoch 5 [550/781]: loss = 3.7545411586761475, lr = 0.0001\n",
            "2025-05-01 18:39:21 INFO     Epoch 5 [600/781]: loss = 3.4243876934051514, lr = 0.0001\n",
            "2025-05-01 18:39:34 INFO     Epoch 5 [650/781]: loss = 3.4961366653442383, lr = 0.0001\n",
            "2025-05-01 18:39:48 INFO     Epoch 5 [700/781]: loss = 3.7592194080352783, lr = 0.0001\n",
            "2025-05-01 18:40:02 INFO     Epoch 5 [750/781]: loss = 3.7556514739990234, lr = 0.0001\n",
            "2025-05-01 18:40:11 INFO     Epoch 6 [0/781]: loss = 3.256751298904419, lr = 0.0001\n",
            "2025-05-01 18:40:25 INFO     Epoch 6 [50/781]: loss = 3.558974027633667, lr = 0.0001\n",
            "2025-05-01 18:40:38 INFO     Epoch 6 [100/781]: loss = 3.648045301437378, lr = 0.0001\n",
            "2025-05-01 18:40:52 INFO     Epoch 6 [150/781]: loss = 3.4835727214813232, lr = 0.0001\n",
            "2025-05-01 18:41:06 INFO     Epoch 6 [200/781]: loss = 3.7278430461883545, lr = 0.0001\n",
            "2025-05-01 18:41:19 INFO     Epoch 6 [250/781]: loss = 3.459735631942749, lr = 0.0001\n",
            "2025-05-01 18:41:33 INFO     Epoch 6 [300/781]: loss = 3.243973731994629, lr = 0.0001\n",
            "2025-05-01 18:41:47 INFO     Epoch 6 [350/781]: loss = 3.4916460514068604, lr = 0.0001\n",
            "2025-05-01 18:42:00 INFO     Epoch 6 [400/781]: loss = 3.6253888607025146, lr = 0.0001\n",
            "2025-05-01 18:42:14 INFO     Epoch 6 [450/781]: loss = 3.374070882797241, lr = 0.0001\n",
            "2025-05-01 18:42:28 INFO     Epoch 6 [500/781]: loss = 3.6132986545562744, lr = 0.0001\n",
            "2025-05-01 18:42:41 INFO     Epoch 6 [550/781]: loss = 3.524738073348999, lr = 0.0001\n",
            "2025-05-01 18:42:55 INFO     Epoch 6 [600/781]: loss = 3.505547285079956, lr = 0.0001\n",
            "2025-05-01 18:43:09 INFO     Epoch 6 [650/781]: loss = 3.549913167953491, lr = 0.0001\n",
            "2025-05-01 18:43:22 INFO     Epoch 6 [700/781]: loss = 3.454444646835327, lr = 0.0001\n",
            "2025-05-01 18:43:36 INFO     Epoch 6 [750/781]: loss = 3.5288703441619873, lr = 0.0001\n",
            "2025-05-01 18:43:45 INFO     Epoch 7 [0/781]: loss = 3.089755058288574, lr = 0.0001\n",
            "2025-05-01 18:43:59 INFO     Epoch 7 [50/781]: loss = 3.573591470718384, lr = 0.0001\n",
            "2025-05-01 18:44:13 INFO     Epoch 7 [100/781]: loss = 3.668135643005371, lr = 0.0001\n",
            "2025-05-01 18:44:26 INFO     Epoch 7 [150/781]: loss = 3.3680784702301025, lr = 0.0001\n",
            "2025-05-01 18:44:40 INFO     Epoch 7 [200/781]: loss = 3.688044786453247, lr = 0.0001\n",
            "2025-05-01 18:44:53 INFO     Epoch 7 [250/781]: loss = 3.52787709236145, lr = 0.0001\n",
            "2025-05-01 18:45:07 INFO     Epoch 7 [300/781]: loss = 3.3904945850372314, lr = 0.0001\n",
            "2025-05-01 18:45:21 INFO     Epoch 7 [350/781]: loss = 3.504657745361328, lr = 0.0001\n",
            "2025-05-01 18:45:35 INFO     Epoch 7 [400/781]: loss = 3.409571409225464, lr = 0.0001\n",
            "2025-05-01 18:45:48 INFO     Epoch 7 [450/781]: loss = 3.4043960571289062, lr = 0.0001\n",
            "2025-05-01 18:46:02 INFO     Epoch 7 [500/781]: loss = 3.4094808101654053, lr = 0.0001\n",
            "2025-05-01 18:46:16 INFO     Epoch 7 [550/781]: loss = 3.7672994136810303, lr = 0.0001\n",
            "2025-05-01 18:46:29 INFO     Epoch 7 [600/781]: loss = 3.4438464641571045, lr = 0.0001\n",
            "2025-05-01 18:46:43 INFO     Epoch 7 [650/781]: loss = 3.27984881401062, lr = 0.0001\n",
            "2025-05-01 18:46:57 INFO     Epoch 7 [700/781]: loss = 3.5905847549438477, lr = 0.0001\n",
            "2025-05-01 18:47:11 INFO     Epoch 7 [750/781]: loss = 3.4339656829833984, lr = 0.0001\n",
            "2025-05-01 18:47:20 INFO     Epoch 8 [0/781]: loss = 3.447997808456421, lr = 0.0001\n",
            "2025-05-01 18:47:34 INFO     Epoch 8 [50/781]: loss = 3.2368876934051514, lr = 0.0001\n",
            "2025-05-01 18:47:48 INFO     Epoch 8 [100/781]: loss = 3.0803451538085938, lr = 0.0001\n",
            "2025-05-01 18:48:01 INFO     Epoch 8 [150/781]: loss = 3.5311403274536133, lr = 0.0001\n",
            "2025-05-01 18:48:15 INFO     Epoch 8 [200/781]: loss = 3.257333993911743, lr = 0.0001\n",
            "2025-05-01 18:48:29 INFO     Epoch 8 [250/781]: loss = 3.4108188152313232, lr = 0.0001\n",
            "2025-05-01 18:48:43 INFO     Epoch 8 [300/781]: loss = 3.514864921569824, lr = 0.0001\n",
            "2025-05-01 18:48:56 INFO     Epoch 8 [350/781]: loss = 3.5065460205078125, lr = 0.0001\n",
            "2025-05-01 18:49:10 INFO     Epoch 8 [400/781]: loss = 3.54874587059021, lr = 0.0001\n",
            "2025-05-01 18:49:24 INFO     Epoch 8 [450/781]: loss = 3.2356624603271484, lr = 0.0001\n",
            "2025-05-01 18:49:38 INFO     Epoch 8 [500/781]: loss = 3.473159074783325, lr = 0.0001\n",
            "2025-05-01 18:49:51 INFO     Epoch 8 [550/781]: loss = 3.5391740798950195, lr = 0.0001\n",
            "2025-05-01 18:50:05 INFO     Epoch 8 [600/781]: loss = 3.4634664058685303, lr = 0.0001\n",
            "2025-05-01 18:50:19 INFO     Epoch 8 [650/781]: loss = 3.2996838092803955, lr = 0.0001\n",
            "2025-05-01 18:50:32 INFO     Epoch 8 [700/781]: loss = 3.423647880554199, lr = 0.0001\n",
            "2025-05-01 18:50:46 INFO     Epoch 8 [750/781]: loss = 3.565368890762329, lr = 0.0001\n",
            "2025-05-01 18:50:55 INFO     Epoch 9 [0/781]: loss = 3.151634931564331, lr = 0.0001\n",
            "2025-05-01 18:51:09 INFO     Epoch 9 [50/781]: loss = 3.1138925552368164, lr = 0.0001\n",
            "2025-05-01 18:51:23 INFO     Epoch 9 [100/781]: loss = 3.515406847000122, lr = 0.0001\n",
            "2025-05-01 18:51:36 INFO     Epoch 9 [150/781]: loss = 3.649785280227661, lr = 0.0001\n",
            "2025-05-01 18:51:50 INFO     Epoch 9 [200/781]: loss = 3.3793790340423584, lr = 0.0001\n",
            "2025-05-01 18:52:04 INFO     Epoch 9 [250/781]: loss = 3.345064163208008, lr = 0.0001\n",
            "2025-05-01 18:52:17 INFO     Epoch 9 [300/781]: loss = 3.150484085083008, lr = 0.0001\n",
            "2025-05-01 18:52:31 INFO     Epoch 9 [350/781]: loss = 2.8274004459381104, lr = 0.0001\n",
            "2025-05-01 18:52:44 INFO     Epoch 9 [400/781]: loss = 2.902571439743042, lr = 0.0001\n",
            "2025-05-01 18:52:58 INFO     Epoch 9 [450/781]: loss = 3.292004346847534, lr = 0.0001\n",
            "2025-05-01 18:53:12 INFO     Epoch 9 [500/781]: loss = 3.341883897781372, lr = 0.0001\n",
            "2025-05-01 18:53:25 INFO     Epoch 9 [550/781]: loss = 3.358152151107788, lr = 0.0001\n",
            "2025-05-01 18:53:39 INFO     Epoch 9 [600/781]: loss = 3.452082872390747, lr = 0.0001\n",
            "2025-05-01 18:53:52 INFO     Epoch 9 [650/781]: loss = 3.474902391433716, lr = 0.0001\n",
            "2025-05-01 18:54:06 INFO     Epoch 9 [700/781]: loss = 3.4273550510406494, lr = 0.0001\n",
            "2025-05-01 18:54:20 INFO     Epoch 9 [750/781]: loss = 3.592985153198242, lr = 0.0001\n",
            "2025-05-01 18:54:29 INFO     Epoch 10 [0/781]: loss = 3.3599655628204346, lr = 0.0001\n",
            "2025-05-01 18:54:43 INFO     Epoch 10 [50/781]: loss = 3.6343538761138916, lr = 0.0001\n",
            "2025-05-01 18:54:57 INFO     Epoch 10 [100/781]: loss = 3.523643732070923, lr = 0.0001\n",
            "2025-05-01 18:55:10 INFO     Epoch 10 [150/781]: loss = 3.3964579105377197, lr = 0.0001\n",
            "2025-05-01 18:55:24 INFO     Epoch 10 [200/781]: loss = 3.5441315174102783, lr = 0.0001\n",
            "2025-05-01 18:55:38 INFO     Epoch 10 [250/781]: loss = 3.2646572589874268, lr = 0.0001\n",
            "2025-05-01 18:55:51 INFO     Epoch 10 [300/781]: loss = 3.0652217864990234, lr = 0.0001\n",
            "2025-05-01 18:56:05 INFO     Epoch 10 [350/781]: loss = 3.260641098022461, lr = 0.0001\n",
            "2025-05-01 18:56:19 INFO     Epoch 10 [400/781]: loss = 3.2466228008270264, lr = 0.0001\n",
            "2025-05-01 18:56:32 INFO     Epoch 10 [450/781]: loss = 3.068963050842285, lr = 0.0001\n",
            "2025-05-01 18:56:46 INFO     Epoch 10 [500/781]: loss = 3.5726382732391357, lr = 0.0001\n",
            "2025-05-01 18:56:59 INFO     Epoch 10 [550/781]: loss = 3.3968141078948975, lr = 0.0001\n",
            "2025-05-01 18:57:13 INFO     Epoch 10 [600/781]: loss = 3.508753538131714, lr = 0.0001\n",
            "2025-05-01 18:57:27 INFO     Epoch 10 [650/781]: loss = 3.2244207859039307, lr = 0.0001\n",
            "2025-05-01 18:57:40 INFO     Epoch 10 [700/781]: loss = 3.607976198196411, lr = 0.0001\n",
            "2025-05-01 18:57:54 INFO     Epoch 10 [750/781]: loss = 3.6206836700439453, lr = 0.0001\n",
            "2025-05-01 18:58:03 INFO     Epoch 11 [0/781]: loss = 3.396373987197876, lr = 0.0001\n",
            "2025-05-01 18:58:17 INFO     Epoch 11 [50/781]: loss = 3.3627383708953857, lr = 0.0001\n",
            "2025-05-01 18:58:30 INFO     Epoch 11 [100/781]: loss = 3.2114169597625732, lr = 0.0001\n",
            "2025-05-01 18:58:44 INFO     Epoch 11 [150/781]: loss = 3.3979368209838867, lr = 0.0001\n",
            "2025-05-01 18:58:58 INFO     Epoch 11 [200/781]: loss = 3.7025575637817383, lr = 0.0001\n",
            "2025-05-01 18:59:11 INFO     Epoch 11 [250/781]: loss = 3.446202278137207, lr = 0.0001\n",
            "2025-05-01 18:59:25 INFO     Epoch 11 [300/781]: loss = 3.4975764751434326, lr = 0.0001\n",
            "2025-05-01 18:59:39 INFO     Epoch 11 [350/781]: loss = 3.5082790851593018, lr = 0.0001\n",
            "2025-05-01 18:59:52 INFO     Epoch 11 [400/781]: loss = 3.0372791290283203, lr = 0.0001\n",
            "2025-05-01 19:00:06 INFO     Epoch 11 [450/781]: loss = 3.368720293045044, lr = 0.0001\n",
            "2025-05-01 19:00:20 INFO     Epoch 11 [500/781]: loss = 3.5358498096466064, lr = 0.0001\n",
            "2025-05-01 19:00:33 INFO     Epoch 11 [550/781]: loss = 3.2346267700195312, lr = 0.0001\n",
            "2025-05-01 19:00:47 INFO     Epoch 11 [600/781]: loss = 3.1154539585113525, lr = 0.0001\n",
            "2025-05-01 19:01:01 INFO     Epoch 11 [650/781]: loss = 3.545603036880493, lr = 0.0001\n",
            "2025-05-01 19:01:14 INFO     Epoch 11 [700/781]: loss = 3.361128091812134, lr = 0.0001\n",
            "2025-05-01 19:01:28 INFO     Epoch 11 [750/781]: loss = 3.7187068462371826, lr = 0.0001\n",
            "2025-05-01 19:01:37 INFO     Epoch 12 [0/781]: loss = 3.533299207687378, lr = 0.0001\n",
            "2025-05-01 19:01:51 INFO     Epoch 12 [50/781]: loss = 3.1569433212280273, lr = 0.0001\n",
            "2025-05-01 19:02:04 INFO     Epoch 12 [100/781]: loss = 3.351757287979126, lr = 0.0001\n",
            "2025-05-01 19:02:18 INFO     Epoch 12 [150/781]: loss = 3.6238222122192383, lr = 0.0001\n",
            "2025-05-01 19:02:32 INFO     Epoch 12 [200/781]: loss = 3.2728185653686523, lr = 0.0001\n",
            "2025-05-01 19:02:45 INFO     Epoch 12 [250/781]: loss = 3.2396023273468018, lr = 0.0001\n",
            "2025-05-01 19:02:59 INFO     Epoch 12 [300/781]: loss = 3.2762699127197266, lr = 0.0001\n",
            "2025-05-01 19:03:12 INFO     Epoch 12 [350/781]: loss = 3.403416395187378, lr = 0.0001\n",
            "2025-05-01 19:03:26 INFO     Epoch 12 [400/781]: loss = 3.3482329845428467, lr = 0.0001\n",
            "2025-05-01 19:03:40 INFO     Epoch 12 [450/781]: loss = 3.3456432819366455, lr = 0.0001\n",
            "2025-05-01 19:03:53 INFO     Epoch 12 [500/781]: loss = 2.936666488647461, lr = 0.0001\n",
            "2025-05-01 19:04:07 INFO     Epoch 12 [550/781]: loss = 3.3218653202056885, lr = 0.0001\n",
            "2025-05-01 19:04:20 INFO     Epoch 12 [600/781]: loss = 3.3011319637298584, lr = 0.0001\n",
            "2025-05-01 19:04:34 INFO     Epoch 12 [650/781]: loss = 3.242418050765991, lr = 0.0001\n",
            "2025-05-01 19:04:48 INFO     Epoch 12 [700/781]: loss = 3.2973382472991943, lr = 0.0001\n",
            "2025-05-01 19:05:01 INFO     Epoch 12 [750/781]: loss = 3.4855239391326904, lr = 0.0001\n",
            "2025-05-01 19:05:11 INFO     Epoch 13 [0/781]: loss = 3.4372212886810303, lr = 0.0001\n",
            "2025-05-01 19:05:24 INFO     Epoch 13 [50/781]: loss = 3.464679479598999, lr = 0.0001\n",
            "2025-05-01 19:05:38 INFO     Epoch 13 [100/781]: loss = 3.587434768676758, lr = 0.0001\n",
            "2025-05-01 19:05:52 INFO     Epoch 13 [150/781]: loss = 3.4003026485443115, lr = 0.0001\n",
            "2025-05-01 19:06:05 INFO     Epoch 13 [200/781]: loss = 3.136845827102661, lr = 0.0001\n",
            "2025-05-01 19:06:19 INFO     Epoch 13 [250/781]: loss = 3.2200028896331787, lr = 0.0001\n",
            "2025-05-01 19:06:32 INFO     Epoch 13 [300/781]: loss = 3.397089958190918, lr = 0.0001\n",
            "2025-05-01 19:06:46 INFO     Epoch 13 [350/781]: loss = 3.241895914077759, lr = 0.0001\n",
            "2025-05-01 19:07:00 INFO     Epoch 13 [400/781]: loss = 3.401521921157837, lr = 0.0001\n",
            "2025-05-01 19:07:13 INFO     Epoch 13 [450/781]: loss = 3.269594430923462, lr = 0.0001\n",
            "2025-05-01 19:07:27 INFO     Epoch 13 [500/781]: loss = 3.167073965072632, lr = 0.0001\n",
            "2025-05-01 19:07:41 INFO     Epoch 13 [550/781]: loss = 3.3603389263153076, lr = 0.0001\n",
            "2025-05-01 19:07:54 INFO     Epoch 13 [600/781]: loss = 3.206702947616577, lr = 0.0001\n",
            "2025-05-01 19:08:08 INFO     Epoch 13 [650/781]: loss = 3.4483299255371094, lr = 0.0001\n",
            "2025-05-01 19:08:21 INFO     Epoch 13 [700/781]: loss = 3.485034227371216, lr = 0.0001\n",
            "2025-05-01 19:08:35 INFO     Epoch 13 [750/781]: loss = 3.420603036880493, lr = 0.0001\n",
            "2025-05-01 19:08:44 INFO     Epoch 14 [0/781]: loss = 2.993471384048462, lr = 0.0001\n",
            "2025-05-01 19:08:58 INFO     Epoch 14 [50/781]: loss = 3.1820642948150635, lr = 0.0001\n",
            "2025-05-01 19:09:12 INFO     Epoch 14 [100/781]: loss = 3.6137590408325195, lr = 0.0001\n",
            "2025-05-01 19:09:25 INFO     Epoch 14 [150/781]: loss = 3.1744048595428467, lr = 0.0001\n",
            "2025-05-01 19:09:39 INFO     Epoch 14 [200/781]: loss = 2.911618947982788, lr = 0.0001\n",
            "2025-05-01 19:09:53 INFO     Epoch 14 [250/781]: loss = 3.4423701763153076, lr = 0.0001\n",
            "2025-05-01 19:10:06 INFO     Epoch 14 [300/781]: loss = 3.0940961837768555, lr = 0.0001\n",
            "2025-05-01 19:10:20 INFO     Epoch 14 [350/781]: loss = 3.2488415241241455, lr = 0.0001\n",
            "2025-05-01 19:10:33 INFO     Epoch 14 [400/781]: loss = 3.4224672317504883, lr = 0.0001\n",
            "2025-05-01 19:10:47 INFO     Epoch 14 [450/781]: loss = 3.510920524597168, lr = 0.0001\n",
            "2025-05-01 19:11:01 INFO     Epoch 14 [500/781]: loss = 3.0432937145233154, lr = 0.0001\n",
            "2025-05-01 19:11:14 INFO     Epoch 14 [550/781]: loss = 3.328723192214966, lr = 0.0001\n",
            "2025-05-01 19:11:28 INFO     Epoch 14 [600/781]: loss = 3.0859014987945557, lr = 0.0001\n",
            "2025-05-01 19:11:42 INFO     Epoch 14 [650/781]: loss = 3.518747329711914, lr = 0.0001\n",
            "2025-05-01 19:11:55 INFO     Epoch 14 [700/781]: loss = 3.2240283489227295, lr = 0.0001\n",
            "2025-05-01 19:12:09 INFO     Epoch 14 [750/781]: loss = 3.672273874282837, lr = 0.0001\n",
            "2025-05-01 19:12:18 INFO     Epoch 15 [0/781]: loss = 3.409038543701172, lr = 0.0001\n",
            "2025-05-01 19:12:32 INFO     Epoch 15 [50/781]: loss = 3.365671157836914, lr = 0.0001\n",
            "2025-05-01 19:12:46 INFO     Epoch 15 [100/781]: loss = 3.344564437866211, lr = 0.0001\n",
            "2025-05-01 19:12:59 INFO     Epoch 15 [150/781]: loss = 3.372138023376465, lr = 0.0001\n",
            "2025-05-01 19:13:13 INFO     Epoch 15 [200/781]: loss = 3.4982635974884033, lr = 0.0001\n",
            "2025-05-01 19:13:27 INFO     Epoch 15 [250/781]: loss = 3.421172857284546, lr = 0.0001\n",
            "2025-05-01 19:13:40 INFO     Epoch 15 [300/781]: loss = 3.272317886352539, lr = 0.0001\n",
            "2025-05-01 19:13:54 INFO     Epoch 15 [350/781]: loss = 3.633005142211914, lr = 0.0001\n",
            "2025-05-01 19:14:07 INFO     Epoch 15 [400/781]: loss = 3.3373279571533203, lr = 0.0001\n",
            "2025-05-01 19:14:21 INFO     Epoch 15 [450/781]: loss = 3.4293935298919678, lr = 0.0001\n",
            "2025-05-01 19:14:35 INFO     Epoch 15 [500/781]: loss = 3.2763516902923584, lr = 0.0001\n",
            "2025-05-01 19:14:48 INFO     Epoch 15 [550/781]: loss = 3.5746514797210693, lr = 0.0001\n",
            "2025-05-01 19:15:02 INFO     Epoch 15 [600/781]: loss = 3.2710368633270264, lr = 0.0001\n",
            "2025-05-01 19:15:16 INFO     Epoch 15 [650/781]: loss = 3.2102277278900146, lr = 0.0001\n",
            "2025-05-01 19:15:29 INFO     Epoch 15 [700/781]: loss = 3.509803056716919, lr = 0.0001\n",
            "2025-05-01 19:15:43 INFO     Epoch 15 [750/781]: loss = 3.512200355529785, lr = 0.0001\n",
            "2025-05-01 19:15:52 INFO     Epoch 16 [0/781]: loss = 3.0009727478027344, lr = 0.0001\n",
            "2025-05-01 19:16:06 INFO     Epoch 16 [50/781]: loss = 3.0917444229125977, lr = 0.0001\n",
            "2025-05-01 19:16:20 INFO     Epoch 16 [100/781]: loss = 3.6283130645751953, lr = 0.0001\n",
            "2025-05-01 19:16:33 INFO     Epoch 16 [150/781]: loss = 3.129166603088379, lr = 0.0001\n",
            "2025-05-01 19:16:47 INFO     Epoch 16 [200/781]: loss = 3.443681478500366, lr = 0.0001\n",
            "2025-05-01 19:17:00 INFO     Epoch 16 [250/781]: loss = 3.493975877761841, lr = 0.0001\n",
            "2025-05-01 19:17:14 INFO     Epoch 16 [300/781]: loss = 3.2830657958984375, lr = 0.0001\n",
            "2025-05-01 19:17:28 INFO     Epoch 16 [350/781]: loss = 3.254122734069824, lr = 0.0001\n",
            "2025-05-01 19:17:41 INFO     Epoch 16 [400/781]: loss = 3.4647350311279297, lr = 0.0001\n",
            "2025-05-01 19:17:55 INFO     Epoch 16 [450/781]: loss = 3.620712995529175, lr = 0.0001\n",
            "2025-05-01 19:18:09 INFO     Epoch 16 [500/781]: loss = 3.04376220703125, lr = 0.0001\n",
            "2025-05-01 19:18:22 INFO     Epoch 16 [550/781]: loss = 3.3798601627349854, lr = 0.0001\n",
            "2025-05-01 19:18:36 INFO     Epoch 16 [600/781]: loss = 3.6831719875335693, lr = 0.0001\n",
            "2025-05-01 19:18:49 INFO     Epoch 16 [650/781]: loss = 3.4031503200531006, lr = 0.0001\n",
            "2025-05-01 19:19:03 INFO     Epoch 16 [700/781]: loss = 3.4040956497192383, lr = 0.0001\n",
            "2025-05-01 19:19:17 INFO     Epoch 16 [750/781]: loss = 3.3593533039093018, lr = 0.0001\n",
            "2025-05-01 19:19:27 INFO     Epoch 17 [0/781]: loss = 3.311912775039673, lr = 0.0001\n",
            "2025-05-01 19:19:40 INFO     Epoch 17 [50/781]: loss = 3.4742019176483154, lr = 0.0001\n",
            "2025-05-01 19:19:54 INFO     Epoch 17 [100/781]: loss = 3.5503299236297607, lr = 0.0001\n",
            "2025-05-01 19:20:07 INFO     Epoch 17 [150/781]: loss = 3.0773661136627197, lr = 0.0001\n",
            "2025-05-01 19:20:21 INFO     Epoch 17 [200/781]: loss = 3.016303062438965, lr = 0.0001\n",
            "2025-05-01 19:20:35 INFO     Epoch 17 [250/781]: loss = 3.403325319290161, lr = 0.0001\n",
            "2025-05-01 19:20:48 INFO     Epoch 17 [300/781]: loss = 3.162569761276245, lr = 0.0001\n",
            "2025-05-01 19:21:02 INFO     Epoch 17 [350/781]: loss = 3.2343409061431885, lr = 0.0001\n",
            "2025-05-01 19:21:16 INFO     Epoch 17 [400/781]: loss = 3.114590883255005, lr = 0.0001\n",
            "2025-05-01 19:21:29 INFO     Epoch 17 [450/781]: loss = 3.272394895553589, lr = 0.0001\n",
            "2025-05-01 19:21:43 INFO     Epoch 17 [500/781]: loss = 3.3346731662750244, lr = 0.0001\n",
            "2025-05-01 19:21:57 INFO     Epoch 17 [550/781]: loss = 3.1964809894561768, lr = 0.0001\n",
            "2025-05-01 19:22:10 INFO     Epoch 17 [600/781]: loss = 2.9987471103668213, lr = 0.0001\n",
            "2025-05-01 19:22:24 INFO     Epoch 17 [650/781]: loss = 3.2003087997436523, lr = 0.0001\n",
            "2025-05-01 19:22:37 INFO     Epoch 17 [700/781]: loss = 3.369274139404297, lr = 0.0001\n",
            "2025-05-01 19:22:51 INFO     Epoch 17 [750/781]: loss = 3.5905349254608154, lr = 0.0001\n",
            "2025-05-01 19:23:00 INFO     Epoch 18 [0/781]: loss = 3.3020248413085938, lr = 0.0001\n",
            "2025-05-01 19:23:14 INFO     Epoch 18 [50/781]: loss = 3.2843806743621826, lr = 0.0001\n",
            "2025-05-01 19:23:28 INFO     Epoch 18 [100/781]: loss = 3.3354198932647705, lr = 0.0001\n",
            "2025-05-01 19:23:41 INFO     Epoch 18 [150/781]: loss = 3.2732150554656982, lr = 0.0001\n",
            "2025-05-01 19:23:55 INFO     Epoch 18 [200/781]: loss = 3.3431313037872314, lr = 0.0001\n",
            "2025-05-01 19:24:09 INFO     Epoch 18 [250/781]: loss = 2.9859371185302734, lr = 0.0001\n",
            "2025-05-01 19:24:22 INFO     Epoch 18 [300/781]: loss = 3.1557083129882812, lr = 0.0001\n",
            "2025-05-01 19:24:36 INFO     Epoch 18 [350/781]: loss = 3.450237989425659, lr = 0.0001\n",
            "2025-05-01 19:24:49 INFO     Epoch 18 [400/781]: loss = 3.292543649673462, lr = 0.0001\n",
            "2025-05-01 19:25:03 INFO     Epoch 18 [450/781]: loss = 3.5687055587768555, lr = 0.0001\n",
            "2025-05-01 19:25:17 INFO     Epoch 18 [500/781]: loss = 2.9088754653930664, lr = 0.0001\n",
            "2025-05-01 19:25:30 INFO     Epoch 18 [550/781]: loss = 3.097543478012085, lr = 0.0001\n",
            "2025-05-01 19:25:44 INFO     Epoch 18 [600/781]: loss = 3.3157269954681396, lr = 0.0001\n",
            "2025-05-01 19:25:58 INFO     Epoch 18 [650/781]: loss = 3.072157859802246, lr = 0.0001\n",
            "2025-05-01 19:26:11 INFO     Epoch 18 [700/781]: loss = 3.0011465549468994, lr = 0.0001\n",
            "2025-05-01 19:26:25 INFO     Epoch 18 [750/781]: loss = 3.2003908157348633, lr = 0.0001\n",
            "2025-05-01 19:26:34 INFO     Epoch 19 [0/781]: loss = 3.407895803451538, lr = 0.0001\n",
            "2025-05-01 19:26:48 INFO     Epoch 19 [50/781]: loss = 3.6354992389678955, lr = 0.0001\n",
            "2025-05-01 19:27:01 INFO     Epoch 19 [100/781]: loss = 3.5192387104034424, lr = 0.0001\n",
            "2025-05-01 19:27:15 INFO     Epoch 19 [150/781]: loss = 3.3592967987060547, lr = 0.0001\n",
            "2025-05-01 19:27:29 INFO     Epoch 19 [200/781]: loss = 3.4811716079711914, lr = 0.0001\n",
            "2025-05-01 19:27:42 INFO     Epoch 19 [250/781]: loss = 3.3469221591949463, lr = 0.0001\n",
            "2025-05-01 19:27:56 INFO     Epoch 19 [300/781]: loss = 3.2704861164093018, lr = 0.0001\n",
            "2025-05-01 19:28:10 INFO     Epoch 19 [350/781]: loss = 3.3246681690216064, lr = 0.0001\n",
            "2025-05-01 19:28:23 INFO     Epoch 19 [400/781]: loss = 3.335639238357544, lr = 0.0001\n",
            "2025-05-01 19:28:37 INFO     Epoch 19 [450/781]: loss = 3.5217275619506836, lr = 0.0001\n",
            "2025-05-01 19:28:50 INFO     Epoch 19 [500/781]: loss = 3.468332052230835, lr = 0.0001\n",
            "2025-05-01 19:29:04 INFO     Epoch 19 [550/781]: loss = 2.976717710494995, lr = 0.0001\n",
            "2025-05-01 19:29:18 INFO     Epoch 19 [600/781]: loss = 3.1640474796295166, lr = 0.0001\n",
            "2025-05-01 19:29:31 INFO     Epoch 19 [650/781]: loss = 3.2684526443481445, lr = 0.0001\n",
            "2025-05-01 19:29:45 INFO     Epoch 19 [700/781]: loss = 3.360549211502075, lr = 0.0001\n",
            "2025-05-01 19:29:58 INFO     Epoch 19 [750/781]: loss = 3.4201648235321045, lr = 0.0001\n",
            "2025-05-01 19:30:08 INFO     Epoch 20 [0/781]: loss = 3.288322687149048, lr = 0.0001\n",
            "2025-05-01 19:30:21 INFO     Epoch 20 [50/781]: loss = 3.2184760570526123, lr = 0.0001\n",
            "2025-05-01 19:30:35 INFO     Epoch 20 [100/781]: loss = 3.096172571182251, lr = 0.0001\n",
            "2025-05-01 19:30:49 INFO     Epoch 20 [150/781]: loss = 3.053874969482422, lr = 0.0001\n",
            "2025-05-01 19:31:02 INFO     Epoch 20 [200/781]: loss = 3.2326669692993164, lr = 0.0001\n",
            "2025-05-01 19:31:16 INFO     Epoch 20 [250/781]: loss = 3.466937780380249, lr = 0.0001\n",
            "2025-05-01 19:31:30 INFO     Epoch 20 [300/781]: loss = 3.3822288513183594, lr = 0.0001\n",
            "2025-05-01 19:31:43 INFO     Epoch 20 [350/781]: loss = 2.974804639816284, lr = 0.0001\n",
            "2025-05-01 19:31:57 INFO     Epoch 20 [400/781]: loss = 3.146101951599121, lr = 0.0001\n",
            "2025-05-01 19:32:11 INFO     Epoch 20 [450/781]: loss = 3.1555635929107666, lr = 0.0001\n",
            "2025-05-01 19:32:24 INFO     Epoch 20 [500/781]: loss = 3.6682989597320557, lr = 0.0001\n",
            "2025-05-01 19:32:38 INFO     Epoch 20 [550/781]: loss = 3.3534231185913086, lr = 0.0001\n",
            "2025-05-01 19:32:52 INFO     Epoch 20 [600/781]: loss = 3.205054998397827, lr = 0.0001\n",
            "2025-05-01 19:33:05 INFO     Epoch 20 [650/781]: loss = 3.722600221633911, lr = 0.0001\n",
            "2025-05-01 19:33:19 INFO     Epoch 20 [700/781]: loss = 3.3760130405426025, lr = 0.0001\n",
            "2025-05-01 19:33:32 INFO     Epoch 20 [750/781]: loss = 3.3494861125946045, lr = 0.0001\n",
            "2025-05-01 19:33:42 INFO     Epoch 21 [0/781]: loss = 3.267512321472168, lr = 0.0001\n",
            "2025-05-01 19:33:55 INFO     Epoch 21 [50/781]: loss = 3.153261184692383, lr = 0.0001\n",
            "2025-05-01 19:34:09 INFO     Epoch 21 [100/781]: loss = 3.4803085327148438, lr = 0.0001\n",
            "2025-05-01 19:34:23 INFO     Epoch 21 [150/781]: loss = 3.3068666458129883, lr = 0.0001\n",
            "2025-05-01 19:34:36 INFO     Epoch 21 [200/781]: loss = 3.3162050247192383, lr = 0.0001\n",
            "2025-05-01 19:34:50 INFO     Epoch 21 [250/781]: loss = 3.30924129486084, lr = 0.0001\n",
            "2025-05-01 19:35:04 INFO     Epoch 21 [300/781]: loss = 2.995424509048462, lr = 0.0001\n",
            "2025-05-01 19:35:17 INFO     Epoch 21 [350/781]: loss = 3.6244184970855713, lr = 0.0001\n",
            "2025-05-01 19:35:31 INFO     Epoch 21 [400/781]: loss = 2.8190557956695557, lr = 0.0001\n",
            "2025-05-01 19:35:44 INFO     Epoch 21 [450/781]: loss = 3.473052978515625, lr = 0.0001\n",
            "2025-05-01 19:35:58 INFO     Epoch 21 [500/781]: loss = 3.272867441177368, lr = 0.0001\n",
            "2025-05-01 19:36:12 INFO     Epoch 21 [550/781]: loss = 3.2434260845184326, lr = 0.0001\n",
            "2025-05-01 19:36:25 INFO     Epoch 21 [600/781]: loss = 3.323195457458496, lr = 0.0001\n",
            "2025-05-01 19:36:39 INFO     Epoch 21 [650/781]: loss = 2.9780375957489014, lr = 0.0001\n",
            "2025-05-01 19:36:53 INFO     Epoch 21 [700/781]: loss = 3.1972596645355225, lr = 0.0001\n",
            "2025-05-01 19:37:06 INFO     Epoch 21 [750/781]: loss = 3.2656402587890625, lr = 0.0001\n",
            "2025-05-01 19:37:16 INFO     Epoch 22 [0/781]: loss = 3.139353036880493, lr = 0.0001\n",
            "2025-05-01 19:37:29 INFO     Epoch 22 [50/781]: loss = 3.3651247024536133, lr = 0.0001\n",
            "2025-05-01 19:37:43 INFO     Epoch 22 [100/781]: loss = 3.2187421321868896, lr = 0.0001\n",
            "2025-05-01 19:37:57 INFO     Epoch 22 [150/781]: loss = 3.401160955429077, lr = 0.0001\n",
            "2025-05-01 19:38:10 INFO     Epoch 22 [200/781]: loss = 3.2392427921295166, lr = 0.0001\n",
            "2025-05-01 19:38:24 INFO     Epoch 22 [250/781]: loss = 3.591603994369507, lr = 0.0001\n",
            "2025-05-01 19:38:37 INFO     Epoch 22 [300/781]: loss = 3.285856246948242, lr = 0.0001\n",
            "2025-05-01 19:38:51 INFO     Epoch 22 [350/781]: loss = 3.304809808731079, lr = 0.0001\n",
            "2025-05-01 19:39:05 INFO     Epoch 22 [400/781]: loss = 3.103712320327759, lr = 0.0001\n",
            "2025-05-01 19:39:18 INFO     Epoch 22 [450/781]: loss = 3.168086051940918, lr = 0.0001\n",
            "2025-05-01 19:39:32 INFO     Epoch 22 [500/781]: loss = 2.9791316986083984, lr = 0.0001\n",
            "2025-05-01 19:39:46 INFO     Epoch 22 [550/781]: loss = 3.2949142456054688, lr = 0.0001\n",
            "2025-05-01 19:39:59 INFO     Epoch 22 [600/781]: loss = 3.23442006111145, lr = 0.0001\n",
            "2025-05-01 19:40:13 INFO     Epoch 22 [650/781]: loss = 3.229355812072754, lr = 0.0001\n",
            "2025-05-01 19:40:27 INFO     Epoch 22 [700/781]: loss = 3.3864262104034424, lr = 0.0001\n",
            "2025-05-01 19:40:40 INFO     Epoch 22 [750/781]: loss = 3.548447608947754, lr = 0.0001\n",
            "2025-05-01 19:40:50 INFO     Epoch 23 [0/781]: loss = 3.1998260021209717, lr = 0.0001\n",
            "2025-05-01 19:41:03 INFO     Epoch 23 [50/781]: loss = 3.2588307857513428, lr = 0.0001\n",
            "2025-05-01 19:41:17 INFO     Epoch 23 [100/781]: loss = 3.3449411392211914, lr = 0.0001\n",
            "2025-05-01 19:41:30 INFO     Epoch 23 [150/781]: loss = 3.0640013217926025, lr = 0.0001\n",
            "2025-05-01 19:41:44 INFO     Epoch 23 [200/781]: loss = 3.3557310104370117, lr = 0.0001\n",
            "2025-05-01 19:41:58 INFO     Epoch 23 [250/781]: loss = 3.1969144344329834, lr = 0.0001\n",
            "2025-05-01 19:42:11 INFO     Epoch 23 [300/781]: loss = 3.101778268814087, lr = 0.0001\n",
            "2025-05-01 19:42:25 INFO     Epoch 23 [350/781]: loss = 3.331674814224243, lr = 0.0001\n",
            "2025-05-01 19:42:39 INFO     Epoch 23 [400/781]: loss = 3.392753839492798, lr = 0.0001\n",
            "2025-05-01 19:42:52 INFO     Epoch 23 [450/781]: loss = 3.054070472717285, lr = 0.0001\n",
            "2025-05-01 19:43:06 INFO     Epoch 23 [500/781]: loss = 3.3379251956939697, lr = 0.0001\n",
            "2025-05-01 19:43:20 INFO     Epoch 23 [550/781]: loss = 3.1072444915771484, lr = 0.0001\n",
            "2025-05-01 19:43:33 INFO     Epoch 23 [600/781]: loss = 3.2914459705352783, lr = 0.0001\n",
            "2025-05-01 19:43:47 INFO     Epoch 23 [650/781]: loss = 3.2231285572052, lr = 0.0001\n",
            "2025-05-01 19:44:01 INFO     Epoch 23 [700/781]: loss = 2.8238213062286377, lr = 0.0001\n",
            "2025-05-01 19:44:14 INFO     Epoch 23 [750/781]: loss = 3.476128578186035, lr = 0.0001\n",
            "2025-05-01 19:44:24 INFO     Epoch 24 [0/781]: loss = 3.2079169750213623, lr = 0.0001\n",
            "2025-05-01 19:44:38 INFO     Epoch 24 [50/781]: loss = 3.4237611293792725, lr = 0.0001\n",
            "2025-05-01 19:44:51 INFO     Epoch 24 [100/781]: loss = 3.339527130126953, lr = 0.0001\n",
            "2025-05-01 19:45:05 INFO     Epoch 24 [150/781]: loss = 2.897829055786133, lr = 0.0001\n",
            "2025-05-01 19:45:18 INFO     Epoch 24 [200/781]: loss = 3.0731070041656494, lr = 0.0001\n",
            "2025-05-01 19:45:32 INFO     Epoch 24 [250/781]: loss = 2.91961407661438, lr = 0.0001\n",
            "2025-05-01 19:45:46 INFO     Epoch 24 [300/781]: loss = 3.3056466579437256, lr = 0.0001\n",
            "2025-05-01 19:45:59 INFO     Epoch 24 [350/781]: loss = 3.01391339302063, lr = 0.0001\n",
            "2025-05-01 19:46:13 INFO     Epoch 24 [400/781]: loss = 3.1544206142425537, lr = 0.0001\n",
            "2025-05-01 19:46:27 INFO     Epoch 24 [450/781]: loss = 3.4390790462493896, lr = 0.0001\n",
            "2025-05-01 19:46:40 INFO     Epoch 24 [500/781]: loss = 3.340423345565796, lr = 0.0001\n",
            "2025-05-01 19:46:54 INFO     Epoch 24 [550/781]: loss = 3.6912829875946045, lr = 0.0001\n",
            "2025-05-01 19:47:08 INFO     Epoch 24 [600/781]: loss = 3.2310190200805664, lr = 0.0001\n",
            "2025-05-01 19:47:21 INFO     Epoch 24 [650/781]: loss = 3.2358646392822266, lr = 0.0001\n",
            "2025-05-01 19:47:35 INFO     Epoch 24 [700/781]: loss = 3.0515899658203125, lr = 0.0001\n",
            "2025-05-01 19:47:48 INFO     Epoch 24 [750/781]: loss = 3.720679998397827, lr = 0.0001\n",
            "2025-05-01 19:47:58 INFO     Epoch 25 [0/781]: loss = 3.42840838432312, lr = 0.0001\n",
            "2025-05-01 19:48:11 INFO     Epoch 25 [50/781]: loss = 3.3244524002075195, lr = 0.0001\n",
            "2025-05-01 19:48:25 INFO     Epoch 25 [100/781]: loss = 3.4166860580444336, lr = 0.0001\n",
            "2025-05-01 19:48:39 INFO     Epoch 25 [150/781]: loss = 3.2673981189727783, lr = 0.0001\n",
            "2025-05-01 19:48:52 INFO     Epoch 25 [200/781]: loss = 2.8031883239746094, lr = 0.0001\n",
            "2025-05-01 19:49:06 INFO     Epoch 25 [250/781]: loss = 2.7971620559692383, lr = 0.0001\n",
            "2025-05-01 19:49:20 INFO     Epoch 25 [300/781]: loss = 3.1542422771453857, lr = 0.0001\n",
            "2025-05-01 19:49:33 INFO     Epoch 25 [350/781]: loss = 3.092055320739746, lr = 0.0001\n",
            "2025-05-01 19:49:47 INFO     Epoch 25 [400/781]: loss = 3.148777723312378, lr = 0.0001\n",
            "2025-05-01 19:50:01 INFO     Epoch 25 [450/781]: loss = 3.6747472286224365, lr = 0.0001\n",
            "2025-05-01 19:50:14 INFO     Epoch 25 [500/781]: loss = 3.438961982727051, lr = 0.0001\n",
            "2025-05-01 19:50:28 INFO     Epoch 25 [550/781]: loss = 3.1095240116119385, lr = 0.0001\n",
            "2025-05-01 19:50:41 INFO     Epoch 25 [600/781]: loss = 3.359468698501587, lr = 0.0001\n",
            "2025-05-01 19:50:55 INFO     Epoch 25 [650/781]: loss = 3.121079683303833, lr = 0.0001\n",
            "2025-05-01 19:51:09 INFO     Epoch 25 [700/781]: loss = 3.431854248046875, lr = 0.0001\n",
            "2025-05-01 19:51:22 INFO     Epoch 25 [750/781]: loss = 3.4317033290863037, lr = 0.0001\n",
            "2025-05-01 19:51:32 INFO     Epoch 26 [0/781]: loss = 3.230351686477661, lr = 0.0001\n",
            "2025-05-01 19:51:46 INFO     Epoch 26 [50/781]: loss = 3.393909454345703, lr = 0.0001\n",
            "2025-05-01 19:51:59 INFO     Epoch 26 [100/781]: loss = 3.0023908615112305, lr = 0.0001\n",
            "2025-05-01 19:52:13 INFO     Epoch 26 [150/781]: loss = 3.2791452407836914, lr = 0.0001\n",
            "2025-05-01 19:52:26 INFO     Epoch 26 [200/781]: loss = 3.4299423694610596, lr = 0.0001\n",
            "2025-05-01 19:52:40 INFO     Epoch 26 [250/781]: loss = 3.3451240062713623, lr = 0.0001\n",
            "2025-05-01 19:52:54 INFO     Epoch 26 [300/781]: loss = 3.1596639156341553, lr = 0.0001\n",
            "2025-05-01 19:53:07 INFO     Epoch 26 [350/781]: loss = 3.3619203567504883, lr = 0.0001\n",
            "2025-05-01 19:53:21 INFO     Epoch 26 [400/781]: loss = 3.3861167430877686, lr = 0.0001\n",
            "2025-05-01 19:53:35 INFO     Epoch 26 [450/781]: loss = 3.3635714054107666, lr = 0.0001\n",
            "2025-05-01 19:53:48 INFO     Epoch 26 [500/781]: loss = 3.397430419921875, lr = 0.0001\n",
            "2025-05-01 19:54:02 INFO     Epoch 26 [550/781]: loss = 3.139934778213501, lr = 0.0001\n",
            "2025-05-01 19:54:16 INFO     Epoch 26 [600/781]: loss = 3.571138381958008, lr = 0.0001\n",
            "2025-05-01 19:54:29 INFO     Epoch 26 [650/781]: loss = 3.1871516704559326, lr = 0.0001\n",
            "2025-05-01 19:54:43 INFO     Epoch 26 [700/781]: loss = 3.3176276683807373, lr = 0.0001\n",
            "2025-05-01 19:54:56 INFO     Epoch 26 [750/781]: loss = 3.0691826343536377, lr = 0.0001\n",
            "2025-05-01 19:55:06 INFO     Epoch 27 [0/781]: loss = 3.092588186264038, lr = 0.0001\n",
            "2025-05-01 19:55:19 INFO     Epoch 27 [50/781]: loss = 3.306673288345337, lr = 0.0001\n",
            "2025-05-01 19:55:33 INFO     Epoch 27 [100/781]: loss = 3.64371657371521, lr = 0.0001\n",
            "2025-05-01 19:55:47 INFO     Epoch 27 [150/781]: loss = 3.010266065597534, lr = 0.0001\n",
            "2025-05-01 19:56:01 INFO     Epoch 27 [200/781]: loss = 2.8630306720733643, lr = 0.0001\n",
            "2025-05-01 19:56:14 INFO     Epoch 27 [250/781]: loss = 3.4735450744628906, lr = 0.0001\n",
            "2025-05-01 19:56:28 INFO     Epoch 27 [300/781]: loss = 2.8350369930267334, lr = 0.0001\n",
            "2025-05-01 19:56:41 INFO     Epoch 27 [350/781]: loss = 3.139704942703247, lr = 0.0001\n",
            "2025-05-01 19:56:55 INFO     Epoch 27 [400/781]: loss = 3.167872667312622, lr = 0.0001\n",
            "2025-05-01 19:57:09 INFO     Epoch 27 [450/781]: loss = 2.8811094760894775, lr = 0.0001\n",
            "2025-05-01 19:57:22 INFO     Epoch 27 [500/781]: loss = 3.763157606124878, lr = 0.0001\n",
            "2025-05-01 19:57:36 INFO     Epoch 27 [550/781]: loss = 3.3848984241485596, lr = 0.0001\n",
            "2025-05-01 19:57:50 INFO     Epoch 27 [600/781]: loss = 3.235293388366699, lr = 0.0001\n",
            "2025-05-01 19:58:03 INFO     Epoch 27 [650/781]: loss = 3.1781599521636963, lr = 0.0001\n",
            "2025-05-01 19:58:17 INFO     Epoch 27 [700/781]: loss = 3.3966586589813232, lr = 0.0001\n",
            "2025-05-01 19:58:30 INFO     Epoch 27 [750/781]: loss = 2.947042226791382, lr = 0.0001\n",
            "2025-05-01 19:58:40 INFO     Epoch 28 [0/781]: loss = 3.1694257259368896, lr = 0.0001\n",
            "2025-05-01 19:58:53 INFO     Epoch 28 [50/781]: loss = 2.7734215259552, lr = 0.0001\n",
            "2025-05-01 19:59:07 INFO     Epoch 28 [100/781]: loss = 3.3171374797821045, lr = 0.0001\n",
            "2025-05-01 19:59:21 INFO     Epoch 28 [150/781]: loss = 3.1325528621673584, lr = 0.0001\n",
            "2025-05-01 19:59:34 INFO     Epoch 28 [200/781]: loss = 3.0788400173187256, lr = 0.0001\n",
            "2025-05-01 19:59:48 INFO     Epoch 28 [250/781]: loss = 3.659734010696411, lr = 0.0001\n",
            "2025-05-01 20:00:02 INFO     Epoch 28 [300/781]: loss = 3.102719306945801, lr = 0.0001\n",
            "2025-05-01 20:00:15 INFO     Epoch 28 [350/781]: loss = 2.8756091594696045, lr = 0.0001\n",
            "2025-05-01 20:00:29 INFO     Epoch 28 [400/781]: loss = 3.1886303424835205, lr = 0.0001\n",
            "2025-05-01 20:00:43 INFO     Epoch 28 [450/781]: loss = 3.323228597640991, lr = 0.0001\n",
            "2025-05-01 20:00:56 INFO     Epoch 28 [500/781]: loss = 3.102813482284546, lr = 0.0001\n",
            "2025-05-01 20:01:10 INFO     Epoch 28 [550/781]: loss = 2.883366346359253, lr = 0.0001\n",
            "2025-05-01 20:01:23 INFO     Epoch 28 [600/781]: loss = 3.1837356090545654, lr = 0.0001\n",
            "2025-05-01 20:01:37 INFO     Epoch 28 [650/781]: loss = 3.3457348346710205, lr = 0.0001\n",
            "2025-05-01 20:01:51 INFO     Epoch 28 [700/781]: loss = 3.116037368774414, lr = 0.0001\n",
            "2025-05-01 20:02:04 INFO     Epoch 28 [750/781]: loss = 3.2823712825775146, lr = 0.0001\n",
            "2025-05-01 20:02:14 INFO     Epoch 29 [0/781]: loss = 3.052793264389038, lr = 0.0001\n",
            "2025-05-01 20:02:27 INFO     Epoch 29 [50/781]: loss = 2.97788143157959, lr = 0.0001\n",
            "2025-05-01 20:02:41 INFO     Epoch 29 [100/781]: loss = 2.832911252975464, lr = 0.0001\n",
            "2025-05-01 20:02:55 INFO     Epoch 29 [150/781]: loss = 3.098881721496582, lr = 0.0001\n",
            "2025-05-01 20:03:08 INFO     Epoch 29 [200/781]: loss = 3.0241098403930664, lr = 0.0001\n",
            "2025-05-01 20:03:22 INFO     Epoch 29 [250/781]: loss = 3.048800230026245, lr = 0.0001\n",
            "2025-05-01 20:03:35 INFO     Epoch 29 [300/781]: loss = 2.9806272983551025, lr = 0.0001\n",
            "2025-05-01 20:03:49 INFO     Epoch 29 [350/781]: loss = 3.5450003147125244, lr = 0.0001\n",
            "2025-05-01 20:04:03 INFO     Epoch 29 [400/781]: loss = 3.3668057918548584, lr = 0.0001\n",
            "2025-05-01 20:04:16 INFO     Epoch 29 [450/781]: loss = 3.02020525932312, lr = 0.0001\n",
            "2025-05-01 20:04:30 INFO     Epoch 29 [500/781]: loss = 3.03678822517395, lr = 0.0001\n",
            "2025-05-01 20:04:44 INFO     Epoch 29 [550/781]: loss = 3.4695894718170166, lr = 0.0001\n",
            "2025-05-01 20:04:57 INFO     Epoch 29 [600/781]: loss = 3.0538647174835205, lr = 0.0001\n",
            "2025-05-01 20:05:11 INFO     Epoch 29 [650/781]: loss = 3.322786569595337, lr = 0.0001\n",
            "2025-05-01 20:05:25 INFO     Epoch 29 [700/781]: loss = 3.2472598552703857, lr = 0.0001\n",
            "2025-05-01 20:05:38 INFO     Epoch 29 [750/781]: loss = 3.6073150634765625, lr = 0.0001\n",
            "2025-05-01 20:05:48 INFO     Epoch 30 [0/781]: loss = 3.1518361568450928, lr = 0.0001\n",
            "2025-05-01 20:06:01 INFO     Epoch 30 [50/781]: loss = 3.469310998916626, lr = 0.0001\n",
            "2025-05-01 20:06:15 INFO     Epoch 30 [100/781]: loss = 3.20644211769104, lr = 0.0001\n",
            "2025-05-01 20:06:28 INFO     Epoch 30 [150/781]: loss = 3.1439380645751953, lr = 0.0001\n",
            "2025-05-01 20:06:42 INFO     Epoch 30 [200/781]: loss = 3.1502647399902344, lr = 0.0001\n",
            "2025-05-01 20:06:56 INFO     Epoch 30 [250/781]: loss = 3.2125470638275146, lr = 0.0001\n",
            "2025-05-01 20:07:09 INFO     Epoch 30 [300/781]: loss = 3.283499002456665, lr = 0.0001\n",
            "2025-05-01 20:07:23 INFO     Epoch 30 [350/781]: loss = 3.339773416519165, lr = 0.0001\n",
            "2025-05-01 20:07:37 INFO     Epoch 30 [400/781]: loss = 3.2146730422973633, lr = 0.0001\n",
            "2025-05-01 20:07:50 INFO     Epoch 30 [450/781]: loss = 3.3413753509521484, lr = 0.0001\n",
            "2025-05-01 20:08:04 INFO     Epoch 30 [500/781]: loss = 3.172057867050171, lr = 0.0001\n",
            "2025-05-01 20:08:17 INFO     Epoch 30 [550/781]: loss = 3.2152812480926514, lr = 0.0001\n",
            "2025-05-01 20:08:31 INFO     Epoch 30 [600/781]: loss = 3.1179749965667725, lr = 0.0001\n",
            "2025-05-01 20:08:45 INFO     Epoch 30 [650/781]: loss = 3.133464813232422, lr = 0.0001\n",
            "2025-05-01 20:08:58 INFO     Epoch 30 [700/781]: loss = 3.2101221084594727, lr = 0.0001\n",
            "2025-05-01 20:09:12 INFO     Epoch 30 [750/781]: loss = 3.2428996562957764, lr = 0.0001\n",
            "2025-05-01 20:09:21 INFO     Epoch 31 [0/781]: loss = 3.1394174098968506, lr = 0.0001\n",
            "2025-05-01 20:09:35 INFO     Epoch 31 [50/781]: loss = 3.2573587894439697, lr = 0.0001\n",
            "2025-05-01 20:09:49 INFO     Epoch 31 [100/781]: loss = 3.382277727127075, lr = 0.0001\n",
            "2025-05-01 20:10:02 INFO     Epoch 31 [150/781]: loss = 3.26837158203125, lr = 0.0001\n",
            "2025-05-01 20:10:16 INFO     Epoch 31 [200/781]: loss = 3.0027637481689453, lr = 0.0001\n",
            "2025-05-01 20:10:30 INFO     Epoch 31 [250/781]: loss = 3.2366342544555664, lr = 0.0001\n",
            "2025-05-01 20:10:43 INFO     Epoch 31 [300/781]: loss = 3.121981620788574, lr = 0.0001\n",
            "2025-05-01 20:10:57 INFO     Epoch 31 [350/781]: loss = 3.1661465167999268, lr = 0.0001\n",
            "2025-05-01 20:11:10 INFO     Epoch 31 [400/781]: loss = 3.1252667903900146, lr = 0.0001\n",
            "2025-05-01 20:11:24 INFO     Epoch 31 [450/781]: loss = 3.326669692993164, lr = 0.0001\n",
            "2025-05-01 20:11:38 INFO     Epoch 31 [500/781]: loss = 2.9865427017211914, lr = 0.0001\n",
            "2025-05-01 20:11:51 INFO     Epoch 31 [550/781]: loss = 3.2656142711639404, lr = 0.0001\n",
            "2025-05-01 20:12:05 INFO     Epoch 31 [600/781]: loss = 3.222081184387207, lr = 0.0001\n",
            "2025-05-01 20:12:19 INFO     Epoch 31 [650/781]: loss = 3.084853410720825, lr = 0.0001\n",
            "2025-05-01 20:12:32 INFO     Epoch 31 [700/781]: loss = 3.089520215988159, lr = 0.0001\n",
            "2025-05-01 20:12:46 INFO     Epoch 31 [750/781]: loss = 3.6494057178497314, lr = 0.0001\n",
            "2025-05-01 20:12:55 INFO     Epoch 32 [0/781]: loss = 3.087913751602173, lr = 0.0001\n",
            "2025-05-01 20:13:09 INFO     Epoch 32 [50/781]: loss = 3.3542048931121826, lr = 0.0001\n",
            "2025-05-01 20:13:22 INFO     Epoch 32 [100/781]: loss = 3.3035390377044678, lr = 0.0001\n",
            "2025-05-01 20:13:36 INFO     Epoch 32 [150/781]: loss = 3.095607042312622, lr = 0.0001\n",
            "2025-05-01 20:13:50 INFO     Epoch 32 [200/781]: loss = 3.486222505569458, lr = 0.0001\n",
            "2025-05-01 20:14:03 INFO     Epoch 32 [250/781]: loss = 3.621232032775879, lr = 0.0001\n",
            "2025-05-01 20:14:17 INFO     Epoch 32 [300/781]: loss = 3.0299932956695557, lr = 0.0001\n",
            "2025-05-01 20:14:31 INFO     Epoch 32 [350/781]: loss = 3.210026741027832, lr = 0.0001\n",
            "2025-05-01 20:14:44 INFO     Epoch 32 [400/781]: loss = 3.186378240585327, lr = 0.0001\n",
            "2025-05-01 20:14:58 INFO     Epoch 32 [450/781]: loss = 3.568531036376953, lr = 0.0001\n",
            "2025-05-01 20:15:11 INFO     Epoch 32 [500/781]: loss = 3.099543333053589, lr = 0.0001\n",
            "2025-05-01 20:15:25 INFO     Epoch 32 [550/781]: loss = 3.2215378284454346, lr = 0.0001\n",
            "2025-05-01 20:15:39 INFO     Epoch 32 [600/781]: loss = 3.642235517501831, lr = 0.0001\n",
            "2025-05-01 20:15:52 INFO     Epoch 32 [650/781]: loss = 3.1702191829681396, lr = 0.0001\n",
            "2025-05-01 20:16:06 INFO     Epoch 32 [700/781]: loss = 3.474949598312378, lr = 0.0001\n",
            "2025-05-01 20:16:20 INFO     Epoch 32 [750/781]: loss = 3.5110580921173096, lr = 0.0001\n",
            "2025-05-01 20:16:29 INFO     Epoch 33 [0/781]: loss = 2.9658586978912354, lr = 0.0001\n",
            "2025-05-01 20:16:43 INFO     Epoch 33 [50/781]: loss = 3.51678466796875, lr = 0.0001\n",
            "2025-05-01 20:16:56 INFO     Epoch 33 [100/781]: loss = 3.203518867492676, lr = 0.0001\n",
            "2025-05-01 20:17:10 INFO     Epoch 33 [150/781]: loss = 3.307974100112915, lr = 0.0001\n",
            "2025-05-01 20:17:23 INFO     Epoch 33 [200/781]: loss = 3.4440271854400635, lr = 0.0001\n",
            "2025-05-01 20:17:37 INFO     Epoch 33 [250/781]: loss = 3.130772829055786, lr = 0.0001\n",
            "2025-05-01 20:17:51 INFO     Epoch 33 [300/781]: loss = 3.2922887802124023, lr = 0.0001\n",
            "2025-05-01 20:18:04 INFO     Epoch 33 [350/781]: loss = 3.432027578353882, lr = 0.0001\n",
            "2025-05-01 20:18:18 INFO     Epoch 33 [400/781]: loss = 3.311410665512085, lr = 0.0001\n",
            "2025-05-01 20:18:31 INFO     Epoch 33 [450/781]: loss = 2.7485883235931396, lr = 0.0001\n",
            "2025-05-01 20:18:45 INFO     Epoch 33 [500/781]: loss = 3.1391947269439697, lr = 0.0001\n",
            "2025-05-01 20:18:59 INFO     Epoch 33 [550/781]: loss = 3.3173084259033203, lr = 0.0001\n",
            "2025-05-01 20:19:12 INFO     Epoch 33 [600/781]: loss = 3.462341547012329, lr = 0.0001\n",
            "2025-05-01 20:19:26 INFO     Epoch 33 [650/781]: loss = 3.498126745223999, lr = 0.0001\n",
            "2025-05-01 20:19:40 INFO     Epoch 33 [700/781]: loss = 3.069153070449829, lr = 0.0001\n",
            "2025-05-01 20:19:53 INFO     Epoch 33 [750/781]: loss = 3.685589551925659, lr = 0.0001\n",
            "2025-05-01 20:20:03 INFO     Epoch 34 [0/781]: loss = 3.1366634368896484, lr = 0.0001\n",
            "2025-05-01 20:20:16 INFO     Epoch 34 [50/781]: loss = 3.0475337505340576, lr = 0.0001\n",
            "2025-05-01 20:20:30 INFO     Epoch 34 [100/781]: loss = 3.1835250854492188, lr = 0.0001\n",
            "2025-05-01 20:20:44 INFO     Epoch 34 [150/781]: loss = 3.313192129135132, lr = 0.0001\n",
            "2025-05-01 20:20:57 INFO     Epoch 34 [200/781]: loss = 3.5614511966705322, lr = 0.0001\n",
            "2025-05-01 20:21:11 INFO     Epoch 34 [250/781]: loss = 3.1852033138275146, lr = 0.0001\n",
            "2025-05-01 20:21:25 INFO     Epoch 34 [300/781]: loss = 3.12178635597229, lr = 0.0001\n",
            "2025-05-01 20:21:38 INFO     Epoch 34 [350/781]: loss = 3.450147867202759, lr = 0.0001\n",
            "2025-05-01 20:21:52 INFO     Epoch 34 [400/781]: loss = 3.1574904918670654, lr = 0.0001\n",
            "2025-05-01 20:22:05 INFO     Epoch 34 [450/781]: loss = 3.0369346141815186, lr = 0.0001\n",
            "2025-05-01 20:22:19 INFO     Epoch 34 [500/781]: loss = 3.447389841079712, lr = 0.0001\n",
            "2025-05-01 20:22:33 INFO     Epoch 34 [550/781]: loss = 3.3094966411590576, lr = 0.0001\n",
            "2025-05-01 20:22:46 INFO     Epoch 34 [600/781]: loss = 3.3125295639038086, lr = 0.0001\n",
            "2025-05-01 20:23:00 INFO     Epoch 34 [650/781]: loss = 3.2280194759368896, lr = 0.0001\n",
            "2025-05-01 20:23:14 INFO     Epoch 34 [700/781]: loss = 3.1104862689971924, lr = 0.0001\n",
            "2025-05-01 20:23:27 INFO     Epoch 34 [750/781]: loss = 3.0836737155914307, lr = 0.0001\n",
            "2025-05-01 20:23:37 INFO     Epoch 35 [0/781]: loss = 2.7474215030670166, lr = 0.0001\n",
            "2025-05-01 20:23:50 INFO     Epoch 35 [50/781]: loss = 3.2511909008026123, lr = 0.0001\n",
            "2025-05-01 20:24:04 INFO     Epoch 35 [100/781]: loss = 3.4857680797576904, lr = 0.0001\n",
            "2025-05-01 20:24:18 INFO     Epoch 35 [150/781]: loss = 3.1156368255615234, lr = 0.0001\n",
            "2025-05-01 20:24:31 INFO     Epoch 35 [200/781]: loss = 2.930710792541504, lr = 0.0001\n",
            "2025-05-01 20:24:45 INFO     Epoch 35 [250/781]: loss = 3.4698798656463623, lr = 0.0001\n",
            "2025-05-01 20:24:58 INFO     Epoch 35 [300/781]: loss = 2.977532148361206, lr = 0.0001\n",
            "2025-05-01 20:25:12 INFO     Epoch 35 [350/781]: loss = 3.3013784885406494, lr = 0.0001\n",
            "2025-05-01 20:25:26 INFO     Epoch 35 [400/781]: loss = 3.487546682357788, lr = 0.0001\n",
            "2025-05-01 20:25:39 INFO     Epoch 35 [450/781]: loss = 2.756429433822632, lr = 0.0001\n",
            "2025-05-01 20:25:53 INFO     Epoch 35 [500/781]: loss = 3.248899221420288, lr = 0.0001\n",
            "2025-05-01 20:26:07 INFO     Epoch 35 [550/781]: loss = 3.2190868854522705, lr = 0.0001\n",
            "2025-05-01 20:26:20 INFO     Epoch 35 [600/781]: loss = 3.1782329082489014, lr = 0.0001\n",
            "2025-05-01 20:26:34 INFO     Epoch 35 [650/781]: loss = 3.3469173908233643, lr = 0.0001\n",
            "2025-05-01 20:26:47 INFO     Epoch 35 [700/781]: loss = 3.612917184829712, lr = 0.0001\n",
            "2025-05-01 20:27:01 INFO     Epoch 35 [750/781]: loss = 2.940922975540161, lr = 0.0001\n",
            "2025-05-01 20:27:10 INFO     Epoch 36 [0/781]: loss = 3.276768922805786, lr = 0.0001\n",
            "2025-05-01 20:27:24 INFO     Epoch 36 [50/781]: loss = 3.2320339679718018, lr = 0.0001\n",
            "2025-05-01 20:27:37 INFO     Epoch 36 [100/781]: loss = 3.1983816623687744, lr = 0.0001\n",
            "2025-05-01 20:27:51 INFO     Epoch 36 [150/781]: loss = 3.3733327388763428, lr = 0.0001\n",
            "2025-05-01 20:28:05 INFO     Epoch 36 [200/781]: loss = 3.3334553241729736, lr = 0.0001\n",
            "2025-05-01 20:28:18 INFO     Epoch 36 [250/781]: loss = 3.2423856258392334, lr = 0.0001\n",
            "2025-05-01 20:28:32 INFO     Epoch 36 [300/781]: loss = 2.9827048778533936, lr = 0.0001\n",
            "2025-05-01 20:28:46 INFO     Epoch 36 [350/781]: loss = 3.2988786697387695, lr = 0.0001\n",
            "2025-05-01 20:28:59 INFO     Epoch 36 [400/781]: loss = 2.892178773880005, lr = 0.0001\n",
            "2025-05-01 20:29:13 INFO     Epoch 36 [450/781]: loss = 3.082517623901367, lr = 0.0001\n",
            "2025-05-01 20:29:27 INFO     Epoch 36 [500/781]: loss = 3.756859540939331, lr = 0.0001\n",
            "2025-05-01 20:29:40 INFO     Epoch 36 [550/781]: loss = 3.1125810146331787, lr = 0.0001\n",
            "2025-05-01 20:29:54 INFO     Epoch 36 [600/781]: loss = 3.3193788528442383, lr = 0.0001\n",
            "2025-05-01 20:30:08 INFO     Epoch 36 [650/781]: loss = 3.219560384750366, lr = 0.0001\n",
            "2025-05-01 20:30:21 INFO     Epoch 36 [700/781]: loss = 3.5054874420166016, lr = 0.0001\n",
            "2025-05-01 20:30:35 INFO     Epoch 36 [750/781]: loss = 3.2217836380004883, lr = 0.0001\n",
            "2025-05-01 20:30:44 INFO     Epoch 37 [0/781]: loss = 3.2239701747894287, lr = 0.0001\n",
            "2025-05-01 20:30:58 INFO     Epoch 37 [50/781]: loss = 3.023827314376831, lr = 0.0001\n",
            "2025-05-01 20:31:12 INFO     Epoch 37 [100/781]: loss = 3.0866806507110596, lr = 0.0001\n",
            "2025-05-01 20:31:25 INFO     Epoch 37 [150/781]: loss = 3.0651633739471436, lr = 0.0001\n",
            "2025-05-01 20:31:39 INFO     Epoch 37 [200/781]: loss = 3.4689102172851562, lr = 0.0001\n",
            "2025-05-01 20:31:53 INFO     Epoch 37 [250/781]: loss = 3.034374237060547, lr = 0.0001\n",
            "2025-05-01 20:32:06 INFO     Epoch 37 [300/781]: loss = 3.026913642883301, lr = 0.0001\n",
            "2025-05-01 20:32:20 INFO     Epoch 37 [350/781]: loss = 3.1415443420410156, lr = 0.0001\n",
            "2025-05-01 20:32:34 INFO     Epoch 37 [400/781]: loss = 3.1433842182159424, lr = 0.0001\n",
            "2025-05-01 20:32:47 INFO     Epoch 37 [450/781]: loss = 3.4260129928588867, lr = 0.0001\n",
            "2025-05-01 20:33:01 INFO     Epoch 37 [500/781]: loss = 3.3426096439361572, lr = 0.0001\n",
            "2025-05-01 20:33:14 INFO     Epoch 37 [550/781]: loss = 3.3525238037109375, lr = 0.0001\n",
            "2025-05-01 20:33:28 INFO     Epoch 37 [600/781]: loss = 3.341662645339966, lr = 0.0001\n",
            "2025-05-01 20:33:42 INFO     Epoch 37 [650/781]: loss = 2.8780834674835205, lr = 0.0001\n",
            "2025-05-01 20:33:55 INFO     Epoch 37 [700/781]: loss = 3.1690642833709717, lr = 0.0001\n",
            "2025-05-01 20:34:09 INFO     Epoch 37 [750/781]: loss = 3.1705033779144287, lr = 0.0001\n",
            "2025-05-01 20:34:18 INFO     Epoch 38 [0/781]: loss = 3.489583730697632, lr = 0.0001\n",
            "2025-05-01 20:34:32 INFO     Epoch 38 [50/781]: loss = 3.4011905193328857, lr = 0.0001\n",
            "2025-05-01 20:34:45 INFO     Epoch 38 [100/781]: loss = 2.801950454711914, lr = 0.0001\n",
            "2025-05-01 20:34:59 INFO     Epoch 38 [150/781]: loss = 3.3240177631378174, lr = 0.0001\n",
            "2025-05-01 20:35:13 INFO     Epoch 38 [200/781]: loss = 3.2076568603515625, lr = 0.0001\n",
            "2025-05-01 20:35:26 INFO     Epoch 38 [250/781]: loss = 3.3201677799224854, lr = 0.0001\n",
            "2025-05-01 20:35:40 INFO     Epoch 38 [300/781]: loss = 3.4582414627075195, lr = 0.0001\n",
            "2025-05-01 20:35:54 INFO     Epoch 38 [350/781]: loss = 3.375755548477173, lr = 0.0001\n",
            "2025-05-01 20:36:07 INFO     Epoch 38 [400/781]: loss = 3.3961973190307617, lr = 0.0001\n",
            "2025-05-01 20:36:21 INFO     Epoch 38 [450/781]: loss = 3.192707061767578, lr = 0.0001\n",
            "2025-05-01 20:36:34 INFO     Epoch 38 [500/781]: loss = 2.901850938796997, lr = 0.0001\n",
            "2025-05-01 20:36:48 INFO     Epoch 38 [550/781]: loss = 3.1822221279144287, lr = 0.0001\n",
            "2025-05-01 20:37:02 INFO     Epoch 38 [600/781]: loss = 3.044053077697754, lr = 0.0001\n",
            "2025-05-01 20:37:15 INFO     Epoch 38 [650/781]: loss = 3.0028154850006104, lr = 0.0001\n",
            "2025-05-01 20:37:29 INFO     Epoch 38 [700/781]: loss = 3.1618356704711914, lr = 0.0001\n",
            "2025-05-01 20:37:43 INFO     Epoch 38 [750/781]: loss = 3.4267361164093018, lr = 0.0001\n",
            "2025-05-01 20:37:52 INFO     Epoch 39 [0/781]: loss = 3.0411384105682373, lr = 0.0001\n",
            "2025-05-01 20:38:05 INFO     Epoch 39 [50/781]: loss = 3.156475067138672, lr = 0.0001\n",
            "2025-05-01 20:38:19 INFO     Epoch 39 [100/781]: loss = 3.2901229858398438, lr = 0.0001\n",
            "2025-05-01 20:38:33 INFO     Epoch 39 [150/781]: loss = 3.1995303630828857, lr = 0.0001\n",
            "2025-05-01 20:38:46 INFO     Epoch 39 [200/781]: loss = 3.054901361465454, lr = 0.0001\n",
            "2025-05-01 20:39:00 INFO     Epoch 39 [250/781]: loss = 3.292546272277832, lr = 0.0001\n",
            "2025-05-01 20:39:14 INFO     Epoch 39 [300/781]: loss = 3.0586302280426025, lr = 0.0001\n",
            "2025-05-01 20:39:27 INFO     Epoch 39 [350/781]: loss = 3.1732289791107178, lr = 0.0001\n",
            "2025-05-01 20:39:41 INFO     Epoch 39 [400/781]: loss = 3.3315913677215576, lr = 0.0001\n",
            "2025-05-01 20:39:55 INFO     Epoch 39 [450/781]: loss = 3.3552677631378174, lr = 0.0001\n",
            "2025-05-01 20:40:08 INFO     Epoch 39 [500/781]: loss = 3.2446229457855225, lr = 0.0001\n",
            "2025-05-01 20:40:22 INFO     Epoch 39 [550/781]: loss = 3.271394729614258, lr = 0.0001\n",
            "2025-05-01 20:40:35 INFO     Epoch 39 [600/781]: loss = 3.1810779571533203, lr = 0.0001\n",
            "2025-05-01 20:40:49 INFO     Epoch 39 [650/781]: loss = 2.8989360332489014, lr = 0.0001\n",
            "2025-05-01 20:41:03 INFO     Epoch 39 [700/781]: loss = 3.3228814601898193, lr = 0.0001\n",
            "2025-05-01 20:41:16 INFO     Epoch 39 [750/781]: loss = 3.5120153427124023, lr = 0.0001\n",
            "2025-05-01 20:41:26 INFO     Epoch 40 [0/781]: loss = 2.9222829341888428, lr = 0.0001\n",
            "2025-05-01 20:41:39 INFO     Epoch 40 [50/781]: loss = 3.2673845291137695, lr = 0.0001\n",
            "2025-05-01 20:41:53 INFO     Epoch 40 [100/781]: loss = 3.3392179012298584, lr = 0.0001\n",
            "2025-05-01 20:42:06 INFO     Epoch 40 [150/781]: loss = 3.048557996749878, lr = 0.0001\n",
            "2025-05-01 20:42:20 INFO     Epoch 40 [200/781]: loss = 3.526418685913086, lr = 0.0001\n",
            "2025-05-01 20:42:34 INFO     Epoch 40 [250/781]: loss = 3.4890384674072266, lr = 0.0001\n",
            "2025-05-01 20:42:47 INFO     Epoch 40 [300/781]: loss = 3.419891119003296, lr = 0.0001\n",
            "2025-05-01 20:43:01 INFO     Epoch 40 [350/781]: loss = 3.078291893005371, lr = 0.0001\n",
            "2025-05-01 20:43:14 INFO     Epoch 40 [400/781]: loss = 3.3719723224639893, lr = 0.0001\n",
            "2025-05-01 20:43:28 INFO     Epoch 40 [450/781]: loss = 3.146615982055664, lr = 0.0001\n",
            "2025-05-01 20:43:42 INFO     Epoch 40 [500/781]: loss = 3.3103420734405518, lr = 0.0001\n",
            "2025-05-01 20:43:55 INFO     Epoch 40 [550/781]: loss = 3.2608258724212646, lr = 0.0001\n",
            "2025-05-01 20:44:09 INFO     Epoch 40 [600/781]: loss = 3.1879968643188477, lr = 0.0001\n",
            "2025-05-01 20:44:23 INFO     Epoch 40 [650/781]: loss = 2.8603155612945557, lr = 0.0001\n",
            "2025-05-01 20:44:36 INFO     Epoch 40 [700/781]: loss = 3.3462610244750977, lr = 0.0001\n",
            "2025-05-01 20:44:50 INFO     Epoch 40 [750/781]: loss = 3.6025102138519287, lr = 0.0001\n",
            "2025-05-01 20:44:59 INFO     Epoch 41 [0/781]: loss = 3.04524827003479, lr = 0.0001\n",
            "2025-05-01 20:45:13 INFO     Epoch 41 [50/781]: loss = 3.141979217529297, lr = 0.0001\n",
            "2025-05-01 20:45:27 INFO     Epoch 41 [100/781]: loss = 3.514828681945801, lr = 0.0001\n",
            "2025-05-01 20:45:40 INFO     Epoch 41 [150/781]: loss = 3.252615213394165, lr = 0.0001\n",
            "2025-05-01 20:45:54 INFO     Epoch 41 [200/781]: loss = 3.005354642868042, lr = 0.0001\n",
            "2025-05-01 20:46:07 INFO     Epoch 41 [250/781]: loss = 3.147876024246216, lr = 0.0001\n",
            "2025-05-01 20:46:21 INFO     Epoch 41 [300/781]: loss = 3.107522964477539, lr = 0.0001\n",
            "2025-05-01 20:46:35 INFO     Epoch 41 [350/781]: loss = 3.136817693710327, lr = 0.0001\n",
            "2025-05-01 20:46:48 INFO     Epoch 41 [400/781]: loss = 3.2258150577545166, lr = 0.0001\n",
            "2025-05-01 20:47:02 INFO     Epoch 41 [450/781]: loss = 2.9783031940460205, lr = 0.0001\n",
            "2025-05-01 20:47:16 INFO     Epoch 41 [500/781]: loss = 3.1465377807617188, lr = 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset cifar10 --output_dir output_cifar10 --batch_size 64 --accum_iter=1 --eval_frequency=100 --epochs=3000 --class_drop_prob=1.0 --cfg_scale=0.0 --compute_fid --ode_method heun2 --ode_options '{\"nfe\": 50}' --use_ema --edm_schedule --skewed_timesteps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JvqNqDftWtS",
        "outputId": "02975d3f-6d60-49a2-80a4-5d3e43f7fe92"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not using distributed mode\n",
            "2025-04-17 08:53:07 INFO     job dir: /content/flow_matching/examples/image\n",
            "2025-04-17 08:53:07 INFO     Namespace(batch_size=64,\n",
            "epochs=3000,\n",
            "accum_iter=1,\n",
            "lr=0.0001,\n",
            "optimizer_betas=[0.9,\n",
            "0.95],\n",
            "decay_lr=False,\n",
            "class_drop_prob=1.0,\n",
            "skewed_timesteps=True,\n",
            "edm_schedule=True,\n",
            "use_ema=True,\n",
            "dataset='cifar10',\n",
            "data_path='./data/image_generation',\n",
            "output_dir='output_cifar10',\n",
            "ode_method='heun2',\n",
            "ode_options={'nfe': 50},\n",
            "sym=0.0,\n",
            "temp=1.0,\n",
            "sym_func=False,\n",
            "sampling_dtype='float32',\n",
            "cfg_scale=0.0,\n",
            "fid_samples=50000,\n",
            "device='cuda',\n",
            "seed=0,\n",
            "resume='',\n",
            "start_epoch=0,\n",
            "eval_only=False,\n",
            "eval_frequency=100,\n",
            "compute_fid=True,\n",
            "save_fid_samples=False,\n",
            "num_workers=10,\n",
            "pin_mem=True,\n",
            "world_size=1,\n",
            "local_rank=-1,\n",
            "dist_on_itp=False,\n",
            "dist_url='env://',\n",
            "test_run=False,\n",
            "discrete_flow_matching=False,\n",
            "discrete_fm_steps=1024,\n",
            "distributed=False)\n",
            "2025-04-17 08:53:07 INFO     Saving args to output_cifar10/args.json\n",
            "2025-04-17 08:53:07 INFO     Initializing Dataset: cifar10\n",
            "100% 170M/170M [00:04<00:00, 41.0MB/s]\n",
            "2025-04-17 08:53:14 INFO     Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data/image_generation\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 RandomHorizontalFlip(p=0.5)\n",
            "                 ToDtype(scale=True)\n",
            "           )\n",
            "2025-04-17 08:53:14 INFO     Intializing DataLoader\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2025-04-17 08:53:14 INFO     <torch.utils.data.distributed.DistributedSampler object at 0x7bc46a52b410>\n",
            "2025-04-17 08:53:14 INFO     Initializing Model\n",
            "2025-04-17 08:53:15 INFO     EMA(\n",
            "  (model): UNetModel(in_channels=3, model_channels=128, out_channels=3, num_res_blocks=4, attention_resolutions=[2], dropout=0.3, channel_mult=[2, 2, 2], conv_resample=False, dims=2, num_classes=None, use_checkpoint=False, num_heads=1, num_head_channels=-1, num_heads_upsample=1, use_scale_shift_norm=True, resblock_updown=False, use_new_attention_order=True, with_fourier_features=False, ignore_time=False, input_projection=True, image_size=-1, _target_='lib.models.gd_unet.UNetModel')\n",
            "  (shadow_params): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 512x128 (cuda:0)]\n",
            "      (1): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (2): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (3): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (4): Parameter containing: [torch.float32 of size 256x3x3x3 (cuda:0)]\n",
            "      (5): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (6): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (7): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (8): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (9): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (10): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (11): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (12): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (13): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (14): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (15): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (16): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (17): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (18): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (19): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (20): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (21): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (22): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (23): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (24): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (25): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (26): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (27): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (28): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (29): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (30): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (31): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (32): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (33): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (34): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (35): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (36): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (37): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (38): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (39): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (40): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (41): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (42): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (43): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (44): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (45): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (46): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (47): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (48): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (49): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (50): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (51): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (52): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (53): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (54): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (55): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (56): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (57): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (58): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (59): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (60): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (61): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (62): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (63): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (64): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (65): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (66): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (67): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (68): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (69): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (70): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (71): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (72): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (73): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (74): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (75): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (76): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (77): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (78): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (79): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (80): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (81): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (82): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (83): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (84): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (85): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (86): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (87): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (88): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (89): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (90): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (91): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (92): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (93): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (94): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (95): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (96): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (97): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (98): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (99): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (100): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (101): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (102): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (103): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (104): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (105): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (106): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (107): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (108): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (109): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (110): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (111): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (112): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (113): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (114): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (115): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (116): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (117): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (118): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (119): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (120): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (121): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (122): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (123): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (124): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (125): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (126): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (127): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (128): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (129): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (130): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (131): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (132): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (133): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (134): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (135): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (136): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (137): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (138): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (139): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (140): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (141): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (142): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (143): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (144): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (145): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (146): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (147): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (148): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (149): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (150): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (151): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (152): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (153): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (154): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (155): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (156): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (157): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (158): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (159): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (160): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (161): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (162): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (163): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (164): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (165): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (166): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (167): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (168): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (169): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (170): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (171): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (172): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (173): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (174): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (175): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (176): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (177): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (178): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (179): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (180): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (181): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (182): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (183): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (184): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (185): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (186): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (187): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (188): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (189): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (190): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (191): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (192): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (193): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (194): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (195): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (196): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (197): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (198): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (199): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (200): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (201): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (202): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (203): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (204): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (205): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (206): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (207): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (208): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (209): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (210): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (211): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (212): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (213): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (214): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (215): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (216): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (217): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (218): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (219): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (220): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (221): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (222): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (223): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (224): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (225): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (226): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (227): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (228): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (229): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (230): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (231): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (232): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (233): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (234): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (235): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (236): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (237): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (238): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (239): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (240): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (241): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (242): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (243): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (244): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (245): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (246): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (247): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (248): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (249): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (250): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (251): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (252): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (253): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (254): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (255): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (256): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (257): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (258): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (259): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (260): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (261): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (262): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (263): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (264): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (265): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (266): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (267): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (268): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (269): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (270): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (271): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (272): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (273): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (274): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (275): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (276): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (277): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (278): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (279): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (280): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (281): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (282): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (283): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (284): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (285): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (286): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (287): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (288): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (289): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (290): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (291): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (292): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (293): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (294): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (295): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (296): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (297): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (298): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (299): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (300): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (301): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (302): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (303): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (304): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (305): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (306): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (307): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (308): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (309): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (310): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (311): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (312): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (313): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (314): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (315): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (316): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (317): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (318): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (319): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (320): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (321): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (322): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (323): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (324): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (325): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (326): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (327): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (328): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (329): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (330): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (331): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (332): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (333): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (334): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (335): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (336): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (337): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (338): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (339): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (340): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (341): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (342): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (343): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (344): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (345): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (346): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (347): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (348): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (349): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (350): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (351): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (352): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (353): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (354): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (355): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (356): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (357): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (358): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (359): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (360): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (361): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (362): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (363): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (364): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (365): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (366): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (367): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (368): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (369): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (370): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (371): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (372): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (373): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (374): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (375): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (376): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (377): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (378): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (379): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (380): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (381): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (382): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (383): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (384): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (385): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (386): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (387): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (388): Parameter containing: [torch.float32 of size 3x256x3x3 (cuda:0)]\n",
            "      (389): Parameter containing: [torch.float32 of size 3 (cuda:0)]\n",
            "  )\n",
            ")\n",
            "2025-04-17 08:53:15 INFO     Learning rate: 1.00e-04\n",
            "2025-04-17 08:53:15 INFO     Accumulate grad iterations: 1\n",
            "2025-04-17 08:53:15 INFO     Effective batch size: 64\n",
            "2025-04-17 08:53:15 INFO     Optimizer: AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: [0.9, 0.95]\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "2025-04-17 08:53:15 INFO     Learning-Rate Schedule: <torch.optim.lr_scheduler.ConstantLR object at 0x7bc461a04190>\n",
            "/content/flow_matching/examples/image/training/grad_scaler.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self._scaler = torch.cuda.amp.GradScaler()\n",
            "2025-04-17 08:53:15 INFO     Start from 0 to 3000 epochs\n",
            "/content/flow_matching/examples/image/training/train_loop.py:100: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "2025-04-17 08:53:20 INFO     Epoch 0 [0/781]: loss = 1.2690505981445312, lr = 0.0001\n",
            "2025-04-17 08:53:53 INFO     Epoch 0 [50/781]: loss = 0.39588260650634766, lr = 0.0001\n",
            "2025-04-17 08:54:26 INFO     Epoch 0 [100/781]: loss = 0.3167325258255005, lr = 0.0001\n",
            "2025-04-17 08:55:00 INFO     Epoch 0 [150/781]: loss = 0.2574637532234192, lr = 0.0001\n",
            "2025-04-17 08:55:34 INFO     Epoch 0 [200/781]: loss = 0.21366429328918457, lr = 0.0001\n",
            "2025-04-17 08:56:08 INFO     Epoch 0 [250/781]: loss = 0.2729591727256775, lr = 0.0001\n",
            "2025-04-17 08:56:42 INFO     Epoch 0 [300/781]: loss = 0.2141873836517334, lr = 0.0001\n",
            "2025-04-17 08:57:17 INFO     Epoch 0 [350/781]: loss = 0.22606389224529266, lr = 0.0001\n",
            "2025-04-17 08:57:51 INFO     Epoch 0 [400/781]: loss = 0.2152235209941864, lr = 0.0001\n",
            "2025-04-17 08:58:25 INFO     Epoch 0 [450/781]: loss = 0.22886864840984344, lr = 0.0001\n",
            "2025-04-17 08:58:59 INFO     Epoch 0 [500/781]: loss = 0.23081204295158386, lr = 0.0001\n",
            "2025-04-17 08:59:33 INFO     Epoch 0 [550/781]: loss = 0.2134130895137787, lr = 0.0001\n",
            "2025-04-17 09:00:07 INFO     Epoch 0 [600/781]: loss = 0.20946133136749268, lr = 0.0001\n",
            "2025-04-17 09:00:42 INFO     Epoch 0 [650/781]: loss = 0.2337268441915512, lr = 0.0001\n",
            "2025-04-17 09:01:16 INFO     Epoch 0 [700/781]: loss = 0.22273653745651245, lr = 0.0001\n",
            "2025-04-17 09:01:50 INFO     Epoch 0 [750/781]: loss = 0.2008974850177765, lr = 0.0001\n",
            "2025-04-17 09:02:12 INFO     Epoch 1 [0/781]: loss = 0.19051897525787354, lr = 0.0001\n",
            "2025-04-17 09:02:46 INFO     Epoch 1 [50/781]: loss = 0.21678398549556732, lr = 0.0001\n",
            "2025-04-17 09:03:20 INFO     Epoch 1 [100/781]: loss = 0.20141810178756714, lr = 0.0001\n",
            "2025-04-17 09:03:55 INFO     Epoch 1 [150/781]: loss = 0.20764145255088806, lr = 0.0001\n",
            "2025-04-17 09:04:29 INFO     Epoch 1 [200/781]: loss = 0.18706795573234558, lr = 0.0001\n",
            "2025-04-17 09:05:03 INFO     Epoch 1 [250/781]: loss = 0.23258349299430847, lr = 0.0001\n",
            "2025-04-17 09:05:37 INFO     Epoch 1 [300/781]: loss = 0.22095182538032532, lr = 0.0001\n",
            "2025-04-17 09:06:11 INFO     Epoch 1 [350/781]: loss = 0.20588165521621704, lr = 0.0001\n",
            "2025-04-17 09:06:45 INFO     Epoch 1 [400/781]: loss = 0.18197381496429443, lr = 0.0001\n",
            "2025-04-17 09:07:19 INFO     Epoch 1 [450/781]: loss = 0.19729745388031006, lr = 0.0001\n",
            "2025-04-17 09:07:53 INFO     Epoch 1 [500/781]: loss = 0.18707603216171265, lr = 0.0001\n",
            "2025-04-17 09:08:28 INFO     Epoch 1 [550/781]: loss = 0.2105555534362793, lr = 0.0001\n",
            "2025-04-17 09:09:02 INFO     Epoch 1 [600/781]: loss = 0.1953573077917099, lr = 0.0001\n",
            "2025-04-17 09:09:36 INFO     Epoch 1 [650/781]: loss = 0.18791460990905762, lr = 0.0001\n",
            "2025-04-17 09:10:10 INFO     Epoch 1 [700/781]: loss = 0.20253634452819824, lr = 0.0001\n",
            "2025-04-17 09:10:44 INFO     Epoch 1 [750/781]: loss = 0.23993274569511414, lr = 0.0001\n",
            "2025-04-17 09:11:07 INFO     Epoch 2 [0/781]: loss = 0.1836549937725067, lr = 0.0001\n",
            "2025-04-17 09:11:41 INFO     Epoch 2 [50/781]: loss = 0.19532375037670135, lr = 0.0001\n",
            "2025-04-17 09:12:15 INFO     Epoch 2 [100/781]: loss = 0.18377122282981873, lr = 0.0001\n",
            "2025-04-17 09:12:50 INFO     Epoch 2 [150/781]: loss = 0.16717159748077393, lr = 0.0001\n",
            "2025-04-17 09:13:24 INFO     Epoch 2 [200/781]: loss = 0.20628076791763306, lr = 0.0001\n",
            "2025-04-17 09:13:58 INFO     Epoch 2 [250/781]: loss = 0.19085656106472015, lr = 0.0001\n",
            "2025-04-17 09:14:32 INFO     Epoch 2 [300/781]: loss = 0.17578762769699097, lr = 0.0001\n",
            "2025-04-17 09:15:06 INFO     Epoch 2 [350/781]: loss = 0.2072685956954956, lr = 0.0001\n",
            "2025-04-17 09:15:40 INFO     Epoch 2 [400/781]: loss = 0.19337467849254608, lr = 0.0001\n",
            "2025-04-17 09:16:14 INFO     Epoch 2 [450/781]: loss = 0.21467474102973938, lr = 0.0001\n",
            "2025-04-17 09:16:48 INFO     Epoch 2 [500/781]: loss = 0.20417504012584686, lr = 0.0001\n",
            "2025-04-17 09:17:22 INFO     Epoch 2 [550/781]: loss = 0.20916643738746643, lr = 0.0001\n",
            "2025-04-17 09:17:57 INFO     Epoch 2 [600/781]: loss = 0.19796261191368103, lr = 0.0001\n",
            "2025-04-17 09:18:31 INFO     Epoch 2 [650/781]: loss = 0.22070658206939697, lr = 0.0001\n",
            "2025-04-17 09:19:05 INFO     Epoch 2 [700/781]: loss = 0.194630965590477, lr = 0.0001\n",
            "2025-04-17 09:19:39 INFO     Epoch 2 [750/781]: loss = 0.2237108200788498, lr = 0.0001\n",
            "2025-04-17 09:20:01 INFO     Epoch 3 [0/781]: loss = 0.21703355014324188, lr = 0.0001\n",
            "2025-04-17 09:20:35 INFO     Epoch 3 [50/781]: loss = 0.20931218564510345, lr = 0.0001\n",
            "2025-04-17 09:21:09 INFO     Epoch 3 [100/781]: loss = 0.1962609738111496, lr = 0.0001\n",
            "2025-04-17 09:21:43 INFO     Epoch 3 [150/781]: loss = 0.18569374084472656, lr = 0.0001\n",
            "2025-04-17 09:22:17 INFO     Epoch 3 [200/781]: loss = 0.19049876928329468, lr = 0.0001\n",
            "2025-04-17 09:22:51 INFO     Epoch 3 [250/781]: loss = 0.18748316168785095, lr = 0.0001\n",
            "2025-04-17 09:23:25 INFO     Epoch 3 [300/781]: loss = 0.19134342670440674, lr = 0.0001\n",
            "2025-04-17 09:23:59 INFO     Epoch 3 [350/781]: loss = 0.18596872687339783, lr = 0.0001\n",
            "2025-04-17 09:24:34 INFO     Epoch 3 [400/781]: loss = 0.18249867856502533, lr = 0.0001\n",
            "2025-04-17 09:25:08 INFO     Epoch 3 [450/781]: loss = 0.20058941841125488, lr = 0.0001\n",
            "2025-04-17 09:25:42 INFO     Epoch 3 [500/781]: loss = 0.2027120292186737, lr = 0.0001\n",
            "2025-04-17 09:26:16 INFO     Epoch 3 [550/781]: loss = 0.20231735706329346, lr = 0.0001\n",
            "2025-04-17 09:26:50 INFO     Epoch 3 [600/781]: loss = 0.20439958572387695, lr = 0.0001\n",
            "2025-04-17 09:27:24 INFO     Epoch 3 [650/781]: loss = 0.18566159904003143, lr = 0.0001\n",
            "2025-04-17 09:27:58 INFO     Epoch 3 [700/781]: loss = 0.2061748504638672, lr = 0.0001\n",
            "2025-04-17 09:28:32 INFO     Epoch 3 [750/781]: loss = 0.20343220233917236, lr = 0.0001\n",
            "2025-04-17 09:28:55 INFO     Epoch 4 [0/781]: loss = 0.19190876185894012, lr = 0.0001\n",
            "2025-04-17 09:29:29 INFO     Epoch 4 [50/781]: loss = 0.1891046166419983, lr = 0.0001\n",
            "2025-04-17 09:30:03 INFO     Epoch 4 [100/781]: loss = 0.1839616298675537, lr = 0.0001\n",
            "2025-04-17 09:30:37 INFO     Epoch 4 [150/781]: loss = 0.18303261697292328, lr = 0.0001\n",
            "2025-04-17 09:31:11 INFO     Epoch 4 [200/781]: loss = 0.18782281875610352, lr = 0.0001\n",
            "2025-04-17 09:31:45 INFO     Epoch 4 [250/781]: loss = 0.20793776214122772, lr = 0.0001\n",
            "2025-04-17 09:32:19 INFO     Epoch 4 [300/781]: loss = 0.175978422164917, lr = 0.0001\n",
            "2025-04-17 09:32:54 INFO     Epoch 4 [350/781]: loss = 0.1807139366865158, lr = 0.0001\n",
            "2025-04-17 09:33:28 INFO     Epoch 4 [400/781]: loss = 0.19041812419891357, lr = 0.0001\n",
            "2025-04-17 09:34:02 INFO     Epoch 4 [450/781]: loss = 0.16084079444408417, lr = 0.0001\n",
            "2025-04-17 09:34:36 INFO     Epoch 4 [500/781]: loss = 0.20923976600170135, lr = 0.0001\n",
            "2025-04-17 09:35:10 INFO     Epoch 4 [550/781]: loss = 0.19188305735588074, lr = 0.0001\n",
            "2025-04-17 09:35:44 INFO     Epoch 4 [600/781]: loss = 0.18772852420806885, lr = 0.0001\n",
            "2025-04-17 09:36:18 INFO     Epoch 4 [650/781]: loss = 0.19194619357585907, lr = 0.0001\n",
            "2025-04-17 09:36:52 INFO     Epoch 4 [700/781]: loss = 0.18795692920684814, lr = 0.0001\n",
            "2025-04-17 09:37:27 INFO     Epoch 4 [750/781]: loss = 0.191559836268425, lr = 0.0001\n",
            "2025-04-17 09:37:49 INFO     Epoch 5 [0/781]: loss = 0.19172146916389465, lr = 0.0001\n",
            "2025-04-17 09:38:23 INFO     Epoch 5 [50/781]: loss = 0.1819886416196823, lr = 0.0001\n",
            "2025-04-17 09:38:57 INFO     Epoch 5 [100/781]: loss = 0.18365070223808289, lr = 0.0001\n",
            "2025-04-17 09:39:31 INFO     Epoch 5 [150/781]: loss = 0.18155574798583984, lr = 0.0001\n",
            "2025-04-17 09:40:05 INFO     Epoch 5 [200/781]: loss = 0.20613281428813934, lr = 0.0001\n",
            "2025-04-17 09:40:40 INFO     Epoch 5 [250/781]: loss = 0.19818627834320068, lr = 0.0001\n",
            "2025-04-17 09:41:14 INFO     Epoch 5 [300/781]: loss = 0.1705714762210846, lr = 0.0001\n",
            "2025-04-17 09:41:48 INFO     Epoch 5 [350/781]: loss = 0.1712859869003296, lr = 0.0001\n",
            "2025-04-17 09:42:22 INFO     Epoch 5 [400/781]: loss = 0.18512040376663208, lr = 0.0001\n",
            "2025-04-17 09:42:56 INFO     Epoch 5 [450/781]: loss = 0.17423617839813232, lr = 0.0001\n",
            "2025-04-17 09:43:30 INFO     Epoch 5 [500/781]: loss = 0.20096322894096375, lr = 0.0001\n",
            "2025-04-17 09:44:05 INFO     Epoch 5 [550/781]: loss = 0.2231142818927765, lr = 0.0001\n",
            "2025-04-17 09:44:39 INFO     Epoch 5 [600/781]: loss = 0.18500111997127533, lr = 0.0001\n",
            "2025-04-17 09:45:13 INFO     Epoch 5 [650/781]: loss = 0.19109341502189636, lr = 0.0001\n",
            "2025-04-17 09:45:47 INFO     Epoch 5 [700/781]: loss = 0.206669420003891, lr = 0.0001\n",
            "2025-04-17 09:46:21 INFO     Epoch 5 [750/781]: loss = 0.17921707034111023, lr = 0.0001\n",
            "2025-04-17 09:46:43 INFO     Epoch 6 [0/781]: loss = 0.19302301108837128, lr = 0.0001\n",
            "2025-04-17 09:47:18 INFO     Epoch 6 [50/781]: loss = 0.18664507567882538, lr = 0.0001\n",
            "2025-04-17 09:47:52 INFO     Epoch 6 [100/781]: loss = 0.19506633281707764, lr = 0.0001\n",
            "2025-04-17 09:48:26 INFO     Epoch 6 [150/781]: loss = 0.18421494960784912, lr = 0.0001\n",
            "2025-04-17 09:49:00 INFO     Epoch 6 [200/781]: loss = 0.18035152554512024, lr = 0.0001\n",
            "2025-04-17 09:49:34 INFO     Epoch 6 [250/781]: loss = 0.19770073890686035, lr = 0.0001\n",
            "2025-04-17 09:50:08 INFO     Epoch 6 [300/781]: loss = 0.1943836808204651, lr = 0.0001\n",
            "2025-04-17 09:50:42 INFO     Epoch 6 [350/781]: loss = 0.1712065190076828, lr = 0.0001\n",
            "2025-04-17 09:51:16 INFO     Epoch 6 [400/781]: loss = 0.1639152467250824, lr = 0.0001\n",
            "2025-04-17 09:51:50 INFO     Epoch 6 [450/781]: loss = 0.17477063834667206, lr = 0.0001\n",
            "2025-04-17 09:52:24 INFO     Epoch 6 [500/781]: loss = 0.19122302532196045, lr = 0.0001\n",
            "2025-04-17 09:52:58 INFO     Epoch 6 [550/781]: loss = 0.1961708664894104, lr = 0.0001\n",
            "2025-04-17 09:53:32 INFO     Epoch 6 [600/781]: loss = 0.1814488172531128, lr = 0.0001\n",
            "2025-04-17 09:54:06 INFO     Epoch 6 [650/781]: loss = 0.18622741103172302, lr = 0.0001\n",
            "2025-04-17 09:54:40 INFO     Epoch 6 [700/781]: loss = 0.19513118267059326, lr = 0.0001\n",
            "2025-04-17 09:55:14 INFO     Epoch 6 [750/781]: loss = 0.19307929277420044, lr = 0.0001\n",
            "2025-04-17 09:55:36 INFO     Epoch 7 [0/781]: loss = 0.17231541872024536, lr = 0.0001\n",
            "2025-04-17 09:56:10 INFO     Epoch 7 [50/781]: loss = 0.18340007960796356, lr = 0.0001\n",
            "2025-04-17 09:56:44 INFO     Epoch 7 [100/781]: loss = 0.20542728900909424, lr = 0.0001\n",
            "2025-04-17 09:57:18 INFO     Epoch 7 [150/781]: loss = 0.17269472777843475, lr = 0.0001\n",
            "2025-04-17 09:57:52 INFO     Epoch 7 [200/781]: loss = 0.21998058259487152, lr = 0.0001\n",
            "2025-04-17 09:58:26 INFO     Epoch 7 [250/781]: loss = 0.19040118157863617, lr = 0.0001\n",
            "2025-04-17 09:59:00 INFO     Epoch 7 [300/781]: loss = 0.1739916056394577, lr = 0.0001\n",
            "2025-04-17 09:59:34 INFO     Epoch 7 [350/781]: loss = 0.19322258234024048, lr = 0.0001\n",
            "2025-04-17 10:00:09 INFO     Epoch 7 [400/781]: loss = 0.18947991728782654, lr = 0.0001\n",
            "2025-04-17 10:00:43 INFO     Epoch 7 [450/781]: loss = 0.16746798157691956, lr = 0.0001\n",
            "2025-04-17 10:01:17 INFO     Epoch 7 [500/781]: loss = 0.17832587659358978, lr = 0.0001\n",
            "2025-04-17 10:01:51 INFO     Epoch 7 [550/781]: loss = 0.18300525844097137, lr = 0.0001\n",
            "2025-04-17 10:02:25 INFO     Epoch 7 [600/781]: loss = 0.18154005706310272, lr = 0.0001\n",
            "2025-04-17 10:02:59 INFO     Epoch 7 [650/781]: loss = 0.20559941232204437, lr = 0.0001\n",
            "2025-04-17 10:03:33 INFO     Epoch 7 [700/781]: loss = 0.1907215118408203, lr = 0.0001\n",
            "2025-04-17 10:04:07 INFO     Epoch 7 [750/781]: loss = 0.1854335069656372, lr = 0.0001\n",
            "2025-04-17 10:04:29 INFO     Epoch 8 [0/781]: loss = 0.20283488929271698, lr = 0.0001\n",
            "2025-04-17 10:05:03 INFO     Epoch 8 [50/781]: loss = 0.18546846508979797, lr = 0.0001\n",
            "2025-04-17 10:05:37 INFO     Epoch 8 [100/781]: loss = 0.1961940973997116, lr = 0.0001\n",
            "2025-04-17 10:06:11 INFO     Epoch 8 [150/781]: loss = 0.18177299201488495, lr = 0.0001\n",
            "2025-04-17 10:06:44 INFO     Epoch 8 [200/781]: loss = 0.17395305633544922, lr = 0.0001\n",
            "2025-04-17 10:07:18 INFO     Epoch 8 [250/781]: loss = 0.19678586721420288, lr = 0.0001\n",
            "2025-04-17 10:07:52 INFO     Epoch 8 [300/781]: loss = 0.2043527066707611, lr = 0.0001\n",
            "2025-04-17 10:08:26 INFO     Epoch 8 [350/781]: loss = 0.17867235839366913, lr = 0.0001\n",
            "2025-04-17 10:09:00 INFO     Epoch 8 [400/781]: loss = 0.18099266290664673, lr = 0.0001\n",
            "2025-04-17 10:09:34 INFO     Epoch 8 [450/781]: loss = 0.15543508529663086, lr = 0.0001\n",
            "2025-04-17 10:10:08 INFO     Epoch 8 [500/781]: loss = 0.19663546979427338, lr = 0.0001\n",
            "2025-04-17 10:10:42 INFO     Epoch 8 [550/781]: loss = 0.1810828149318695, lr = 0.0001\n",
            "2025-04-17 10:11:15 INFO     Epoch 8 [600/781]: loss = 0.16483554244041443, lr = 0.0001\n",
            "2025-04-17 10:11:49 INFO     Epoch 8 [650/781]: loss = 0.20616072416305542, lr = 0.0001\n",
            "2025-04-17 10:12:23 INFO     Epoch 8 [700/781]: loss = 0.18997815251350403, lr = 0.0001\n",
            "2025-04-17 10:12:57 INFO     Epoch 8 [750/781]: loss = 0.1936555802822113, lr = 0.0001\n",
            "2025-04-17 10:13:19 INFO     Epoch 9 [0/781]: loss = 0.1767980307340622, lr = 0.0001\n",
            "2025-04-17 10:13:53 INFO     Epoch 9 [50/781]: loss = 0.1783907264471054, lr = 0.0001\n",
            "2025-04-17 10:14:27 INFO     Epoch 9 [100/781]: loss = 0.20202267169952393, lr = 0.0001\n",
            "2025-04-17 10:15:01 INFO     Epoch 9 [150/781]: loss = 0.18218904733657837, lr = 0.0001\n",
            "2025-04-17 10:15:35 INFO     Epoch 9 [200/781]: loss = 0.16778044402599335, lr = 0.0001\n",
            "2025-04-17 10:16:09 INFO     Epoch 9 [250/781]: loss = 0.19565360248088837, lr = 0.0001\n",
            "2025-04-17 10:16:43 INFO     Epoch 9 [300/781]: loss = 0.1887447088956833, lr = 0.0001\n",
            "2025-04-17 10:17:16 INFO     Epoch 9 [350/781]: loss = 0.1834096908569336, lr = 0.0001\n",
            "2025-04-17 10:17:50 INFO     Epoch 9 [400/781]: loss = 0.19651281833648682, lr = 0.0001\n",
            "2025-04-17 10:18:24 INFO     Epoch 9 [450/781]: loss = 0.16701172292232513, lr = 0.0001\n",
            "2025-04-17 10:18:58 INFO     Epoch 9 [500/781]: loss = 0.1977374255657196, lr = 0.0001\n",
            "2025-04-17 10:19:32 INFO     Epoch 9 [550/781]: loss = 0.17805258929729462, lr = 0.0001\n",
            "2025-04-17 10:20:06 INFO     Epoch 9 [600/781]: loss = 0.17720097303390503, lr = 0.0001\n",
            "2025-04-17 10:20:40 INFO     Epoch 9 [650/781]: loss = 0.19044332206249237, lr = 0.0001\n",
            "2025-04-17 10:21:14 INFO     Epoch 9 [700/781]: loss = 0.19674187898635864, lr = 0.0001\n",
            "2025-04-17 10:21:48 INFO     Epoch 9 [750/781]: loss = 0.19547538459300995, lr = 0.0001\n",
            "2025-04-17 10:22:10 INFO     Epoch 10 [0/781]: loss = 0.17076699435710907, lr = 0.0001\n",
            "2025-04-17 10:22:44 INFO     Epoch 10 [50/781]: loss = 0.1862916201353073, lr = 0.0001\n",
            "2025-04-17 10:23:18 INFO     Epoch 10 [100/781]: loss = 0.18606525659561157, lr = 0.0001\n",
            "2025-04-17 10:23:52 INFO     Epoch 10 [150/781]: loss = 0.18241676688194275, lr = 0.0001\n",
            "2025-04-17 10:24:26 INFO     Epoch 10 [200/781]: loss = 0.20786850154399872, lr = 0.0001\n",
            "2025-04-17 10:25:01 INFO     Epoch 10 [250/781]: loss = 0.19596070051193237, lr = 0.0001\n",
            "2025-04-17 10:25:35 INFO     Epoch 10 [300/781]: loss = 0.17397837340831757, lr = 0.0001\n",
            "2025-04-17 10:26:09 INFO     Epoch 10 [350/781]: loss = 0.18165133893489838, lr = 0.0001\n",
            "2025-04-17 10:26:43 INFO     Epoch 10 [400/781]: loss = 0.20199429988861084, lr = 0.0001\n",
            "2025-04-17 10:27:17 INFO     Epoch 10 [450/781]: loss = 0.18205194175243378, lr = 0.0001\n",
            "2025-04-17 10:27:51 INFO     Epoch 10 [500/781]: loss = 0.20143213868141174, lr = 0.0001\n",
            "2025-04-17 10:28:26 INFO     Epoch 10 [550/781]: loss = 0.21959921717643738, lr = 0.0001\n",
            "2025-04-17 10:29:00 INFO     Epoch 10 [600/781]: loss = 0.189347505569458, lr = 0.0001\n",
            "2025-04-17 10:29:34 INFO     Epoch 10 [650/781]: loss = 0.19349059462547302, lr = 0.0001\n",
            "2025-04-17 10:30:08 INFO     Epoch 10 [700/781]: loss = 0.1924455612897873, lr = 0.0001\n",
            "2025-04-17 10:30:42 INFO     Epoch 10 [750/781]: loss = 0.18420687317848206, lr = 0.0001\n",
            "2025-04-17 10:31:04 INFO     Epoch 11 [0/781]: loss = 0.1970309466123581, lr = 0.0001\n",
            "2025-04-17 10:31:39 INFO     Epoch 11 [50/781]: loss = 0.19105744361877441, lr = 0.0001\n",
            "2025-04-17 10:32:13 INFO     Epoch 11 [100/781]: loss = 0.1946110725402832, lr = 0.0001\n",
            "2025-04-17 10:32:47 INFO     Epoch 11 [150/781]: loss = 0.20001018047332764, lr = 0.0001\n",
            "2025-04-17 10:33:21 INFO     Epoch 11 [200/781]: loss = 0.18796232342720032, lr = 0.0001\n",
            "2025-04-17 10:33:55 INFO     Epoch 11 [250/781]: loss = 0.20737320184707642, lr = 0.0001\n",
            "2025-04-17 10:34:29 INFO     Epoch 11 [300/781]: loss = 0.17302647233009338, lr = 0.0001\n",
            "2025-04-17 10:35:04 INFO     Epoch 11 [350/781]: loss = 0.20097756385803223, lr = 0.0001\n",
            "2025-04-17 10:35:38 INFO     Epoch 11 [400/781]: loss = 0.18393635749816895, lr = 0.0001\n",
            "2025-04-17 10:36:12 INFO     Epoch 11 [450/781]: loss = 0.1680130958557129, lr = 0.0001\n",
            "2025-04-17 10:36:46 INFO     Epoch 11 [500/781]: loss = 0.1749754548072815, lr = 0.0001\n",
            "2025-04-17 10:37:21 INFO     Epoch 11 [550/781]: loss = 0.2028127759695053, lr = 0.0001\n",
            "2025-04-17 10:37:55 INFO     Epoch 11 [600/781]: loss = 0.18078309297561646, lr = 0.0001\n",
            "2025-04-17 10:38:29 INFO     Epoch 11 [650/781]: loss = 0.19002699851989746, lr = 0.0001\n",
            "2025-04-17 10:39:03 INFO     Epoch 11 [700/781]: loss = 0.18963387608528137, lr = 0.0001\n",
            "2025-04-17 10:39:37 INFO     Epoch 11 [750/781]: loss = 0.19054758548736572, lr = 0.0001\n",
            "2025-04-17 10:39:59 INFO     Epoch 12 [0/781]: loss = 0.18299934267997742, lr = 0.0001\n",
            "2025-04-17 10:40:34 INFO     Epoch 12 [50/781]: loss = 0.19226083159446716, lr = 0.0001\n",
            "2025-04-17 10:41:08 INFO     Epoch 12 [100/781]: loss = 0.18165633082389832, lr = 0.0001\n",
            "2025-04-17 10:41:42 INFO     Epoch 12 [150/781]: loss = 0.19421568512916565, lr = 0.0001\n",
            "2025-04-17 10:42:16 INFO     Epoch 12 [200/781]: loss = 0.1772063672542572, lr = 0.0001\n",
            "2025-04-17 10:42:51 INFO     Epoch 12 [250/781]: loss = 0.17164520919322968, lr = 0.0001\n",
            "2025-04-17 10:43:25 INFO     Epoch 12 [300/781]: loss = 0.17352989315986633, lr = 0.0001\n",
            "2025-04-17 10:43:59 INFO     Epoch 12 [350/781]: loss = 0.16142290830612183, lr = 0.0001\n",
            "2025-04-17 10:44:33 INFO     Epoch 12 [400/781]: loss = 0.1648297756910324, lr = 0.0001\n",
            "2025-04-17 10:45:07 INFO     Epoch 12 [450/781]: loss = 0.17734408378601074, lr = 0.0001\n",
            "2025-04-17 10:45:41 INFO     Epoch 12 [500/781]: loss = 0.17843878269195557, lr = 0.0001\n",
            "2025-04-17 10:46:16 INFO     Epoch 12 [550/781]: loss = 0.21346363425254822, lr = 0.0001\n",
            "2025-04-17 10:46:50 INFO     Epoch 12 [600/781]: loss = 0.16787652671337128, lr = 0.0001\n",
            "2025-04-17 10:47:24 INFO     Epoch 12 [650/781]: loss = 0.20377986133098602, lr = 0.0001\n",
            "2025-04-17 10:47:58 INFO     Epoch 12 [700/781]: loss = 0.19246743619441986, lr = 0.0001\n",
            "2025-04-17 10:48:33 INFO     Epoch 12 [750/781]: loss = 0.18310964107513428, lr = 0.0001\n",
            "2025-04-17 10:48:55 INFO     Epoch 13 [0/781]: loss = 0.18727481365203857, lr = 0.0001\n",
            "2025-04-17 10:49:29 INFO     Epoch 13 [50/781]: loss = 0.20609116554260254, lr = 0.0001\n",
            "2025-04-17 10:50:03 INFO     Epoch 13 [100/781]: loss = 0.15930838882923126, lr = 0.0001\n",
            "2025-04-17 10:50:38 INFO     Epoch 13 [150/781]: loss = 0.1911160945892334, lr = 0.0001\n",
            "2025-04-17 10:51:12 INFO     Epoch 13 [200/781]: loss = 0.1832084357738495, lr = 0.0001\n",
            "2025-04-17 10:51:46 INFO     Epoch 13 [250/781]: loss = 0.2035561203956604, lr = 0.0001\n",
            "2025-04-17 10:52:20 INFO     Epoch 13 [300/781]: loss = 0.17981939017772675, lr = 0.0001\n",
            "2025-04-17 10:52:54 INFO     Epoch 13 [350/781]: loss = 0.18905887007713318, lr = 0.0001\n",
            "2025-04-17 10:53:29 INFO     Epoch 13 [400/781]: loss = 0.15683454275131226, lr = 0.0001\n",
            "2025-04-17 10:54:03 INFO     Epoch 13 [450/781]: loss = 0.17625534534454346, lr = 0.0001\n",
            "2025-04-17 10:54:37 INFO     Epoch 13 [500/781]: loss = 0.18138353526592255, lr = 0.0001\n",
            "2025-04-17 10:55:11 INFO     Epoch 13 [550/781]: loss = 0.19378070533275604, lr = 0.0001\n",
            "2025-04-17 10:55:45 INFO     Epoch 13 [600/781]: loss = 0.18098410964012146, lr = 0.0001\n",
            "2025-04-17 10:56:20 INFO     Epoch 13 [650/781]: loss = 0.19760063290596008, lr = 0.0001\n",
            "2025-04-17 10:56:54 INFO     Epoch 13 [700/781]: loss = 0.1794654130935669, lr = 0.0001\n",
            "2025-04-17 10:57:28 INFO     Epoch 13 [750/781]: loss = 0.18214258551597595, lr = 0.0001\n",
            "2025-04-17 10:57:50 INFO     Epoch 14 [0/781]: loss = 0.18179833889007568, lr = 0.0001\n",
            "2025-04-17 10:58:24 INFO     Epoch 14 [50/781]: loss = 0.18179862201213837, lr = 0.0001\n",
            "2025-04-17 10:58:59 INFO     Epoch 14 [100/781]: loss = 0.17488645017147064, lr = 0.0001\n",
            "2025-04-17 10:59:33 INFO     Epoch 14 [150/781]: loss = 0.18776550889015198, lr = 0.0001\n",
            "2025-04-17 11:00:07 INFO     Epoch 14 [200/781]: loss = 0.18034110963344574, lr = 0.0001\n",
            "2025-04-17 11:00:41 INFO     Epoch 14 [250/781]: loss = 0.20491795241832733, lr = 0.0001\n",
            "2025-04-17 11:01:15 INFO     Epoch 14 [300/781]: loss = 0.17326991260051727, lr = 0.0001\n",
            "2025-04-17 11:01:49 INFO     Epoch 14 [350/781]: loss = 0.1834104061126709, lr = 0.0001\n",
            "2025-04-17 11:02:24 INFO     Epoch 14 [400/781]: loss = 0.16781489551067352, lr = 0.0001\n",
            "2025-04-17 11:02:58 INFO     Epoch 14 [450/781]: loss = 0.18514135479927063, lr = 0.0001\n",
            "2025-04-17 11:03:32 INFO     Epoch 14 [500/781]: loss = 0.19530169665813446, lr = 0.0001\n",
            "2025-04-17 11:04:06 INFO     Epoch 14 [550/781]: loss = 0.1928226351737976, lr = 0.0001\n",
            "2025-04-17 11:04:40 INFO     Epoch 14 [600/781]: loss = 0.1801549643278122, lr = 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "KW301QW7RqwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir output_cifar10\n"
      ],
      "metadata": {
        "id": "GGufxAzLRsmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install submitit"
      ],
      "metadata": {
        "id": "EC8oAM6hRv7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4350b6a-d7b1-4099-c828-66d81b9315c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: submitit in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from submitit) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import uuid  # Import the uuid module (although it's already in your submitit_train.py)\n",
        "\n",
        "shared_dir = \"/content/shared_experiments\" # Choose a path within /content/\n",
        "\n",
        "if not Path(shared_dir).is_dir():\n",
        "    os.makedirs(shared_dir, exist_ok=True)\n",
        "\n",
        "def get_shared_folder(shared_dir: str) -> Path:\n",
        "    user = os.getenv(\"USER\", \"default_user\") # Colab might not always have USER set\n",
        "    p = Path(shared_dir) / user / \"experiments\"\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "def get_init_file(shared_dir: str):\n",
        "    shared_folder = get_shared_folder(shared_dir)\n",
        "    init_file = shared_folder / f\"{uuid.uuid4().hex}_init\"\n",
        "    if init_file.exists():\n",
        "        os.remove(str(init_file))\n",
        "    return init_file\n",
        "\n",
        "# You can optionally run these lines to see the paths that will be used\n",
        "job_dir = get_shared_folder(shared_dir) / \"my_job\" # Example job directory\n",
        "print(f\"Job directory: {job_dir}\")\n",
        "init_file = get_init_file(shared_dir)\n",
        "print(f\"Init file: {init_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opZ2B51vax81",
        "outputId": "f8aea8ec-25ed-4eeb-8dc8-8d7c6079d1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job directory: /content/shared_experiments/default_user/experiments/my_job\n",
            "Init file: /content/shared_experiments/default_user/experiments/af6edabdc1e248e18abdf42794a7eaf6_init\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['USER'] = 'thesis_dfki'"
      ],
      "metadata": {
        "id": "H1_GpDqxniqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python submitit_train.py \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=64 \\\n",
        "    --nodes=1 \\\n",
        "    --accum_iter=1 \\\n",
        "    --eval_frequency=100 \\\n",
        "    --epochs=3000 \\\n",
        "    --class_drop_prob=1.0 \\\n",
        "    --cfg_scale=0.0 \\\n",
        "    --compute_fid \\\n",
        "    --ode_method heun2 \\\n",
        "    --ode_options '{\"nfe\": 50}' \\\n",
        "    --use_ema \\\n",
        "    --edm_schedule \\\n",
        "    --skewed_timesteps \\\n",
        "    --output_dir output_cifar10_submitit \\\n",
        "    --shared_dir \"/content/shared_experiments\""
      ],
      "metadata": {
        "id": "oAubohbgUUl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09580062-4dc8-4fce-ca93-c5496cb74831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-21 18:40:36 INFO     Submitted job 5326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "args = {\n",
        "    \"output_dir\": Path(\"/tmp/some/path\"),\n",
        "    \"other_param\": 42,\n",
        "}\n",
        "\n",
        "with open(\"args.json\", \"w\") as f:\n",
        "    json.dump({k: str(v) if isinstance(v, Path) else v for k, v in args.items()}, f)\n"
      ],
      "metadata": {
        "id": "17jgxnM_qSPG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}