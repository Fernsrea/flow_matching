{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fernsrea/flow_matching/blob/main/CIFAR_10_Discreet_Reduced_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jRnYLF-sE8H",
        "outputId": "1a62006e-1029-4e54-ef8f-abfaad8dc94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'flow_matching'...\n",
            "remote: Enumerating objects: 255, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 255 (delta 46), reused 21 (delta 21), pack-reused 165 (from 1)\u001b[K\n",
            "Receiving objects: 100% (255/255), 3.23 MiB | 17.49 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n",
            "/content/flow_matching\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Fernsrea/flow_matching.git\n",
        "%cd flow_matching"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd examples/image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1R7FXmqsYCR",
        "outputId": "58a4a45c-43d2-4bc5-d768-1addb413f0c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/flow_matching/examples/image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzyJxPEasbeA",
        "outputId": "71364fc7-0811-4f00-8bdd-59f34bcbf0bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting submitit (from -r requirements.txt (line 1))\n",
            "  Downloading submitit-1.5.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.21.0+cu124)\n",
            "Collecting torchmetrics[image] (from -r requirements.txt (line 2))\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from submitit->-r requirements.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]->-r requirements.txt (line 2)) (1.15.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r requirements.txt (line 3)) (11.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics[image]->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics[image]->-r requirements.txt (line 2)) (3.0.2)\n",
            "Downloading submitit-1.5.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: submitit, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, torch-fidelity\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 submitit-1.5.2 torch-fidelity-0.3.0 torchmetrics-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdiffeq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSbE2uw71gz3",
        "outputId": "7eb43f0e-1293-48cd-ce03-7f9b550e4aef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdiffeq\n",
            "  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq) (1.15.2)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy>=1.4.0->torchdiffeq) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\n",
            "Downloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: torchdiffeq\n",
            "Successfully installed torchdiffeq-0.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flow_matching"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4SivJfO2boL",
        "outputId": "a95d8889-ec2c-4ad9-a619-9e07c91b106e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flow_matching\n",
            "  Downloading flow_matching-1.0.10-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from flow_matching) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flow_matching) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.11/dist-packages (from flow_matching) (0.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flow_matching) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flow_matching) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from torchdiffeq->flow_matching) (1.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flow_matching) (3.0.2)\n",
            "Downloading flow_matching-1.0.10-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flow_matching\n",
            "Successfully installed flow_matching-1.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!python train.py \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=64 \\\n",
        "    --accum_iter=1 \\\n",
        "    --eval_frequency=50 \\\n",
        "    --epochs=500 \\\n",
        "    --use_ema \\\n",
        "    --discrete_flow_matching \\\n",
        "    --output_dir='/content/drive/MyDrive/flow_matching_checkpoints'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rzsI7hIC7hI",
        "outputId": "57787f65-f31c-49f9-8e68-a7e448689d30"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Not using distributed mode\n",
            "2025-05-01 20:48:31 INFO     job dir: /content/flow_matching/examples/image\n",
            "2025-05-01 20:48:31 INFO     Namespace(batch_size=64,\n",
            "epochs=500,\n",
            "accum_iter=1,\n",
            "lr=0.0001,\n",
            "optimizer_betas=[0.9,\n",
            "0.95],\n",
            "decay_lr=False,\n",
            "class_drop_prob=0.2,\n",
            "skewed_timesteps=False,\n",
            "edm_schedule=False,\n",
            "use_ema=True,\n",
            "dataset='cifar10',\n",
            "data_path='./data/image_generation',\n",
            "output_dir='/content/drive/MyDrive/flow_matching_checkpoints',\n",
            "ode_method='midpoint',\n",
            "ode_options={'step_size': 0.01},\n",
            "sym=0.0,\n",
            "temp=1.0,\n",
            "sym_func=False,\n",
            "sampling_dtype='float32',\n",
            "cfg_scale=0.2,\n",
            "fid_samples=50000,\n",
            "device='cuda',\n",
            "seed=0,\n",
            "resume='',\n",
            "start_epoch=0,\n",
            "eval_only=False,\n",
            "eval_frequency=50,\n",
            "compute_fid=False,\n",
            "save_fid_samples=False,\n",
            "num_workers=10,\n",
            "pin_mem=True,\n",
            "world_size=1,\n",
            "local_rank=-1,\n",
            "dist_on_itp=False,\n",
            "dist_url='env://',\n",
            "test_run=False,\n",
            "discrete_flow_matching=True,\n",
            "discrete_fm_steps=1024,\n",
            "distributed=False)\n",
            "2025-05-01 20:48:31 INFO     Saving args to /content/drive/MyDrive/flow_matching_checkpoints/args.json\n",
            "2025-05-01 20:48:31 INFO     Initializing Dataset: cifar10\n",
            "2025-05-01 20:48:32 INFO     Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data/image_generation\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 RandomHorizontalFlip(p=0.5)\n",
            "                 ToDtype(scale=True)\n",
            "           )\n",
            "2025-05-01 20:48:32 INFO     Intializing DataLoader\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2025-05-01 20:48:32 INFO     <torch.utils.data.distributed.DistributedSampler object at 0x7c7d7eebfad0>\n",
            "2025-05-01 20:48:32 INFO     Initializing Model\n",
            "2025-05-01 20:48:32 INFO     EMA(\n",
            "  (model): DiscreteUNetModel(vocab_size=257, in_channels=3, model_channels=48, out_channels=3, num_res_blocks=2, attention_resolutions=[2], dropout=0.4, channel_mult=[2, 2, 2], conv_resample=False, dims=2, num_classes=None, use_checkpoint=False, num_heads=-1, num_head_channels=32, num_heads_upsample=-1, use_scale_shift_norm=True, resblock_updown=False, use_new_attention_order=True, with_fourier_features=False)\n",
            "  (shadow_params): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 257x32 (cuda:0)]\n",
            "      (1): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (2): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (3): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (4): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (5): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (6): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (7): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (8): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (9): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (10): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (11): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (12): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (13): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (14): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (15): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (16): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (17): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (18): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (19): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (20): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (21): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (22): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (23): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (24): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (25): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (26): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (27): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (28): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (29): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (30): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (31): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (32): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (33): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (34): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (35): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (36): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (37): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (38): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (39): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (40): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (41): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (42): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (43): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (44): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (45): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (46): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (47): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (48): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (49): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (50): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (51): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (52): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (53): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (54): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (55): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (56): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (57): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (58): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (59): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (60): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (61): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (62): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (63): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (64): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (65): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (66): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (67): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (68): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (69): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (70): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (71): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (72): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (73): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (74): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (75): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (76): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (77): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (78): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (79): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (80): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (81): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (82): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (83): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (84): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (85): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (86): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (87): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (88): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (89): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (90): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (91): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (92): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (93): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (94): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (95): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (96): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (97): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (98): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (99): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (100): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (101): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (102): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (103): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (104): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (105): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (106): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (107): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (108): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (109): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (110): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (111): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (112): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (113): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (114): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (115): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (116): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (117): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (118): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (119): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (120): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (121): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (122): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (123): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (124): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (125): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (126): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (127): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (128): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (129): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (130): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (131): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (132): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (133): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (134): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (135): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (136): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (137): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (138): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (139): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (140): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (141): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (142): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (143): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (144): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (145): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (146): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (147): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (148): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (149): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (150): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (151): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (152): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (153): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (154): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (155): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (156): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (157): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (158): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (159): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (160): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (161): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (162): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (163): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (164): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (165): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (166): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (167): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (168): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (169): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (170): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (171): Parameter containing: [torch.float32 of size 288x96x1 (cuda:0)]\n",
            "      (172): Parameter containing: [torch.float32 of size 288 (cuda:0)]\n",
            "      (173): Parameter containing: [torch.float32 of size 96x96x1 (cuda:0)]\n",
            "      (174): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (175): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (176): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (177): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (178): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (179): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (180): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (181): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (182): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (183): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (184): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (185): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (186): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (187): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (188): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (189): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (190): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (191): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (192): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (193): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (194): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (195): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (196): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (197): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (198): Parameter containing: [torch.float32 of size 192 (cuda:0)]\n",
            "      (199): Parameter containing: [torch.float32 of size 96x192x3x3 (cuda:0)]\n",
            "      (200): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (201): Parameter containing: [torch.float32 of size 1x192 (cuda:0)]\n",
            "      (202): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (203): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (204): Parameter containing: [torch.float32 of size 96x96x3x3 (cuda:0)]\n",
            "      (205): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (206): Parameter containing: [torch.float32 of size 96x192x1x1 (cuda:0)]\n",
            "      (207): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (208): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (209): Parameter containing: [torch.float32 of size 96 (cuda:0)]\n",
            "      (210): Parameter containing: [torch.float32 of size 771x96x3x3 (cuda:0)]\n",
            "      (211): Parameter containing: [torch.float32 of size 771 (cuda:0)]\n",
            "  )\n",
            ")\n",
            "2025-05-01 20:48:32 INFO     Learning rate: 1.00e-04\n",
            "2025-05-01 20:48:32 INFO     Accumulate grad iterations: 1\n",
            "2025-05-01 20:48:32 INFO     Effective batch size: 64\n",
            "2025-05-01 20:48:32 INFO     Optimizer: AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: [0.9, 0.95]\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "2025-05-01 20:48:32 INFO     Learning-Rate Schedule: <torch.optim.lr_scheduler.ConstantLR object at 0x7c7d77904450>\n",
            "/content/flow_matching/examples/image/training/grad_scaler.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self._scaler = torch.cuda.amp.GradScaler()\n",
            "2025-05-01 20:48:32 INFO     Start from 0 to 500 epochs\n",
            "2025-05-01 20:48:37 INFO     Epoch 0 [0/781]: loss = 5.548991680145264, lr = 0.0001\n",
            "2025-05-01 20:48:50 INFO     Epoch 0 [50/781]: loss = 5.385605335235596, lr = 0.0001\n",
            "2025-05-01 20:49:03 INFO     Epoch 0 [100/781]: loss = 5.322007656097412, lr = 0.0001\n",
            "2025-05-01 20:49:15 INFO     Epoch 0 [150/781]: loss = 5.246541976928711, lr = 0.0001\n",
            "2025-05-01 20:49:28 INFO     Epoch 0 [200/781]: loss = 5.133996486663818, lr = 0.0001\n",
            "2025-05-01 20:49:41 INFO     Epoch 0 [250/781]: loss = 5.129027843475342, lr = 0.0001\n",
            "2025-05-01 20:49:55 INFO     Epoch 0 [300/781]: loss = 4.965603351593018, lr = 0.0001\n",
            "2025-05-01 20:50:08 INFO     Epoch 0 [350/781]: loss = 4.896108627319336, lr = 0.0001\n",
            "2025-05-01 20:50:22 INFO     Epoch 0 [400/781]: loss = 4.951463222503662, lr = 0.0001\n",
            "2025-05-01 20:50:35 INFO     Epoch 0 [450/781]: loss = 4.76085901260376, lr = 0.0001\n",
            "2025-05-01 20:50:49 INFO     Epoch 0 [500/781]: loss = 4.861316680908203, lr = 0.0001\n",
            "2025-05-01 20:51:03 INFO     Epoch 0 [550/781]: loss = 4.801401615142822, lr = 0.0001\n",
            "2025-05-01 20:51:17 INFO     Epoch 0 [600/781]: loss = 4.662643909454346, lr = 0.0001\n",
            "2025-05-01 20:51:31 INFO     Epoch 0 [650/781]: loss = 4.56508731842041, lr = 0.0001\n",
            "2025-05-01 20:51:45 INFO     Epoch 0 [700/781]: loss = 4.574123859405518, lr = 0.0001\n",
            "2025-05-01 20:51:58 INFO     Epoch 0 [750/781]: loss = 4.496906757354736, lr = 0.0001\n",
            "2025-05-01 20:52:08 INFO     Epoch 1 [0/781]: loss = 4.493504047393799, lr = 0.0001\n",
            "2025-05-01 20:52:22 INFO     Epoch 1 [50/781]: loss = 4.339785575866699, lr = 0.0001\n",
            "2025-05-01 20:52:36 INFO     Epoch 1 [100/781]: loss = 4.398406028747559, lr = 0.0001\n",
            "2025-05-01 20:52:49 INFO     Epoch 1 [150/781]: loss = 4.586653232574463, lr = 0.0001\n",
            "2025-05-01 20:53:03 INFO     Epoch 1 [200/781]: loss = 4.374404430389404, lr = 0.0001\n",
            "2025-05-01 20:53:17 INFO     Epoch 1 [250/781]: loss = 4.3846917152404785, lr = 0.0001\n",
            "2025-05-01 20:53:31 INFO     Epoch 1 [300/781]: loss = 4.202188968658447, lr = 0.0001\n",
            "2025-05-01 20:53:45 INFO     Epoch 1 [350/781]: loss = 4.229465484619141, lr = 0.0001\n",
            "2025-05-01 20:53:59 INFO     Epoch 1 [400/781]: loss = 4.185898303985596, lr = 0.0001\n",
            "2025-05-01 20:54:13 INFO     Epoch 1 [450/781]: loss = 4.118610382080078, lr = 0.0001\n",
            "2025-05-01 20:54:26 INFO     Epoch 1 [500/781]: loss = 3.880200147628784, lr = 0.0001\n",
            "2025-05-01 20:54:40 INFO     Epoch 1 [550/781]: loss = 4.2047953605651855, lr = 0.0001\n",
            "2025-05-01 20:54:54 INFO     Epoch 1 [600/781]: loss = 4.032607555389404, lr = 0.0001\n",
            "2025-05-01 20:55:08 INFO     Epoch 1 [650/781]: loss = 3.9662322998046875, lr = 0.0001\n",
            "2025-05-01 20:55:22 INFO     Epoch 1 [700/781]: loss = 4.1390156745910645, lr = 0.0001\n",
            "2025-05-01 20:55:36 INFO     Epoch 1 [750/781]: loss = 4.040399074554443, lr = 0.0001\n",
            "2025-05-01 20:55:45 INFO     Epoch 2 [0/781]: loss = 3.91668701171875, lr = 0.0001\n",
            "2025-05-01 20:55:59 INFO     Epoch 2 [50/781]: loss = 3.9533309936523438, lr = 0.0001\n",
            "2025-05-01 20:56:13 INFO     Epoch 2 [100/781]: loss = 4.1241021156311035, lr = 0.0001\n",
            "2025-05-01 20:56:27 INFO     Epoch 2 [150/781]: loss = 3.9793498516082764, lr = 0.0001\n",
            "2025-05-01 20:56:41 INFO     Epoch 2 [200/781]: loss = 3.9505224227905273, lr = 0.0001\n",
            "2025-05-01 20:56:54 INFO     Epoch 2 [250/781]: loss = 4.032303333282471, lr = 0.0001\n",
            "2025-05-01 20:57:08 INFO     Epoch 2 [300/781]: loss = 3.664423704147339, lr = 0.0001\n",
            "2025-05-01 20:57:22 INFO     Epoch 2 [350/781]: loss = 3.9991352558135986, lr = 0.0001\n",
            "2025-05-01 20:57:36 INFO     Epoch 2 [400/781]: loss = 3.826488494873047, lr = 0.0001\n",
            "2025-05-01 20:57:49 INFO     Epoch 2 [450/781]: loss = 3.9114177227020264, lr = 0.0001\n",
            "2025-05-01 20:58:03 INFO     Epoch 2 [500/781]: loss = 3.7597224712371826, lr = 0.0001\n",
            "2025-05-01 20:58:17 INFO     Epoch 2 [550/781]: loss = 3.8139588832855225, lr = 0.0001\n",
            "2025-05-01 20:58:31 INFO     Epoch 2 [600/781]: loss = 3.7855637073516846, lr = 0.0001\n",
            "2025-05-01 20:58:45 INFO     Epoch 2 [650/781]: loss = 3.4482650756835938, lr = 0.0001\n",
            "2025-05-01 20:58:59 INFO     Epoch 2 [700/781]: loss = 4.195841312408447, lr = 0.0001\n",
            "2025-05-01 20:59:13 INFO     Epoch 2 [750/781]: loss = 3.7470061779022217, lr = 0.0001\n",
            "2025-05-01 20:59:22 INFO     Epoch 3 [0/781]: loss = 3.3393561840057373, lr = 0.0001\n",
            "2025-05-01 20:59:36 INFO     Epoch 3 [50/781]: loss = 3.639658212661743, lr = 0.0001\n",
            "2025-05-01 20:59:50 INFO     Epoch 3 [100/781]: loss = 3.6573781967163086, lr = 0.0001\n",
            "2025-05-01 21:00:04 INFO     Epoch 3 [150/781]: loss = 3.741668701171875, lr = 0.0001\n",
            "2025-05-01 21:00:18 INFO     Epoch 3 [200/781]: loss = 3.472381591796875, lr = 0.0001\n",
            "2025-05-01 21:00:32 INFO     Epoch 3 [250/781]: loss = 4.071629524230957, lr = 0.0001\n",
            "2025-05-01 21:00:45 INFO     Epoch 3 [300/781]: loss = 3.503647565841675, lr = 0.0001\n",
            "2025-05-01 21:00:59 INFO     Epoch 3 [350/781]: loss = 3.7452962398529053, lr = 0.0001\n",
            "2025-05-01 21:01:13 INFO     Epoch 3 [400/781]: loss = 3.7693405151367188, lr = 0.0001\n",
            "2025-05-01 21:01:26 INFO     Epoch 3 [450/781]: loss = 3.5755109786987305, lr = 0.0001\n",
            "2025-05-01 21:01:40 INFO     Epoch 3 [500/781]: loss = 3.733726739883423, lr = 0.0001\n",
            "2025-05-01 21:01:54 INFO     Epoch 3 [550/781]: loss = 3.808662176132202, lr = 0.0001\n",
            "2025-05-01 21:02:07 INFO     Epoch 3 [600/781]: loss = 3.657505750656128, lr = 0.0001\n",
            "2025-05-01 21:02:21 INFO     Epoch 3 [650/781]: loss = 3.574726104736328, lr = 0.0001\n",
            "2025-05-01 21:02:35 INFO     Epoch 3 [700/781]: loss = 3.695693016052246, lr = 0.0001\n",
            "2025-05-01 21:02:48 INFO     Epoch 3 [750/781]: loss = 3.754333257675171, lr = 0.0001\n",
            "2025-05-01 21:02:58 INFO     Epoch 4 [0/781]: loss = 3.811692476272583, lr = 0.0001\n",
            "2025-05-01 21:03:12 INFO     Epoch 4 [50/781]: loss = 3.607447624206543, lr = 0.0001\n",
            "2025-05-01 21:03:26 INFO     Epoch 4 [100/781]: loss = 3.4654366970062256, lr = 0.0001\n",
            "2025-05-01 21:03:40 INFO     Epoch 4 [150/781]: loss = 3.4982945919036865, lr = 0.0001\n",
            "2025-05-01 21:03:54 INFO     Epoch 4 [200/781]: loss = 3.2960193157196045, lr = 0.0001\n",
            "2025-05-01 21:04:07 INFO     Epoch 4 [250/781]: loss = 3.423398017883301, lr = 0.0001\n",
            "2025-05-01 21:04:21 INFO     Epoch 4 [300/781]: loss = 3.497945547103882, lr = 0.0001\n",
            "2025-05-01 21:04:35 INFO     Epoch 4 [350/781]: loss = 3.601301431655884, lr = 0.0001\n",
            "2025-05-01 21:04:49 INFO     Epoch 4 [400/781]: loss = 3.4303433895111084, lr = 0.0001\n",
            "2025-05-01 21:05:03 INFO     Epoch 4 [450/781]: loss = 3.5416629314422607, lr = 0.0001\n",
            "2025-05-01 21:05:17 INFO     Epoch 4 [500/781]: loss = 3.5793583393096924, lr = 0.0001\n",
            "2025-05-01 21:05:31 INFO     Epoch 4 [550/781]: loss = 3.6019513607025146, lr = 0.0001\n",
            "2025-05-01 21:05:45 INFO     Epoch 4 [600/781]: loss = 3.3600170612335205, lr = 0.0001\n",
            "2025-05-01 21:05:58 INFO     Epoch 4 [650/781]: loss = 3.3322575092315674, lr = 0.0001\n",
            "2025-05-01 21:06:12 INFO     Epoch 4 [700/781]: loss = 3.5012805461883545, lr = 0.0001\n",
            "2025-05-01 21:06:26 INFO     Epoch 4 [750/781]: loss = 3.6364023685455322, lr = 0.0001\n",
            "2025-05-01 21:06:35 INFO     Epoch 5 [0/781]: loss = 3.2747585773468018, lr = 0.0001\n",
            "2025-05-01 21:06:49 INFO     Epoch 5 [50/781]: loss = 3.438444137573242, lr = 0.0001\n",
            "2025-05-01 21:07:03 INFO     Epoch 5 [100/781]: loss = 3.8165276050567627, lr = 0.0001\n",
            "2025-05-01 21:07:17 INFO     Epoch 5 [150/781]: loss = 3.8589279651641846, lr = 0.0001\n",
            "2025-05-01 21:07:31 INFO     Epoch 5 [200/781]: loss = 3.4308900833129883, lr = 0.0001\n",
            "2025-05-01 21:07:45 INFO     Epoch 5 [250/781]: loss = 3.7071187496185303, lr = 0.0001\n",
            "2025-05-01 21:07:59 INFO     Epoch 5 [300/781]: loss = 3.5234594345092773, lr = 0.0001\n",
            "2025-05-01 21:08:12 INFO     Epoch 5 [350/781]: loss = 3.475774049758911, lr = 0.0001\n",
            "2025-05-01 21:08:26 INFO     Epoch 5 [400/781]: loss = 3.4668004512786865, lr = 0.0001\n",
            "2025-05-01 21:08:40 INFO     Epoch 5 [450/781]: loss = 3.449594736099243, lr = 0.0001\n",
            "2025-05-01 21:08:54 INFO     Epoch 5 [500/781]: loss = 3.6097211837768555, lr = 0.0001\n",
            "2025-05-01 21:09:08 INFO     Epoch 5 [550/781]: loss = 3.7566983699798584, lr = 0.0001\n",
            "2025-05-01 21:09:22 INFO     Epoch 5 [600/781]: loss = 3.420896291732788, lr = 0.0001\n",
            "2025-05-01 21:09:36 INFO     Epoch 5 [650/781]: loss = 3.48557448387146, lr = 0.0001\n",
            "2025-05-01 21:09:50 INFO     Epoch 5 [700/781]: loss = 3.7579004764556885, lr = 0.0001\n",
            "2025-05-01 21:10:03 INFO     Epoch 5 [750/781]: loss = 3.738950729370117, lr = 0.0001\n",
            "2025-05-01 21:10:13 INFO     Epoch 6 [0/781]: loss = 3.2575597763061523, lr = 0.0001\n",
            "2025-05-01 21:10:27 INFO     Epoch 6 [50/781]: loss = 3.5536892414093018, lr = 0.0001\n",
            "2025-05-01 21:10:40 INFO     Epoch 6 [100/781]: loss = 3.6417016983032227, lr = 0.0001\n",
            "2025-05-01 21:10:54 INFO     Epoch 6 [150/781]: loss = 3.4664604663848877, lr = 0.0001\n",
            "2025-05-01 21:11:08 INFO     Epoch 6 [200/781]: loss = 3.739790678024292, lr = 0.0001\n",
            "2025-05-01 21:11:22 INFO     Epoch 6 [250/781]: loss = 3.461498975753784, lr = 0.0001\n",
            "2025-05-01 21:11:36 INFO     Epoch 6 [300/781]: loss = 3.2404673099517822, lr = 0.0001\n",
            "2025-05-01 21:11:50 INFO     Epoch 6 [350/781]: loss = 3.488710641860962, lr = 0.0001\n",
            "2025-05-01 21:12:03 INFO     Epoch 6 [400/781]: loss = 3.6158647537231445, lr = 0.0001\n",
            "2025-05-01 21:12:17 INFO     Epoch 6 [450/781]: loss = 3.383911371231079, lr = 0.0001\n",
            "2025-05-01 21:12:31 INFO     Epoch 6 [500/781]: loss = 3.6101763248443604, lr = 0.0001\n",
            "2025-05-01 21:12:45 INFO     Epoch 6 [550/781]: loss = 3.52763295173645, lr = 0.0001\n",
            "2025-05-01 21:12:59 INFO     Epoch 6 [600/781]: loss = 3.5084056854248047, lr = 0.0001\n",
            "2025-05-01 21:13:13 INFO     Epoch 6 [650/781]: loss = 3.54206919670105, lr = 0.0001\n",
            "2025-05-01 21:13:27 INFO     Epoch 6 [700/781]: loss = 3.45816707611084, lr = 0.0001\n",
            "2025-05-01 21:13:41 INFO     Epoch 6 [750/781]: loss = 3.5312440395355225, lr = 0.0001\n",
            "2025-05-01 21:13:50 INFO     Epoch 7 [0/781]: loss = 3.0852584838867188, lr = 0.0001\n",
            "2025-05-01 21:14:04 INFO     Epoch 7 [50/781]: loss = 3.570449113845825, lr = 0.0001\n",
            "2025-05-01 21:14:18 INFO     Epoch 7 [100/781]: loss = 3.661029577255249, lr = 0.0001\n",
            "2025-05-01 21:14:32 INFO     Epoch 7 [150/781]: loss = 3.3723573684692383, lr = 0.0001\n",
            "2025-05-01 21:14:45 INFO     Epoch 7 [200/781]: loss = 3.6957242488861084, lr = 0.0001\n",
            "2025-05-01 21:14:59 INFO     Epoch 7 [250/781]: loss = 3.5279483795166016, lr = 0.0001\n",
            "2025-05-01 21:15:13 INFO     Epoch 7 [300/781]: loss = 3.39399790763855, lr = 0.0001\n",
            "2025-05-01 21:15:26 INFO     Epoch 7 [350/781]: loss = 3.5021603107452393, lr = 0.0001\n",
            "2025-05-01 21:15:40 INFO     Epoch 7 [400/781]: loss = 3.415757417678833, lr = 0.0001\n",
            "2025-05-01 21:15:54 INFO     Epoch 7 [450/781]: loss = 3.4146816730499268, lr = 0.0001\n",
            "2025-05-01 21:16:07 INFO     Epoch 7 [500/781]: loss = 3.4113738536834717, lr = 0.0001\n",
            "2025-05-01 21:16:21 INFO     Epoch 7 [550/781]: loss = 3.76226806640625, lr = 0.0001\n",
            "2025-05-01 21:16:35 INFO     Epoch 7 [600/781]: loss = 3.450629472732544, lr = 0.0001\n",
            "2025-05-01 21:16:49 INFO     Epoch 7 [650/781]: loss = 3.2761662006378174, lr = 0.0001\n",
            "2025-05-01 21:17:03 INFO     Epoch 7 [700/781]: loss = 3.5960636138916016, lr = 0.0001\n",
            "2025-05-01 21:17:17 INFO     Epoch 7 [750/781]: loss = 3.4357168674468994, lr = 0.0001\n",
            "2025-05-01 21:17:26 INFO     Epoch 8 [0/781]: loss = 3.4440290927886963, lr = 0.0001\n",
            "2025-05-01 21:17:40 INFO     Epoch 8 [50/781]: loss = 3.2319705486297607, lr = 0.0001\n",
            "2025-05-01 21:17:54 INFO     Epoch 8 [100/781]: loss = 3.0790538787841797, lr = 0.0001\n",
            "2025-05-01 21:18:08 INFO     Epoch 8 [150/781]: loss = 3.531179428100586, lr = 0.0001\n",
            "2025-05-01 21:18:21 INFO     Epoch 8 [200/781]: loss = 3.250627279281616, lr = 0.0001\n",
            "2025-05-01 21:18:35 INFO     Epoch 8 [250/781]: loss = 3.4133684635162354, lr = 0.0001\n",
            "2025-05-01 21:18:49 INFO     Epoch 8 [300/781]: loss = 3.5175840854644775, lr = 0.0001\n",
            "2025-05-01 21:19:03 INFO     Epoch 8 [350/781]: loss = 3.506218910217285, lr = 0.0001\n",
            "2025-05-01 21:19:17 INFO     Epoch 8 [400/781]: loss = 3.542363166809082, lr = 0.0001\n",
            "2025-05-01 21:19:31 INFO     Epoch 8 [450/781]: loss = 3.2293291091918945, lr = 0.0001\n",
            "2025-05-01 21:19:44 INFO     Epoch 8 [500/781]: loss = 3.466197967529297, lr = 0.0001\n",
            "2025-05-01 21:19:58 INFO     Epoch 8 [550/781]: loss = 3.5377776622772217, lr = 0.0001\n",
            "2025-05-01 21:20:12 INFO     Epoch 8 [600/781]: loss = 3.4629087448120117, lr = 0.0001\n",
            "2025-05-01 21:20:26 INFO     Epoch 8 [650/781]: loss = 3.3009016513824463, lr = 0.0001\n",
            "2025-05-01 21:20:40 INFO     Epoch 8 [700/781]: loss = 3.4297263622283936, lr = 0.0001\n",
            "2025-05-01 21:20:54 INFO     Epoch 8 [750/781]: loss = 3.556814193725586, lr = 0.0001\n",
            "2025-05-01 21:21:03 INFO     Epoch 9 [0/781]: loss = 3.153578519821167, lr = 0.0001\n",
            "2025-05-01 21:21:17 INFO     Epoch 9 [50/781]: loss = 3.1063108444213867, lr = 0.0001\n",
            "2025-05-01 21:21:31 INFO     Epoch 9 [100/781]: loss = 3.507878303527832, lr = 0.0001\n",
            "2025-05-01 21:21:45 INFO     Epoch 9 [150/781]: loss = 3.6553027629852295, lr = 0.0001\n",
            "2025-05-01 21:21:58 INFO     Epoch 9 [200/781]: loss = 3.3830058574676514, lr = 0.0001\n",
            "2025-05-01 21:22:12 INFO     Epoch 9 [250/781]: loss = 3.3373193740844727, lr = 0.0001\n",
            "2025-05-01 21:22:26 INFO     Epoch 9 [300/781]: loss = 3.1556336879730225, lr = 0.0001\n",
            "2025-05-01 21:22:40 INFO     Epoch 9 [350/781]: loss = 2.826390027999878, lr = 0.0001\n",
            "2025-05-01 21:22:54 INFO     Epoch 9 [400/781]: loss = 2.9063005447387695, lr = 0.0001\n",
            "2025-05-01 21:23:08 INFO     Epoch 9 [450/781]: loss = 3.2965517044067383, lr = 0.0001\n",
            "2025-05-01 21:23:22 INFO     Epoch 9 [500/781]: loss = 3.3372299671173096, lr = 0.0001\n",
            "2025-05-01 21:23:35 INFO     Epoch 9 [550/781]: loss = 3.36542010307312, lr = 0.0001\n",
            "2025-05-01 21:23:49 INFO     Epoch 9 [600/781]: loss = 3.4582359790802, lr = 0.0001\n",
            "2025-05-01 21:24:03 INFO     Epoch 9 [650/781]: loss = 3.472595453262329, lr = 0.0001\n",
            "2025-05-01 21:24:17 INFO     Epoch 9 [700/781]: loss = 3.426485776901245, lr = 0.0001\n",
            "2025-05-01 21:24:31 INFO     Epoch 9 [750/781]: loss = 3.5968902111053467, lr = 0.0001\n",
            "2025-05-01 21:24:41 INFO     Epoch 10 [0/781]: loss = 3.3534905910491943, lr = 0.0001\n",
            "2025-05-01 21:24:55 INFO     Epoch 10 [50/781]: loss = 3.635563611984253, lr = 0.0001\n",
            "2025-05-01 21:25:09 INFO     Epoch 10 [100/781]: loss = 3.5221216678619385, lr = 0.0001\n",
            "2025-05-01 21:25:23 INFO     Epoch 10 [150/781]: loss = 3.3956298828125, lr = 0.0001\n",
            "2025-05-01 21:25:36 INFO     Epoch 10 [200/781]: loss = 3.5541670322418213, lr = 0.0001\n",
            "2025-05-01 21:25:50 INFO     Epoch 10 [250/781]: loss = 3.266728639602661, lr = 0.0001\n",
            "2025-05-01 21:26:04 INFO     Epoch 10 [300/781]: loss = 3.066669464111328, lr = 0.0001\n",
            "2025-05-01 21:26:18 INFO     Epoch 10 [350/781]: loss = 3.2639224529266357, lr = 0.0001\n",
            "2025-05-01 21:26:32 INFO     Epoch 10 [400/781]: loss = 3.252439260482788, lr = 0.0001\n",
            "2025-05-01 21:26:46 INFO     Epoch 10 [450/781]: loss = 3.0661134719848633, lr = 0.0001\n",
            "2025-05-01 21:27:00 INFO     Epoch 10 [500/781]: loss = 3.562049150466919, lr = 0.0001\n",
            "2025-05-01 21:27:13 INFO     Epoch 10 [550/781]: loss = 3.3909246921539307, lr = 0.0001\n",
            "2025-05-01 21:27:27 INFO     Epoch 10 [600/781]: loss = 3.5131006240844727, lr = 0.0001\n",
            "2025-05-01 21:27:41 INFO     Epoch 10 [650/781]: loss = 3.22804856300354, lr = 0.0001\n",
            "2025-05-01 21:27:55 INFO     Epoch 10 [700/781]: loss = 3.6039040088653564, lr = 0.0001\n",
            "2025-05-01 21:28:09 INFO     Epoch 10 [750/781]: loss = 3.615507125854492, lr = 0.0001\n",
            "2025-05-01 21:28:18 INFO     Epoch 11 [0/781]: loss = 3.4102227687835693, lr = 0.0001\n",
            "2025-05-01 21:28:32 INFO     Epoch 11 [50/781]: loss = 3.367204427719116, lr = 0.0001\n",
            "2025-05-01 21:28:46 INFO     Epoch 11 [100/781]: loss = 3.2133169174194336, lr = 0.0001\n",
            "2025-05-01 21:29:00 INFO     Epoch 11 [150/781]: loss = 3.394925117492676, lr = 0.0001\n",
            "2025-05-01 21:29:14 INFO     Epoch 11 [200/781]: loss = 3.7052440643310547, lr = 0.0001\n",
            "2025-05-01 21:29:27 INFO     Epoch 11 [250/781]: loss = 3.440572738647461, lr = 0.0001\n",
            "2025-05-01 21:29:41 INFO     Epoch 11 [300/781]: loss = 3.4929935932159424, lr = 0.0001\n",
            "2025-05-01 21:29:55 INFO     Epoch 11 [350/781]: loss = 3.5108325481414795, lr = 0.0001\n",
            "2025-05-01 21:30:09 INFO     Epoch 11 [400/781]: loss = 3.0330517292022705, lr = 0.0001\n",
            "2025-05-01 21:30:23 INFO     Epoch 11 [450/781]: loss = 3.365626573562622, lr = 0.0001\n",
            "2025-05-01 21:30:37 INFO     Epoch 11 [500/781]: loss = 3.531491994857788, lr = 0.0001\n",
            "2025-05-01 21:30:51 INFO     Epoch 11 [550/781]: loss = 3.2377140522003174, lr = 0.0001\n",
            "2025-05-01 21:31:05 INFO     Epoch 11 [600/781]: loss = 3.1113977432250977, lr = 0.0001\n",
            "2025-05-01 21:31:18 INFO     Epoch 11 [650/781]: loss = 3.5453546047210693, lr = 0.0001\n",
            "2025-05-01 21:31:32 INFO     Epoch 11 [700/781]: loss = 3.3622848987579346, lr = 0.0001\n",
            "2025-05-01 21:31:46 INFO     Epoch 11 [750/781]: loss = 3.7206966876983643, lr = 0.0001\n",
            "2025-05-01 21:31:56 INFO     Epoch 12 [0/781]: loss = 3.5388343334198, lr = 0.0001\n",
            "2025-05-01 21:32:10 INFO     Epoch 12 [50/781]: loss = 3.1580588817596436, lr = 0.0001\n",
            "2025-05-01 21:32:24 INFO     Epoch 12 [100/781]: loss = 3.349896192550659, lr = 0.0001\n",
            "2025-05-01 21:32:37 INFO     Epoch 12 [150/781]: loss = 3.625769853591919, lr = 0.0001\n",
            "2025-05-01 21:32:51 INFO     Epoch 12 [200/781]: loss = 3.26521372795105, lr = 0.0001\n",
            "2025-05-01 21:33:05 INFO     Epoch 12 [250/781]: loss = 3.241224527359009, lr = 0.0001\n",
            "2025-05-01 21:33:19 INFO     Epoch 12 [300/781]: loss = 3.273245096206665, lr = 0.0001\n",
            "2025-05-01 21:33:33 INFO     Epoch 12 [350/781]: loss = 3.4020376205444336, lr = 0.0001\n",
            "2025-05-01 21:33:47 INFO     Epoch 12 [400/781]: loss = 3.3490149974823, lr = 0.0001\n",
            "2025-05-01 21:34:00 INFO     Epoch 12 [450/781]: loss = 3.3486881256103516, lr = 0.0001\n",
            "2025-05-01 21:34:14 INFO     Epoch 12 [500/781]: loss = 2.938312530517578, lr = 0.0001\n",
            "2025-05-01 21:34:28 INFO     Epoch 12 [550/781]: loss = 3.3169095516204834, lr = 0.0001\n",
            "2025-05-01 21:34:42 INFO     Epoch 12 [600/781]: loss = 3.2943954467773438, lr = 0.0001\n",
            "2025-05-01 21:34:56 INFO     Epoch 12 [650/781]: loss = 3.2369344234466553, lr = 0.0001\n",
            "2025-05-01 21:35:10 INFO     Epoch 12 [700/781]: loss = 3.3032591342926025, lr = 0.0001\n",
            "2025-05-01 21:35:24 INFO     Epoch 12 [750/781]: loss = 3.4898908138275146, lr = 0.0001\n",
            "2025-05-01 21:35:33 INFO     Epoch 13 [0/781]: loss = 3.4451467990875244, lr = 0.0001\n",
            "2025-05-01 21:35:47 INFO     Epoch 13 [50/781]: loss = 3.466750383377075, lr = 0.0001\n",
            "2025-05-01 21:36:01 INFO     Epoch 13 [100/781]: loss = 3.580652952194214, lr = 0.0001\n",
            "2025-05-01 21:36:14 INFO     Epoch 13 [150/781]: loss = 3.3853366374969482, lr = 0.0001\n",
            "2025-05-01 21:36:28 INFO     Epoch 13 [200/781]: loss = 3.1348226070404053, lr = 0.0001\n",
            "2025-05-01 21:36:42 INFO     Epoch 13 [250/781]: loss = 3.2218523025512695, lr = 0.0001\n",
            "2025-05-01 21:36:56 INFO     Epoch 13 [300/781]: loss = 3.394001007080078, lr = 0.0001\n",
            "2025-05-01 21:37:10 INFO     Epoch 13 [350/781]: loss = 3.2425098419189453, lr = 0.0001\n",
            "2025-05-01 21:37:24 INFO     Epoch 13 [400/781]: loss = 3.392896890640259, lr = 0.0001\n",
            "2025-05-01 21:37:38 INFO     Epoch 13 [450/781]: loss = 3.2657811641693115, lr = 0.0001\n",
            "2025-05-01 21:37:52 INFO     Epoch 13 [500/781]: loss = 3.167438507080078, lr = 0.0001\n",
            "2025-05-01 21:38:06 INFO     Epoch 13 [550/781]: loss = 3.3620765209198, lr = 0.0001\n",
            "2025-05-01 21:38:19 INFO     Epoch 13 [600/781]: loss = 3.2068469524383545, lr = 0.0001\n",
            "2025-05-01 21:38:33 INFO     Epoch 13 [650/781]: loss = 3.445000410079956, lr = 0.0001\n",
            "2025-05-01 21:38:47 INFO     Epoch 13 [700/781]: loss = 3.4860317707061768, lr = 0.0001\n",
            "2025-05-01 21:39:01 INFO     Epoch 13 [750/781]: loss = 3.4197614192962646, lr = 0.0001\n",
            "2025-05-01 21:39:10 INFO     Epoch 14 [0/781]: loss = 2.996872663497925, lr = 0.0001\n",
            "2025-05-01 21:39:24 INFO     Epoch 14 [50/781]: loss = 3.183455467224121, lr = 0.0001\n",
            "2025-05-01 21:39:38 INFO     Epoch 14 [100/781]: loss = 3.6212806701660156, lr = 0.0001\n",
            "2025-05-01 21:39:52 INFO     Epoch 14 [150/781]: loss = 3.179539442062378, lr = 0.0001\n",
            "2025-05-01 21:40:06 INFO     Epoch 14 [200/781]: loss = 2.9090754985809326, lr = 0.0001\n",
            "2025-05-01 21:40:20 INFO     Epoch 14 [250/781]: loss = 3.444453001022339, lr = 0.0001\n",
            "2025-05-01 21:40:33 INFO     Epoch 14 [300/781]: loss = 3.1044352054595947, lr = 0.0001\n",
            "2025-05-01 21:40:47 INFO     Epoch 14 [350/781]: loss = 3.2496144771575928, lr = 0.0001\n",
            "2025-05-01 21:41:01 INFO     Epoch 14 [400/781]: loss = 3.415919542312622, lr = 0.0001\n",
            "2025-05-01 21:41:15 INFO     Epoch 14 [450/781]: loss = 3.51037335395813, lr = 0.0001\n",
            "2025-05-01 21:41:29 INFO     Epoch 14 [500/781]: loss = 3.045631170272827, lr = 0.0001\n",
            "2025-05-01 21:41:43 INFO     Epoch 14 [550/781]: loss = 3.339951753616333, lr = 0.0001\n",
            "2025-05-01 21:41:57 INFO     Epoch 14 [600/781]: loss = 3.0822973251342773, lr = 0.0001\n",
            "2025-05-01 21:42:10 INFO     Epoch 14 [650/781]: loss = 3.520657777786255, lr = 0.0001\n",
            "2025-05-01 21:42:24 INFO     Epoch 14 [700/781]: loss = 3.226609468460083, lr = 0.0001\n",
            "2025-05-01 21:42:38 INFO     Epoch 14 [750/781]: loss = 3.6780827045440674, lr = 0.0001\n",
            "2025-05-01 21:42:48 INFO     Epoch 15 [0/781]: loss = 3.4199600219726562, lr = 0.0001\n",
            "2025-05-01 21:43:01 INFO     Epoch 15 [50/781]: loss = 3.3640012741088867, lr = 0.0001\n",
            "2025-05-01 21:43:15 INFO     Epoch 15 [100/781]: loss = 3.3441007137298584, lr = 0.0001\n",
            "2025-05-01 21:43:29 INFO     Epoch 15 [150/781]: loss = 3.381617784500122, lr = 0.0001\n",
            "2025-05-01 21:43:43 INFO     Epoch 15 [200/781]: loss = 3.506079912185669, lr = 0.0001\n",
            "2025-05-01 21:43:57 INFO     Epoch 15 [250/781]: loss = 3.42390513420105, lr = 0.0001\n",
            "2025-05-01 21:44:11 INFO     Epoch 15 [300/781]: loss = 3.272014617919922, lr = 0.0001\n",
            "2025-05-01 21:44:25 INFO     Epoch 15 [350/781]: loss = 3.6332590579986572, lr = 0.0001\n",
            "2025-05-01 21:44:38 INFO     Epoch 15 [400/781]: loss = 3.336967706680298, lr = 0.0001\n",
            "2025-05-01 21:44:52 INFO     Epoch 15 [450/781]: loss = 3.4242169857025146, lr = 0.0001\n",
            "2025-05-01 21:45:06 INFO     Epoch 15 [500/781]: loss = 3.2719364166259766, lr = 0.0001\n",
            "2025-05-01 21:45:20 INFO     Epoch 15 [550/781]: loss = 3.5726253986358643, lr = 0.0001\n",
            "2025-05-01 21:45:34 INFO     Epoch 15 [600/781]: loss = 3.2702198028564453, lr = 0.0001\n",
            "2025-05-01 21:45:48 INFO     Epoch 15 [650/781]: loss = 3.209538698196411, lr = 0.0001\n",
            "2025-05-01 21:46:02 INFO     Epoch 15 [700/781]: loss = 3.5155317783355713, lr = 0.0001\n",
            "2025-05-01 21:46:15 INFO     Epoch 15 [750/781]: loss = 3.5120861530303955, lr = 0.0001\n",
            "2025-05-01 21:46:25 INFO     Epoch 16 [0/781]: loss = 2.9998538494110107, lr = 0.0001\n",
            "2025-05-01 21:46:39 INFO     Epoch 16 [50/781]: loss = 3.0881776809692383, lr = 0.0001\n",
            "2025-05-01 21:46:52 INFO     Epoch 16 [100/781]: loss = 3.6248528957366943, lr = 0.0001\n",
            "2025-05-01 21:47:06 INFO     Epoch 16 [150/781]: loss = 3.125157356262207, lr = 0.0001\n",
            "2025-05-01 21:47:20 INFO     Epoch 16 [200/781]: loss = 3.4461448192596436, lr = 0.0001\n",
            "2025-05-01 21:47:34 INFO     Epoch 16 [250/781]: loss = 3.4942896366119385, lr = 0.0001\n",
            "2025-05-01 21:47:48 INFO     Epoch 16 [300/781]: loss = 3.282738447189331, lr = 0.0001\n",
            "2025-05-01 21:48:02 INFO     Epoch 16 [350/781]: loss = 3.255347490310669, lr = 0.0001\n",
            "2025-05-01 21:48:16 INFO     Epoch 16 [400/781]: loss = 3.464205503463745, lr = 0.0001\n",
            "2025-05-01 21:48:29 INFO     Epoch 16 [450/781]: loss = 3.6160011291503906, lr = 0.0001\n",
            "2025-05-01 21:48:43 INFO     Epoch 16 [500/781]: loss = 3.0485775470733643, lr = 0.0001\n",
            "2025-05-01 21:48:57 INFO     Epoch 16 [550/781]: loss = 3.384611129760742, lr = 0.0001\n",
            "2025-05-01 21:49:11 INFO     Epoch 16 [600/781]: loss = 3.6842434406280518, lr = 0.0001\n",
            "2025-05-01 21:49:25 INFO     Epoch 16 [650/781]: loss = 3.4001033306121826, lr = 0.0001\n",
            "2025-05-01 21:49:39 INFO     Epoch 16 [700/781]: loss = 3.402728319168091, lr = 0.0001\n",
            "2025-05-01 21:49:53 INFO     Epoch 16 [750/781]: loss = 3.3653619289398193, lr = 0.0001\n",
            "2025-05-01 21:50:03 INFO     Epoch 17 [0/781]: loss = 3.3100016117095947, lr = 0.0001\n",
            "2025-05-01 21:50:17 INFO     Epoch 17 [50/781]: loss = 3.466874361038208, lr = 0.0001\n",
            "2025-05-01 21:50:30 INFO     Epoch 17 [100/781]: loss = 3.5497922897338867, lr = 0.0001\n",
            "2025-05-01 21:50:44 INFO     Epoch 17 [150/781]: loss = 3.070996046066284, lr = 0.0001\n",
            "2025-05-01 21:50:58 INFO     Epoch 17 [200/781]: loss = 3.0189530849456787, lr = 0.0001\n",
            "2025-05-01 21:51:12 INFO     Epoch 17 [250/781]: loss = 3.398829698562622, lr = 0.0001\n",
            "2025-05-01 21:51:26 INFO     Epoch 17 [300/781]: loss = 3.1635901927948, lr = 0.0001\n",
            "2025-05-01 21:51:40 INFO     Epoch 17 [350/781]: loss = 3.238640785217285, lr = 0.0001\n",
            "2025-05-01 21:51:54 INFO     Epoch 17 [400/781]: loss = 3.1044921875, lr = 0.0001\n",
            "2025-05-01 21:52:08 INFO     Epoch 17 [450/781]: loss = 3.262425422668457, lr = 0.0001\n",
            "2025-05-01 21:52:21 INFO     Epoch 17 [500/781]: loss = 3.33583927154541, lr = 0.0001\n",
            "2025-05-01 21:52:35 INFO     Epoch 17 [550/781]: loss = 3.194922685623169, lr = 0.0001\n",
            "2025-05-01 21:52:49 INFO     Epoch 17 [600/781]: loss = 3.007894515991211, lr = 0.0001\n",
            "2025-05-01 21:53:03 INFO     Epoch 17 [650/781]: loss = 3.2053422927856445, lr = 0.0001\n",
            "2025-05-01 21:53:17 INFO     Epoch 17 [700/781]: loss = 3.366774559020996, lr = 0.0001\n",
            "2025-05-01 21:53:31 INFO     Epoch 17 [750/781]: loss = 3.5921804904937744, lr = 0.0001\n",
            "2025-05-01 21:53:40 INFO     Epoch 18 [0/781]: loss = 3.304795980453491, lr = 0.0001\n",
            "2025-05-01 21:53:54 INFO     Epoch 18 [50/781]: loss = 3.2922821044921875, lr = 0.0001\n",
            "2025-05-01 21:54:08 INFO     Epoch 18 [100/781]: loss = 3.3312692642211914, lr = 0.0001\n",
            "2025-05-01 21:54:22 INFO     Epoch 18 [150/781]: loss = 3.2769458293914795, lr = 0.0001\n",
            "2025-05-01 21:54:36 INFO     Epoch 18 [200/781]: loss = 3.3409554958343506, lr = 0.0001\n",
            "2025-05-01 21:54:49 INFO     Epoch 18 [250/781]: loss = 2.989102363586426, lr = 0.0001\n",
            "2025-05-01 21:55:03 INFO     Epoch 18 [300/781]: loss = 3.1567156314849854, lr = 0.0001\n",
            "2025-05-01 21:55:17 INFO     Epoch 18 [350/781]: loss = 3.440833330154419, lr = 0.0001\n",
            "2025-05-01 21:55:31 INFO     Epoch 18 [400/781]: loss = 3.286221504211426, lr = 0.0001\n",
            "2025-05-01 21:55:45 INFO     Epoch 18 [450/781]: loss = 3.5659172534942627, lr = 0.0001\n",
            "2025-05-01 21:55:59 INFO     Epoch 18 [500/781]: loss = 2.9106807708740234, lr = 0.0001\n",
            "2025-05-01 21:56:13 INFO     Epoch 18 [550/781]: loss = 3.100583791732788, lr = 0.0001\n",
            "2025-05-01 21:56:27 INFO     Epoch 18 [600/781]: loss = 3.319432020187378, lr = 0.0001\n",
            "2025-05-01 21:56:41 INFO     Epoch 18 [650/781]: loss = 3.0732851028442383, lr = 0.0001\n",
            "2025-05-01 21:56:54 INFO     Epoch 18 [700/781]: loss = 2.9986469745635986, lr = 0.0001\n",
            "2025-05-01 21:57:08 INFO     Epoch 18 [750/781]: loss = 3.2008650302886963, lr = 0.0001\n",
            "2025-05-01 21:57:18 INFO     Epoch 19 [0/781]: loss = 3.4032363891601562, lr = 0.0001\n",
            "2025-05-01 21:57:32 INFO     Epoch 19 [50/781]: loss = 3.635646104812622, lr = 0.0001\n",
            "2025-05-01 21:57:46 INFO     Epoch 19 [100/781]: loss = 3.5188515186309814, lr = 0.0001\n",
            "2025-05-01 21:58:00 INFO     Epoch 19 [150/781]: loss = 3.362338066101074, lr = 0.0001\n",
            "2025-05-01 21:58:14 INFO     Epoch 19 [200/781]: loss = 3.483651876449585, lr = 0.0001\n",
            "2025-05-01 21:58:28 INFO     Epoch 19 [250/781]: loss = 3.3485171794891357, lr = 0.0001\n",
            "2025-05-01 21:58:41 INFO     Epoch 19 [300/781]: loss = 3.2661616802215576, lr = 0.0001\n",
            "2025-05-01 21:58:55 INFO     Epoch 19 [350/781]: loss = 3.3201863765716553, lr = 0.0001\n",
            "2025-05-01 21:59:09 INFO     Epoch 19 [400/781]: loss = 3.331390142440796, lr = 0.0001\n",
            "2025-05-01 21:59:23 INFO     Epoch 19 [450/781]: loss = 3.5200319290161133, lr = 0.0001\n",
            "2025-05-01 21:59:37 INFO     Epoch 19 [500/781]: loss = 3.471095085144043, lr = 0.0001\n",
            "2025-05-01 21:59:51 INFO     Epoch 19 [550/781]: loss = 2.9808003902435303, lr = 0.0001\n",
            "2025-05-01 22:00:05 INFO     Epoch 19 [600/781]: loss = 3.162109375, lr = 0.0001\n",
            "2025-05-01 22:00:18 INFO     Epoch 19 [650/781]: loss = 3.2738969326019287, lr = 0.0001\n",
            "2025-05-01 22:00:32 INFO     Epoch 19 [700/781]: loss = 3.361849546432495, lr = 0.0001\n",
            "2025-05-01 22:00:46 INFO     Epoch 19 [750/781]: loss = 3.424123764038086, lr = 0.0001\n",
            "2025-05-01 22:00:56 INFO     Epoch 20 [0/781]: loss = 3.287954330444336, lr = 0.0001\n",
            "2025-05-01 22:01:10 INFO     Epoch 20 [50/781]: loss = 3.219297409057617, lr = 0.0001\n",
            "2025-05-01 22:01:23 INFO     Epoch 20 [100/781]: loss = 3.098992109298706, lr = 0.0001\n",
            "2025-05-01 22:01:37 INFO     Epoch 20 [150/781]: loss = 3.0629827976226807, lr = 0.0001\n",
            "2025-05-01 22:01:51 INFO     Epoch 20 [200/781]: loss = 3.230931520462036, lr = 0.0001\n",
            "2025-05-01 22:02:05 INFO     Epoch 20 [250/781]: loss = 3.4657630920410156, lr = 0.0001\n",
            "2025-05-01 22:02:19 INFO     Epoch 20 [300/781]: loss = 3.376999855041504, lr = 0.0001\n",
            "2025-05-01 22:02:33 INFO     Epoch 20 [350/781]: loss = 2.976005792617798, lr = 0.0001\n",
            "2025-05-01 22:02:47 INFO     Epoch 20 [400/781]: loss = 3.1499197483062744, lr = 0.0001\n",
            "2025-05-01 22:03:01 INFO     Epoch 20 [450/781]: loss = 3.1532270908355713, lr = 0.0001\n",
            "2025-05-01 22:03:14 INFO     Epoch 20 [500/781]: loss = 3.6719439029693604, lr = 0.0001\n",
            "2025-05-01 22:03:28 INFO     Epoch 20 [550/781]: loss = 3.3502254486083984, lr = 0.0001\n",
            "2025-05-01 22:03:42 INFO     Epoch 20 [600/781]: loss = 3.2029855251312256, lr = 0.0001\n",
            "2025-05-01 22:03:56 INFO     Epoch 20 [650/781]: loss = 3.717071533203125, lr = 0.0001\n",
            "2025-05-01 22:04:10 INFO     Epoch 20 [700/781]: loss = 3.373612403869629, lr = 0.0001\n",
            "2025-05-01 22:04:24 INFO     Epoch 20 [750/781]: loss = 3.353398561477661, lr = 0.0001\n",
            "2025-05-01 22:04:33 INFO     Epoch 21 [0/781]: loss = 3.2679035663604736, lr = 0.0001\n",
            "2025-05-01 22:04:47 INFO     Epoch 21 [50/781]: loss = 3.1475038528442383, lr = 0.0001\n",
            "2025-05-01 22:05:01 INFO     Epoch 21 [100/781]: loss = 3.479271650314331, lr = 0.0001\n",
            "2025-05-01 22:05:15 INFO     Epoch 21 [150/781]: loss = 3.3079583644866943, lr = 0.0001\n",
            "2025-05-01 22:05:29 INFO     Epoch 21 [200/781]: loss = 3.319382667541504, lr = 0.0001\n",
            "2025-05-01 22:05:42 INFO     Epoch 21 [250/781]: loss = 3.3092195987701416, lr = 0.0001\n",
            "2025-05-01 22:05:56 INFO     Epoch 21 [300/781]: loss = 2.9986581802368164, lr = 0.0001\n",
            "2025-05-01 22:06:10 INFO     Epoch 21 [350/781]: loss = 3.6241767406463623, lr = 0.0001\n",
            "2025-05-01 22:06:24 INFO     Epoch 21 [400/781]: loss = 2.8183562755584717, lr = 0.0001\n",
            "2025-05-01 22:06:38 INFO     Epoch 21 [450/781]: loss = 3.4637632369995117, lr = 0.0001\n",
            "2025-05-01 22:06:52 INFO     Epoch 21 [500/781]: loss = 3.278752088546753, lr = 0.0001\n",
            "2025-05-01 22:07:06 INFO     Epoch 21 [550/781]: loss = 3.240567445755005, lr = 0.0001\n",
            "2025-05-01 22:07:20 INFO     Epoch 21 [600/781]: loss = 3.320763349533081, lr = 0.0001\n",
            "2025-05-01 22:07:33 INFO     Epoch 21 [650/781]: loss = 2.9763872623443604, lr = 0.0001\n",
            "2025-05-01 22:07:47 INFO     Epoch 21 [700/781]: loss = 3.2001073360443115, lr = 0.0001\n",
            "2025-05-01 22:08:01 INFO     Epoch 21 [750/781]: loss = 3.2620537281036377, lr = 0.0001\n",
            "2025-05-01 22:08:11 INFO     Epoch 22 [0/781]: loss = 3.1358392238616943, lr = 0.0001\n",
            "2025-05-01 22:08:25 INFO     Epoch 22 [50/781]: loss = 3.3579208850860596, lr = 0.0001\n",
            "2025-05-01 22:08:39 INFO     Epoch 22 [100/781]: loss = 3.216771125793457, lr = 0.0001\n",
            "2025-05-01 22:08:52 INFO     Epoch 22 [150/781]: loss = 3.4019439220428467, lr = 0.0001\n",
            "2025-05-01 22:09:06 INFO     Epoch 22 [200/781]: loss = 3.241912841796875, lr = 0.0001\n",
            "2025-05-01 22:09:20 INFO     Epoch 22 [250/781]: loss = 3.589993476867676, lr = 0.0001\n",
            "2025-05-01 22:09:34 INFO     Epoch 22 [300/781]: loss = 3.280574083328247, lr = 0.0001\n",
            "2025-05-01 22:09:48 INFO     Epoch 22 [350/781]: loss = 3.305077314376831, lr = 0.0001\n",
            "2025-05-01 22:10:02 INFO     Epoch 22 [400/781]: loss = 3.09911847114563, lr = 0.0001\n",
            "2025-05-01 22:10:16 INFO     Epoch 22 [450/781]: loss = 3.171186685562134, lr = 0.0001\n",
            "2025-05-01 22:10:30 INFO     Epoch 22 [500/781]: loss = 2.985549211502075, lr = 0.0001\n",
            "2025-05-01 22:10:44 INFO     Epoch 22 [550/781]: loss = 3.2901694774627686, lr = 0.0001\n",
            "2025-05-01 22:10:57 INFO     Epoch 22 [600/781]: loss = 3.2306840419769287, lr = 0.0001\n",
            "2025-05-01 22:11:11 INFO     Epoch 22 [650/781]: loss = 3.2255895137786865, lr = 0.0001\n",
            "2025-05-01 22:11:25 INFO     Epoch 22 [700/781]: loss = 3.3825619220733643, lr = 0.0001\n",
            "2025-05-01 22:11:39 INFO     Epoch 22 [750/781]: loss = 3.5499584674835205, lr = 0.0001\n",
            "2025-05-01 22:11:49 INFO     Epoch 23 [0/781]: loss = 3.2028729915618896, lr = 0.0001\n",
            "2025-05-01 22:12:02 INFO     Epoch 23 [50/781]: loss = 3.2600250244140625, lr = 0.0001\n",
            "2025-05-01 22:12:16 INFO     Epoch 23 [100/781]: loss = 3.3452205657958984, lr = 0.0001\n",
            "2025-05-01 22:12:30 INFO     Epoch 23 [150/781]: loss = 3.058688163757324, lr = 0.0001\n",
            "2025-05-01 22:12:44 INFO     Epoch 23 [200/781]: loss = 3.3542184829711914, lr = 0.0001\n",
            "2025-05-01 22:12:58 INFO     Epoch 23 [250/781]: loss = 3.200005292892456, lr = 0.0001\n",
            "2025-05-01 22:13:12 INFO     Epoch 23 [300/781]: loss = 3.097686767578125, lr = 0.0001\n",
            "2025-05-01 22:13:26 INFO     Epoch 23 [350/781]: loss = 3.333207845687866, lr = 0.0001\n",
            "2025-05-01 22:13:40 INFO     Epoch 23 [400/781]: loss = 3.3978641033172607, lr = 0.0001\n",
            "2025-05-01 22:13:54 INFO     Epoch 23 [450/781]: loss = 3.0494930744171143, lr = 0.0001\n",
            "2025-05-01 22:14:08 INFO     Epoch 23 [500/781]: loss = 3.339693307876587, lr = 0.0001\n",
            "2025-05-01 22:14:22 INFO     Epoch 23 [550/781]: loss = 3.113510847091675, lr = 0.0001\n",
            "2025-05-01 22:14:35 INFO     Epoch 23 [600/781]: loss = 3.295011281967163, lr = 0.0001\n",
            "2025-05-01 22:14:49 INFO     Epoch 23 [650/781]: loss = 3.2219161987304688, lr = 0.0001\n",
            "2025-05-01 22:15:03 INFO     Epoch 23 [700/781]: loss = 2.824315309524536, lr = 0.0001\n",
            "2025-05-01 22:15:17 INFO     Epoch 23 [750/781]: loss = 3.4721755981445312, lr = 0.0001\n",
            "2025-05-01 22:15:27 INFO     Epoch 24 [0/781]: loss = 3.2082550525665283, lr = 0.0001\n",
            "2025-05-01 22:15:41 INFO     Epoch 24 [50/781]: loss = 3.4223792552948, lr = 0.0001\n",
            "2025-05-01 22:15:55 INFO     Epoch 24 [100/781]: loss = 3.3326616287231445, lr = 0.0001\n",
            "2025-05-01 22:16:09 INFO     Epoch 24 [150/781]: loss = 2.895024061203003, lr = 0.0001\n",
            "2025-05-01 22:16:23 INFO     Epoch 24 [200/781]: loss = 3.067056655883789, lr = 0.0001\n",
            "2025-05-01 22:16:37 INFO     Epoch 24 [250/781]: loss = 2.9214696884155273, lr = 0.0001\n",
            "2025-05-01 22:16:50 INFO     Epoch 24 [300/781]: loss = 3.3016233444213867, lr = 0.0001\n",
            "2025-05-01 22:17:04 INFO     Epoch 24 [350/781]: loss = 3.010864019393921, lr = 0.0001\n",
            "2025-05-01 22:17:18 INFO     Epoch 24 [400/781]: loss = 3.1550426483154297, lr = 0.0001\n",
            "2025-05-01 22:17:32 INFO     Epoch 24 [450/781]: loss = 3.438534736633301, lr = 0.0001\n",
            "2025-05-01 22:17:46 INFO     Epoch 24 [500/781]: loss = 3.335555076599121, lr = 0.0001\n",
            "2025-05-01 22:18:00 INFO     Epoch 24 [550/781]: loss = 3.6883199214935303, lr = 0.0001\n",
            "2025-05-01 22:18:14 INFO     Epoch 24 [600/781]: loss = 3.2246720790863037, lr = 0.0001\n",
            "2025-05-01 22:18:28 INFO     Epoch 24 [650/781]: loss = 3.236140012741089, lr = 0.0001\n",
            "2025-05-01 22:18:42 INFO     Epoch 24 [700/781]: loss = 3.056063413619995, lr = 0.0001\n",
            "2025-05-01 22:18:56 INFO     Epoch 24 [750/781]: loss = 3.718461751937866, lr = 0.0001\n",
            "2025-05-01 22:19:05 INFO     Epoch 25 [0/781]: loss = 3.423710584640503, lr = 0.0001\n",
            "2025-05-01 22:19:19 INFO     Epoch 25 [50/781]: loss = 3.3322057723999023, lr = 0.0001\n",
            "2025-05-01 22:19:33 INFO     Epoch 25 [100/781]: loss = 3.4226458072662354, lr = 0.0001\n",
            "2025-05-01 22:19:46 INFO     Epoch 25 [150/781]: loss = 3.2621116638183594, lr = 0.0001\n",
            "2025-05-01 22:20:00 INFO     Epoch 25 [200/781]: loss = 2.8029441833496094, lr = 0.0001\n",
            "2025-05-01 22:20:14 INFO     Epoch 25 [250/781]: loss = 2.798150062561035, lr = 0.0001\n",
            "2025-05-01 22:20:28 INFO     Epoch 25 [300/781]: loss = 3.1506145000457764, lr = 0.0001\n",
            "2025-05-01 22:20:42 INFO     Epoch 25 [350/781]: loss = 3.0933704376220703, lr = 0.0001\n",
            "2025-05-01 22:20:56 INFO     Epoch 25 [400/781]: loss = 3.1463773250579834, lr = 0.0001\n",
            "2025-05-01 22:21:10 INFO     Epoch 25 [450/781]: loss = 3.6748178005218506, lr = 0.0001\n",
            "2025-05-01 22:21:24 INFO     Epoch 25 [500/781]: loss = 3.4380996227264404, lr = 0.0001\n",
            "2025-05-01 22:21:38 INFO     Epoch 25 [550/781]: loss = 3.110901117324829, lr = 0.0001\n",
            "2025-05-01 22:21:52 INFO     Epoch 25 [600/781]: loss = 3.3589401245117188, lr = 0.0001\n",
            "2025-05-01 22:22:05 INFO     Epoch 25 [650/781]: loss = 3.1229398250579834, lr = 0.0001\n",
            "2025-05-01 22:22:19 INFO     Epoch 25 [700/781]: loss = 3.4365131855010986, lr = 0.0001\n",
            "2025-05-01 22:22:33 INFO     Epoch 25 [750/781]: loss = 3.4392988681793213, lr = 0.0001\n",
            "2025-05-01 22:22:43 INFO     Epoch 26 [0/781]: loss = 3.2284905910491943, lr = 0.0001\n",
            "2025-05-01 22:22:56 INFO     Epoch 26 [50/781]: loss = 3.385547637939453, lr = 0.0001\n",
            "2025-05-01 22:23:10 INFO     Epoch 26 [100/781]: loss = 2.9961016178131104, lr = 0.0001\n",
            "2025-05-01 22:23:24 INFO     Epoch 26 [150/781]: loss = 3.281543493270874, lr = 0.0001\n",
            "2025-05-01 22:23:38 INFO     Epoch 26 [200/781]: loss = 3.4255902767181396, lr = 0.0001\n",
            "2025-05-01 22:23:52 INFO     Epoch 26 [250/781]: loss = 3.344942331314087, lr = 0.0001\n",
            "2025-05-01 22:24:06 INFO     Epoch 26 [300/781]: loss = 3.15412974357605, lr = 0.0001\n",
            "2025-05-01 22:24:20 INFO     Epoch 26 [350/781]: loss = 3.3609964847564697, lr = 0.0001\n",
            "2025-05-01 22:24:34 INFO     Epoch 26 [400/781]: loss = 3.388094186782837, lr = 0.0001\n",
            "2025-05-01 22:24:47 INFO     Epoch 26 [450/781]: loss = 3.3647172451019287, lr = 0.0001\n",
            "2025-05-01 22:25:01 INFO     Epoch 26 [500/781]: loss = 3.3946049213409424, lr = 0.0001\n",
            "2025-05-01 22:25:15 INFO     Epoch 26 [550/781]: loss = 3.1401968002319336, lr = 0.0001\n",
            "2025-05-01 22:25:29 INFO     Epoch 26 [600/781]: loss = 3.5657331943511963, lr = 0.0001\n",
            "2025-05-01 22:25:43 INFO     Epoch 26 [650/781]: loss = 3.19461727142334, lr = 0.0001\n",
            "2025-05-01 22:25:57 INFO     Epoch 26 [700/781]: loss = 3.3144237995147705, lr = 0.0001\n",
            "2025-05-01 22:26:11 INFO     Epoch 26 [750/781]: loss = 3.075181245803833, lr = 0.0001\n",
            "2025-05-01 22:26:20 INFO     Epoch 27 [0/781]: loss = 3.096322774887085, lr = 0.0001\n",
            "2025-05-01 22:26:34 INFO     Epoch 27 [50/781]: loss = 3.3033838272094727, lr = 0.0001\n",
            "2025-05-01 22:26:48 INFO     Epoch 27 [100/781]: loss = 3.6404714584350586, lr = 0.0001\n",
            "2025-05-01 22:27:02 INFO     Epoch 27 [150/781]: loss = 3.006187677383423, lr = 0.0001\n",
            "2025-05-01 22:27:16 INFO     Epoch 27 [200/781]: loss = 2.8663175106048584, lr = 0.0001\n",
            "2025-05-01 22:27:30 INFO     Epoch 27 [250/781]: loss = 3.4736671447753906, lr = 0.0001\n",
            "2025-05-01 22:27:44 INFO     Epoch 27 [300/781]: loss = 2.833094358444214, lr = 0.0001\n",
            "2025-05-01 22:27:58 INFO     Epoch 27 [350/781]: loss = 3.1471588611602783, lr = 0.0001\n",
            "2025-05-01 22:28:12 INFO     Epoch 27 [400/781]: loss = 3.156449317932129, lr = 0.0001\n",
            "2025-05-01 22:28:26 INFO     Epoch 27 [450/781]: loss = 2.882862091064453, lr = 0.0001\n",
            "2025-05-01 22:28:39 INFO     Epoch 27 [500/781]: loss = 3.761676073074341, lr = 0.0001\n",
            "2025-05-01 22:28:53 INFO     Epoch 27 [550/781]: loss = 3.384599447250366, lr = 0.0001\n",
            "2025-05-01 22:29:07 INFO     Epoch 27 [600/781]: loss = 3.236567497253418, lr = 0.0001\n",
            "2025-05-01 22:29:21 INFO     Epoch 27 [650/781]: loss = 3.1798808574676514, lr = 0.0001\n",
            "2025-05-01 22:29:35 INFO     Epoch 27 [700/781]: loss = 3.392326593399048, lr = 0.0001\n",
            "2025-05-01 22:29:49 INFO     Epoch 27 [750/781]: loss = 2.948592185974121, lr = 0.0001\n",
            "2025-05-01 22:29:59 INFO     Epoch 28 [0/781]: loss = 3.1650846004486084, lr = 0.0001\n",
            "2025-05-01 22:30:12 INFO     Epoch 28 [50/781]: loss = 2.76924991607666, lr = 0.0001\n",
            "2025-05-01 22:30:26 INFO     Epoch 28 [100/781]: loss = 3.310774087905884, lr = 0.0001\n",
            "2025-05-01 22:30:40 INFO     Epoch 28 [150/781]: loss = 3.1324236392974854, lr = 0.0001\n",
            "2025-05-01 22:30:54 INFO     Epoch 28 [200/781]: loss = 3.0849196910858154, lr = 0.0001\n",
            "2025-05-01 22:31:08 INFO     Epoch 28 [250/781]: loss = 3.663750648498535, lr = 0.0001\n",
            "2025-05-01 22:31:22 INFO     Epoch 28 [300/781]: loss = 3.1041767597198486, lr = 0.0001\n",
            "2025-05-01 22:31:36 INFO     Epoch 28 [350/781]: loss = 2.874363660812378, lr = 0.0001\n",
            "2025-05-01 22:31:50 INFO     Epoch 28 [400/781]: loss = 3.1891019344329834, lr = 0.0001\n",
            "2025-05-01 22:32:04 INFO     Epoch 28 [450/781]: loss = 3.3241827487945557, lr = 0.0001\n",
            "2025-05-01 22:32:18 INFO     Epoch 28 [500/781]: loss = 3.10135817527771, lr = 0.0001\n",
            "2025-05-01 22:32:32 INFO     Epoch 28 [550/781]: loss = 2.8839199542999268, lr = 0.0001\n",
            "2025-05-01 22:32:45 INFO     Epoch 28 [600/781]: loss = 3.1825954914093018, lr = 0.0001\n",
            "2025-05-01 22:32:59 INFO     Epoch 28 [650/781]: loss = 3.338927984237671, lr = 0.0001\n",
            "2025-05-01 22:33:13 INFO     Epoch 28 [700/781]: loss = 3.119523048400879, lr = 0.0001\n",
            "2025-05-01 22:33:27 INFO     Epoch 28 [750/781]: loss = 3.2855818271636963, lr = 0.0001\n",
            "2025-05-01 22:33:37 INFO     Epoch 29 [0/781]: loss = 3.04913067817688, lr = 0.0001\n",
            "2025-05-01 22:33:51 INFO     Epoch 29 [50/781]: loss = 2.971555471420288, lr = 0.0001\n",
            "2025-05-01 22:34:05 INFO     Epoch 29 [100/781]: loss = 2.8294849395751953, lr = 0.0001\n",
            "2025-05-01 22:34:19 INFO     Epoch 29 [150/781]: loss = 3.091432571411133, lr = 0.0001\n",
            "2025-05-01 22:34:33 INFO     Epoch 29 [200/781]: loss = 3.0238616466522217, lr = 0.0001\n",
            "2025-05-01 22:34:46 INFO     Epoch 29 [250/781]: loss = 3.0464792251586914, lr = 0.0001\n",
            "2025-05-01 22:35:00 INFO     Epoch 29 [300/781]: loss = 2.9766337871551514, lr = 0.0001\n",
            "2025-05-01 22:35:14 INFO     Epoch 29 [350/781]: loss = 3.541386365890503, lr = 0.0001\n",
            "2025-05-01 22:35:28 INFO     Epoch 29 [400/781]: loss = 3.3700199127197266, lr = 0.0001\n",
            "2025-05-01 22:35:42 INFO     Epoch 29 [450/781]: loss = 3.0139904022216797, lr = 0.0001\n",
            "2025-05-01 22:35:56 INFO     Epoch 29 [500/781]: loss = 3.037612199783325, lr = 0.0001\n",
            "2025-05-01 22:36:10 INFO     Epoch 29 [550/781]: loss = 3.4737417697906494, lr = 0.0001\n",
            "2025-05-01 22:36:23 INFO     Epoch 29 [600/781]: loss = 3.0569448471069336, lr = 0.0001\n",
            "2025-05-01 22:36:37 INFO     Epoch 29 [650/781]: loss = 3.320511817932129, lr = 0.0001\n",
            "2025-05-01 22:36:51 INFO     Epoch 29 [700/781]: loss = 3.237428665161133, lr = 0.0001\n",
            "2025-05-01 22:37:05 INFO     Epoch 29 [750/781]: loss = 3.6051504611968994, lr = 0.0001\n",
            "2025-05-01 22:37:14 INFO     Epoch 30 [0/781]: loss = 3.1544888019561768, lr = 0.0001\n",
            "2025-05-01 22:37:28 INFO     Epoch 30 [50/781]: loss = 3.465128183364868, lr = 0.0001\n",
            "2025-05-01 22:37:42 INFO     Epoch 30 [100/781]: loss = 3.2076175212860107, lr = 0.0001\n",
            "2025-05-01 22:37:56 INFO     Epoch 30 [150/781]: loss = 3.1453168392181396, lr = 0.0001\n",
            "2025-05-01 22:38:10 INFO     Epoch 30 [200/781]: loss = 3.150663375854492, lr = 0.0001\n",
            "2025-05-01 22:38:24 INFO     Epoch 30 [250/781]: loss = 3.212604522705078, lr = 0.0001\n",
            "2025-05-01 22:38:38 INFO     Epoch 30 [300/781]: loss = 3.2872440814971924, lr = 0.0001\n",
            "2025-05-01 22:38:52 INFO     Epoch 30 [350/781]: loss = 3.340705156326294, lr = 0.0001\n",
            "2025-05-01 22:39:06 INFO     Epoch 30 [400/781]: loss = 3.2085983753204346, lr = 0.0001\n",
            "2025-05-01 22:39:19 INFO     Epoch 30 [450/781]: loss = 3.34770131111145, lr = 0.0001\n",
            "2025-05-01 22:39:33 INFO     Epoch 30 [500/781]: loss = 3.16794490814209, lr = 0.0001\n",
            "2025-05-01 22:39:47 INFO     Epoch 30 [550/781]: loss = 3.213117837905884, lr = 0.0001\n",
            "2025-05-01 22:40:01 INFO     Epoch 30 [600/781]: loss = 3.1197292804718018, lr = 0.0001\n",
            "2025-05-01 22:40:15 INFO     Epoch 30 [650/781]: loss = 3.1303646564483643, lr = 0.0001\n",
            "2025-05-01 22:40:29 INFO     Epoch 30 [700/781]: loss = 3.206939697265625, lr = 0.0001\n",
            "2025-05-01 22:40:43 INFO     Epoch 30 [750/781]: loss = 3.243896484375, lr = 0.0001\n",
            "2025-05-01 22:40:52 INFO     Epoch 31 [0/781]: loss = 3.1429026126861572, lr = 0.0001\n",
            "2025-05-01 22:41:06 INFO     Epoch 31 [50/781]: loss = 3.265101671218872, lr = 0.0001\n",
            "2025-05-01 22:41:20 INFO     Epoch 31 [100/781]: loss = 3.379746198654175, lr = 0.0001\n",
            "2025-05-01 22:41:34 INFO     Epoch 31 [150/781]: loss = 3.2635061740875244, lr = 0.0001\n",
            "2025-05-01 22:41:48 INFO     Epoch 31 [200/781]: loss = 3.00022029876709, lr = 0.0001\n",
            "2025-05-01 22:42:01 INFO     Epoch 31 [250/781]: loss = 3.2364933490753174, lr = 0.0001\n",
            "2025-05-01 22:42:15 INFO     Epoch 31 [300/781]: loss = 3.116607427597046, lr = 0.0001\n",
            "2025-05-01 22:42:29 INFO     Epoch 31 [350/781]: loss = 3.16788387298584, lr = 0.0001\n",
            "2025-05-01 22:42:43 INFO     Epoch 31 [400/781]: loss = 3.1293747425079346, lr = 0.0001\n",
            "2025-05-01 22:42:57 INFO     Epoch 31 [450/781]: loss = 3.3209307193756104, lr = 0.0001\n",
            "2025-05-01 22:43:11 INFO     Epoch 31 [500/781]: loss = 2.991234540939331, lr = 0.0001\n",
            "2025-05-01 22:43:25 INFO     Epoch 31 [550/781]: loss = 3.2659518718719482, lr = 0.0001\n",
            "2025-05-01 22:43:39 INFO     Epoch 31 [600/781]: loss = 3.2183125019073486, lr = 0.0001\n",
            "2025-05-01 22:43:53 INFO     Epoch 31 [650/781]: loss = 3.0878689289093018, lr = 0.0001\n",
            "2025-05-01 22:44:07 INFO     Epoch 31 [700/781]: loss = 3.0899465084075928, lr = 0.0001\n",
            "2025-05-01 22:44:21 INFO     Epoch 31 [750/781]: loss = 3.6534535884857178, lr = 0.0001\n",
            "2025-05-01 22:44:30 INFO     Epoch 32 [0/781]: loss = 3.089252233505249, lr = 0.0001\n",
            "2025-05-01 22:44:44 INFO     Epoch 32 [50/781]: loss = 3.349952459335327, lr = 0.0001\n",
            "2025-05-01 22:44:58 INFO     Epoch 32 [100/781]: loss = 3.30346417427063, lr = 0.0001\n",
            "2025-05-01 22:45:12 INFO     Epoch 32 [150/781]: loss = 3.0936601161956787, lr = 0.0001\n",
            "2025-05-01 22:45:26 INFO     Epoch 32 [200/781]: loss = 3.4916465282440186, lr = 0.0001\n",
            "2025-05-01 22:45:40 INFO     Epoch 32 [250/781]: loss = 3.61712384223938, lr = 0.0001\n",
            "2025-05-01 22:45:54 INFO     Epoch 32 [300/781]: loss = 3.0298874378204346, lr = 0.0001\n",
            "2025-05-01 22:46:07 INFO     Epoch 32 [350/781]: loss = 3.2067692279815674, lr = 0.0001\n",
            "2025-05-01 22:46:21 INFO     Epoch 32 [400/781]: loss = 3.1797351837158203, lr = 0.0001\n",
            "2025-05-01 22:46:35 INFO     Epoch 32 [450/781]: loss = 3.569842576980591, lr = 0.0001\n",
            "2025-05-01 22:46:49 INFO     Epoch 32 [500/781]: loss = 3.0989418029785156, lr = 0.0001\n",
            "2025-05-01 22:47:03 INFO     Epoch 32 [550/781]: loss = 3.2212278842926025, lr = 0.0001\n",
            "2025-05-01 22:47:17 INFO     Epoch 32 [600/781]: loss = 3.6443026065826416, lr = 0.0001\n",
            "2025-05-01 22:47:31 INFO     Epoch 32 [650/781]: loss = 3.1668198108673096, lr = 0.0001\n",
            "2025-05-01 22:47:45 INFO     Epoch 32 [700/781]: loss = 3.47586727142334, lr = 0.0001\n",
            "2025-05-01 22:47:59 INFO     Epoch 32 [750/781]: loss = 3.5067851543426514, lr = 0.0001\n",
            "2025-05-01 22:48:08 INFO     Epoch 33 [0/781]: loss = 2.960632085800171, lr = 0.0001\n",
            "2025-05-01 22:48:22 INFO     Epoch 33 [50/781]: loss = 3.521754264831543, lr = 0.0001\n",
            "2025-05-01 22:48:36 INFO     Epoch 33 [100/781]: loss = 3.2018649578094482, lr = 0.0001\n",
            "2025-05-01 22:48:50 INFO     Epoch 33 [150/781]: loss = 3.3034257888793945, lr = 0.0001\n",
            "2025-05-01 22:49:03 INFO     Epoch 33 [200/781]: loss = 3.444443464279175, lr = 0.0001\n",
            "2025-05-01 22:49:17 INFO     Epoch 33 [250/781]: loss = 3.1322643756866455, lr = 0.0001\n",
            "2025-05-01 22:49:31 INFO     Epoch 33 [300/781]: loss = 3.295315742492676, lr = 0.0001\n",
            "2025-05-01 22:49:45 INFO     Epoch 33 [350/781]: loss = 3.436232566833496, lr = 0.0001\n",
            "2025-05-01 22:49:59 INFO     Epoch 33 [400/781]: loss = 3.308283567428589, lr = 0.0001\n",
            "2025-05-01 22:50:13 INFO     Epoch 33 [450/781]: loss = 2.747145891189575, lr = 0.0001\n",
            "2025-05-01 22:50:27 INFO     Epoch 33 [500/781]: loss = 3.1430435180664062, lr = 0.0001\n",
            "2025-05-01 22:50:41 INFO     Epoch 33 [550/781]: loss = 3.318804979324341, lr = 0.0001\n",
            "2025-05-01 22:50:55 INFO     Epoch 33 [600/781]: loss = 3.4654557704925537, lr = 0.0001\n",
            "2025-05-01 22:51:08 INFO     Epoch 33 [650/781]: loss = 3.4983131885528564, lr = 0.0001\n",
            "2025-05-01 22:51:22 INFO     Epoch 33 [700/781]: loss = 3.0649044513702393, lr = 0.0001\n",
            "2025-05-01 22:51:36 INFO     Epoch 33 [750/781]: loss = 3.691473960876465, lr = 0.0001\n",
            "2025-05-01 22:51:46 INFO     Epoch 34 [0/781]: loss = 3.1389360427856445, lr = 0.0001\n",
            "2025-05-01 22:52:00 INFO     Epoch 34 [50/781]: loss = 3.052917242050171, lr = 0.0001\n",
            "2025-05-01 22:52:14 INFO     Epoch 34 [100/781]: loss = 3.192291259765625, lr = 0.0001\n",
            "2025-05-01 22:52:28 INFO     Epoch 34 [150/781]: loss = 3.315904378890991, lr = 0.0001\n",
            "2025-05-01 22:52:42 INFO     Epoch 34 [200/781]: loss = 3.567291498184204, lr = 0.0001\n",
            "2025-05-01 22:52:56 INFO     Epoch 34 [250/781]: loss = 3.1928117275238037, lr = 0.0001\n",
            "2025-05-01 22:53:09 INFO     Epoch 34 [300/781]: loss = 3.1205012798309326, lr = 0.0001\n",
            "2025-05-01 22:53:23 INFO     Epoch 34 [350/781]: loss = 3.446047067642212, lr = 0.0001\n",
            "2025-05-01 22:53:37 INFO     Epoch 34 [400/781]: loss = 3.1563873291015625, lr = 0.0001\n",
            "2025-05-01 22:53:51 INFO     Epoch 34 [450/781]: loss = 3.0340425968170166, lr = 0.0001\n",
            "2025-05-01 22:54:05 INFO     Epoch 34 [500/781]: loss = 3.4538447856903076, lr = 0.0001\n",
            "2025-05-01 22:54:19 INFO     Epoch 34 [550/781]: loss = 3.316044569015503, lr = 0.0001\n",
            "2025-05-01 22:54:33 INFO     Epoch 34 [600/781]: loss = 3.310669183731079, lr = 0.0001\n",
            "2025-05-01 22:54:47 INFO     Epoch 34 [650/781]: loss = 3.225398302078247, lr = 0.0001\n",
            "2025-05-01 22:55:00 INFO     Epoch 34 [700/781]: loss = 3.1040852069854736, lr = 0.0001\n",
            "2025-05-01 22:55:14 INFO     Epoch 34 [750/781]: loss = 3.080225706100464, lr = 0.0001\n",
            "2025-05-01 22:55:24 INFO     Epoch 35 [0/781]: loss = 2.7424910068511963, lr = 0.0001\n",
            "2025-05-01 22:55:38 INFO     Epoch 35 [50/781]: loss = 3.253904342651367, lr = 0.0001\n",
            "2025-05-01 22:55:52 INFO     Epoch 35 [100/781]: loss = 3.489286184310913, lr = 0.0001\n",
            "2025-05-01 22:56:05 INFO     Epoch 35 [150/781]: loss = 3.1172072887420654, lr = 0.0001\n",
            "2025-05-01 22:56:19 INFO     Epoch 35 [200/781]: loss = 2.927718162536621, lr = 0.0001\n",
            "2025-05-01 22:56:33 INFO     Epoch 35 [250/781]: loss = 3.4641599655151367, lr = 0.0001\n",
            "2025-05-01 22:56:47 INFO     Epoch 35 [300/781]: loss = 2.9767940044403076, lr = 0.0001\n",
            "2025-05-01 22:57:01 INFO     Epoch 35 [350/781]: loss = 3.297179937362671, lr = 0.0001\n",
            "2025-05-01 22:57:15 INFO     Epoch 35 [400/781]: loss = 3.489699363708496, lr = 0.0001\n",
            "2025-05-01 22:57:28 INFO     Epoch 35 [450/781]: loss = 2.754108190536499, lr = 0.0001\n",
            "2025-05-01 22:57:42 INFO     Epoch 35 [500/781]: loss = 3.2517693042755127, lr = 0.0001\n",
            "2025-05-01 22:57:56 INFO     Epoch 35 [550/781]: loss = 3.2208900451660156, lr = 0.0001\n",
            "2025-05-01 22:58:10 INFO     Epoch 35 [600/781]: loss = 3.175475835800171, lr = 0.0001\n",
            "2025-05-01 22:58:24 INFO     Epoch 35 [650/781]: loss = 3.3469295501708984, lr = 0.0001\n",
            "2025-05-01 22:58:38 INFO     Epoch 35 [700/781]: loss = 3.6133315563201904, lr = 0.0001\n",
            "2025-05-01 22:58:51 INFO     Epoch 35 [750/781]: loss = 2.9420995712280273, lr = 0.0001\n",
            "2025-05-01 22:59:01 INFO     Epoch 36 [0/781]: loss = 3.277827262878418, lr = 0.0001\n",
            "2025-05-01 22:59:15 INFO     Epoch 36 [50/781]: loss = 3.2339534759521484, lr = 0.0001\n",
            "2025-05-01 22:59:28 INFO     Epoch 36 [100/781]: loss = 3.197000741958618, lr = 0.0001\n",
            "2025-05-01 22:59:42 INFO     Epoch 36 [150/781]: loss = 3.3730127811431885, lr = 0.0001\n",
            "2025-05-01 22:59:56 INFO     Epoch 36 [200/781]: loss = 3.3295013904571533, lr = 0.0001\n",
            "2025-05-01 23:00:10 INFO     Epoch 36 [250/781]: loss = 3.2406790256500244, lr = 0.0001\n",
            "2025-05-01 23:00:24 INFO     Epoch 36 [300/781]: loss = 2.989224672317505, lr = 0.0001\n",
            "2025-05-01 23:00:38 INFO     Epoch 36 [350/781]: loss = 3.297135353088379, lr = 0.0001\n",
            "2025-05-01 23:00:52 INFO     Epoch 36 [400/781]: loss = 2.891437292098999, lr = 0.0001\n",
            "2025-05-01 23:01:05 INFO     Epoch 36 [450/781]: loss = 3.0813801288604736, lr = 0.0001\n",
            "2025-05-01 23:01:19 INFO     Epoch 36 [500/781]: loss = 3.757863998413086, lr = 0.0001\n",
            "2025-05-01 23:01:33 INFO     Epoch 36 [550/781]: loss = 3.106491804122925, lr = 0.0001\n",
            "2025-05-01 23:01:47 INFO     Epoch 36 [600/781]: loss = 3.318077325820923, lr = 0.0001\n",
            "2025-05-01 23:02:01 INFO     Epoch 36 [650/781]: loss = 3.2180309295654297, lr = 0.0001\n",
            "2025-05-01 23:02:15 INFO     Epoch 36 [700/781]: loss = 3.5046491622924805, lr = 0.0001\n",
            "2025-05-01 23:02:28 INFO     Epoch 36 [750/781]: loss = 3.2195851802825928, lr = 0.0001\n",
            "2025-05-01 23:02:38 INFO     Epoch 37 [0/781]: loss = 3.2213573455810547, lr = 0.0001\n",
            "2025-05-01 23:02:52 INFO     Epoch 37 [50/781]: loss = 3.024090051651001, lr = 0.0001\n",
            "2025-05-01 23:03:05 INFO     Epoch 37 [100/781]: loss = 3.0847482681274414, lr = 0.0001\n",
            "2025-05-01 23:03:19 INFO     Epoch 37 [150/781]: loss = 3.0630123615264893, lr = 0.0001\n",
            "2025-05-01 23:03:33 INFO     Epoch 37 [200/781]: loss = 3.4711530208587646, lr = 0.0001\n",
            "2025-05-01 23:03:47 INFO     Epoch 37 [250/781]: loss = 3.032594919204712, lr = 0.0001\n",
            "2025-05-01 23:04:01 INFO     Epoch 37 [300/781]: loss = 3.031463384628296, lr = 0.0001\n",
            "2025-05-01 23:04:15 INFO     Epoch 37 [350/781]: loss = 3.147249460220337, lr = 0.0001\n",
            "2025-05-01 23:04:29 INFO     Epoch 37 [400/781]: loss = 3.142094850540161, lr = 0.0001\n",
            "2025-05-01 23:04:42 INFO     Epoch 37 [450/781]: loss = 3.4238741397857666, lr = 0.0001\n",
            "2025-05-01 23:04:56 INFO     Epoch 37 [500/781]: loss = 3.34186053276062, lr = 0.0001\n",
            "2025-05-01 23:05:10 INFO     Epoch 37 [550/781]: loss = 3.354022979736328, lr = 0.0001\n",
            "2025-05-01 23:05:24 INFO     Epoch 37 [600/781]: loss = 3.341961145401001, lr = 0.0001\n",
            "2025-05-01 23:05:38 INFO     Epoch 37 [650/781]: loss = 2.8736307621002197, lr = 0.0001\n",
            "2025-05-01 23:05:52 INFO     Epoch 37 [700/781]: loss = 3.1698427200317383, lr = 0.0001\n",
            "2025-05-01 23:06:05 INFO     Epoch 37 [750/781]: loss = 3.1665704250335693, lr = 0.0001\n",
            "2025-05-01 23:06:15 INFO     Epoch 38 [0/781]: loss = 3.487863302230835, lr = 0.0001\n",
            "2025-05-01 23:06:29 INFO     Epoch 38 [50/781]: loss = 3.3995144367218018, lr = 0.0001\n",
            "2025-05-01 23:06:43 INFO     Epoch 38 [100/781]: loss = 2.8033955097198486, lr = 0.0001\n",
            "2025-05-01 23:06:56 INFO     Epoch 38 [150/781]: loss = 3.326767921447754, lr = 0.0001\n",
            "2025-05-01 23:07:10 INFO     Epoch 38 [200/781]: loss = 3.203406572341919, lr = 0.0001\n",
            "2025-05-01 23:07:24 INFO     Epoch 38 [250/781]: loss = 3.3214962482452393, lr = 0.0001\n",
            "2025-05-01 23:07:38 INFO     Epoch 38 [300/781]: loss = 3.4630143642425537, lr = 0.0001\n",
            "2025-05-01 23:07:52 INFO     Epoch 38 [350/781]: loss = 3.3780813217163086, lr = 0.0001\n",
            "2025-05-01 23:08:06 INFO     Epoch 38 [400/781]: loss = 3.3912670612335205, lr = 0.0001\n",
            "2025-05-01 23:08:19 INFO     Epoch 38 [450/781]: loss = 3.199031114578247, lr = 0.0001\n",
            "2025-05-01 23:08:33 INFO     Epoch 38 [500/781]: loss = 2.9001896381378174, lr = 0.0001\n",
            "2025-05-01 23:08:47 INFO     Epoch 38 [550/781]: loss = 3.1830151081085205, lr = 0.0001\n",
            "2025-05-01 23:09:01 INFO     Epoch 38 [600/781]: loss = 3.036902666091919, lr = 0.0001\n",
            "2025-05-01 23:09:15 INFO     Epoch 38 [650/781]: loss = 3.001880645751953, lr = 0.0001\n",
            "2025-05-01 23:09:29 INFO     Epoch 38 [700/781]: loss = 3.1611506938934326, lr = 0.0001\n",
            "2025-05-01 23:09:43 INFO     Epoch 38 [750/781]: loss = 3.4250574111938477, lr = 0.0001\n",
            "2025-05-01 23:09:52 INFO     Epoch 39 [0/781]: loss = 3.038759231567383, lr = 0.0001\n",
            "2025-05-01 23:10:06 INFO     Epoch 39 [50/781]: loss = 3.156651735305786, lr = 0.0001\n",
            "2025-05-01 23:10:20 INFO     Epoch 39 [100/781]: loss = 3.2888543605804443, lr = 0.0001\n",
            "2025-05-01 23:10:34 INFO     Epoch 39 [150/781]: loss = 3.2036876678466797, lr = 0.0001\n",
            "2025-05-01 23:10:48 INFO     Epoch 39 [200/781]: loss = 3.056554079055786, lr = 0.0001\n",
            "2025-05-01 23:11:02 INFO     Epoch 39 [250/781]: loss = 3.28629207611084, lr = 0.0001\n",
            "2025-05-01 23:11:16 INFO     Epoch 39 [300/781]: loss = 3.060985803604126, lr = 0.0001\n",
            "2025-05-01 23:11:30 INFO     Epoch 39 [350/781]: loss = 3.1735565662384033, lr = 0.0001\n",
            "2025-05-01 23:11:43 INFO     Epoch 39 [400/781]: loss = 3.328972578048706, lr = 0.0001\n",
            "2025-05-01 23:11:57 INFO     Epoch 39 [450/781]: loss = 3.3506195545196533, lr = 0.0001\n",
            "2025-05-01 23:12:11 INFO     Epoch 39 [500/781]: loss = 3.2499148845672607, lr = 0.0001\n",
            "2025-05-01 23:12:25 INFO     Epoch 39 [550/781]: loss = 3.2638301849365234, lr = 0.0001\n",
            "2025-05-01 23:12:39 INFO     Epoch 39 [600/781]: loss = 3.174123764038086, lr = 0.0001\n",
            "2025-05-01 23:12:53 INFO     Epoch 39 [650/781]: loss = 2.897413969039917, lr = 0.0001\n",
            "2025-05-01 23:13:07 INFO     Epoch 39 [700/781]: loss = 3.3202407360076904, lr = 0.0001\n",
            "2025-05-01 23:13:20 INFO     Epoch 39 [750/781]: loss = 3.5132627487182617, lr = 0.0001\n",
            "2025-05-01 23:13:30 INFO     Epoch 40 [0/781]: loss = 2.919194221496582, lr = 0.0001\n",
            "2025-05-01 23:13:44 INFO     Epoch 40 [50/781]: loss = 3.2610714435577393, lr = 0.0001\n",
            "2025-05-01 23:13:57 INFO     Epoch 40 [100/781]: loss = 3.334383249282837, lr = 0.0001\n",
            "2025-05-01 23:14:11 INFO     Epoch 40 [150/781]: loss = 3.043156385421753, lr = 0.0001\n",
            "2025-05-01 23:14:25 INFO     Epoch 40 [200/781]: loss = 3.5275871753692627, lr = 0.0001\n",
            "2025-05-01 23:14:39 INFO     Epoch 40 [250/781]: loss = 3.4827098846435547, lr = 0.0001\n",
            "2025-05-01 23:14:53 INFO     Epoch 40 [300/781]: loss = 3.4198362827301025, lr = 0.0001\n",
            "2025-05-01 23:15:07 INFO     Epoch 40 [350/781]: loss = 3.084158182144165, lr = 0.0001\n",
            "2025-05-01 23:15:21 INFO     Epoch 40 [400/781]: loss = 3.3680009841918945, lr = 0.0001\n",
            "2025-05-01 23:15:35 INFO     Epoch 40 [450/781]: loss = 3.1458375453948975, lr = 0.0001\n",
            "2025-05-01 23:15:49 INFO     Epoch 40 [500/781]: loss = 3.311594009399414, lr = 0.0001\n",
            "2025-05-01 23:16:03 INFO     Epoch 40 [550/781]: loss = 3.2572813034057617, lr = 0.0001\n",
            "2025-05-01 23:16:17 INFO     Epoch 40 [600/781]: loss = 3.1864101886749268, lr = 0.0001\n",
            "2025-05-01 23:16:30 INFO     Epoch 40 [650/781]: loss = 2.8591277599334717, lr = 0.0001\n",
            "2025-05-01 23:16:44 INFO     Epoch 40 [700/781]: loss = 3.344350576400757, lr = 0.0001\n",
            "2025-05-01 23:16:58 INFO     Epoch 40 [750/781]: loss = 3.6077778339385986, lr = 0.0001\n",
            "2025-05-01 23:17:09 INFO     Epoch 41 [0/781]: loss = 3.040682792663574, lr = 0.0001\n",
            "2025-05-01 23:17:23 INFO     Epoch 41 [50/781]: loss = 3.142683982849121, lr = 0.0001\n",
            "2025-05-01 23:17:37 INFO     Epoch 41 [100/781]: loss = 3.516099691390991, lr = 0.0001\n",
            "2025-05-01 23:17:51 INFO     Epoch 41 [150/781]: loss = 3.246373176574707, lr = 0.0001\n",
            "2025-05-01 23:18:05 INFO     Epoch 41 [200/781]: loss = 3.0055580139160156, lr = 0.0001\n",
            "2025-05-01 23:18:19 INFO     Epoch 41 [250/781]: loss = 3.1410534381866455, lr = 0.0001\n",
            "2025-05-01 23:18:33 INFO     Epoch 41 [300/781]: loss = 3.105455160140991, lr = 0.0001\n",
            "2025-05-01 23:18:47 INFO     Epoch 41 [350/781]: loss = 3.1354589462280273, lr = 0.0001\n",
            "2025-05-01 23:19:01 INFO     Epoch 41 [400/781]: loss = 3.2230730056762695, lr = 0.0001\n",
            "2025-05-01 23:19:15 INFO     Epoch 41 [450/781]: loss = 2.976837158203125, lr = 0.0001\n",
            "2025-05-01 23:19:29 INFO     Epoch 41 [500/781]: loss = 3.136969804763794, lr = 0.0001\n",
            "2025-05-01 23:19:43 INFO     Epoch 41 [550/781]: loss = 3.1242618560791016, lr = 0.0001\n",
            "2025-05-01 23:19:57 INFO     Epoch 41 [600/781]: loss = 3.2396554946899414, lr = 0.0001\n",
            "2025-05-01 23:20:11 INFO     Epoch 41 [650/781]: loss = 3.4519479274749756, lr = 0.0001\n",
            "2025-05-01 23:20:25 INFO     Epoch 41 [700/781]: loss = 3.239732503890991, lr = 0.0001\n",
            "2025-05-01 23:20:39 INFO     Epoch 41 [750/781]: loss = 3.2614755630493164, lr = 0.0001\n",
            "2025-05-01 23:20:48 INFO     Epoch 42 [0/781]: loss = 2.891733407974243, lr = 0.0001\n",
            "2025-05-01 23:21:02 INFO     Epoch 42 [50/781]: loss = 3.360753059387207, lr = 0.0001\n",
            "2025-05-01 23:21:16 INFO     Epoch 42 [100/781]: loss = 3.477365255355835, lr = 0.0001\n",
            "2025-05-01 23:21:30 INFO     Epoch 42 [150/781]: loss = 3.4117307662963867, lr = 0.0001\n",
            "2025-05-01 23:21:44 INFO     Epoch 42 [200/781]: loss = 3.1681792736053467, lr = 0.0001\n",
            "2025-05-01 23:21:58 INFO     Epoch 42 [250/781]: loss = 3.559673309326172, lr = 0.0001\n",
            "2025-05-01 23:22:11 INFO     Epoch 42 [300/781]: loss = 3.3794872760772705, lr = 0.0001\n",
            "2025-05-01 23:22:25 INFO     Epoch 42 [350/781]: loss = 3.001021146774292, lr = 0.0001\n",
            "2025-05-01 23:22:39 INFO     Epoch 42 [400/781]: loss = 3.232050895690918, lr = 0.0001\n",
            "2025-05-01 23:22:53 INFO     Epoch 42 [450/781]: loss = 3.2702977657318115, lr = 0.0001\n",
            "2025-05-01 23:23:07 INFO     Epoch 42 [500/781]: loss = 2.897568464279175, lr = 0.0001\n",
            "2025-05-01 23:23:21 INFO     Epoch 42 [550/781]: loss = 3.2933599948883057, lr = 0.0001\n",
            "2025-05-01 23:23:35 INFO     Epoch 42 [600/781]: loss = 3.4584152698516846, lr = 0.0001\n",
            "2025-05-01 23:23:48 INFO     Epoch 42 [650/781]: loss = 2.9082326889038086, lr = 0.0001\n",
            "2025-05-01 23:24:02 INFO     Epoch 42 [700/781]: loss = 3.2891435623168945, lr = 0.0001\n",
            "2025-05-01 23:24:16 INFO     Epoch 42 [750/781]: loss = 3.340574264526367, lr = 0.0001\n",
            "2025-05-01 23:24:26 INFO     Epoch 43 [0/781]: loss = 3.111379384994507, lr = 0.0001\n",
            "2025-05-01 23:24:39 INFO     Epoch 43 [50/781]: loss = 3.5370891094207764, lr = 0.0001\n",
            "2025-05-01 23:24:53 INFO     Epoch 43 [100/781]: loss = 3.08233904838562, lr = 0.0001\n",
            "2025-05-01 23:25:07 INFO     Epoch 43 [150/781]: loss = 2.917128562927246, lr = 0.0001\n",
            "2025-05-01 23:25:21 INFO     Epoch 43 [200/781]: loss = 2.9346208572387695, lr = 0.0001\n",
            "2025-05-01 23:25:35 INFO     Epoch 43 [250/781]: loss = 3.3192508220672607, lr = 0.0001\n",
            "2025-05-01 23:25:49 INFO     Epoch 43 [300/781]: loss = 3.4172699451446533, lr = 0.0001\n",
            "2025-05-01 23:26:03 INFO     Epoch 43 [350/781]: loss = 3.1811630725860596, lr = 0.0001\n",
            "2025-05-01 23:26:17 INFO     Epoch 43 [400/781]: loss = 3.178037643432617, lr = 0.0001\n",
            "2025-05-01 23:26:31 INFO     Epoch 43 [450/781]: loss = 3.0140864849090576, lr = 0.0001\n",
            "2025-05-01 23:26:44 INFO     Epoch 43 [500/781]: loss = 3.184687614440918, lr = 0.0001\n",
            "2025-05-01 23:26:58 INFO     Epoch 43 [550/781]: loss = 3.5384585857391357, lr = 0.0001\n",
            "2025-05-01 23:27:12 INFO     Epoch 43 [600/781]: loss = 3.06597900390625, lr = 0.0001\n",
            "2025-05-01 23:27:26 INFO     Epoch 43 [650/781]: loss = 3.3323371410369873, lr = 0.0001\n",
            "2025-05-01 23:27:40 INFO     Epoch 43 [700/781]: loss = 3.5401451587677, lr = 0.0001\n",
            "2025-05-01 23:27:54 INFO     Epoch 43 [750/781]: loss = 2.9874417781829834, lr = 0.0001\n",
            "2025-05-01 23:28:03 INFO     Epoch 44 [0/781]: loss = 3.30080246925354, lr = 0.0001\n",
            "2025-05-01 23:28:17 INFO     Epoch 44 [50/781]: loss = 3.0701076984405518, lr = 0.0001\n",
            "2025-05-01 23:28:31 INFO     Epoch 44 [100/781]: loss = 2.7859184741973877, lr = 0.0001\n",
            "2025-05-01 23:28:45 INFO     Epoch 44 [150/781]: loss = 3.0460922718048096, lr = 0.0001\n",
            "2025-05-01 23:28:59 INFO     Epoch 44 [200/781]: loss = 3.3794984817504883, lr = 0.0001\n",
            "2025-05-01 23:29:13 INFO     Epoch 44 [250/781]: loss = 2.967562675476074, lr = 0.0001\n",
            "2025-05-01 23:29:26 INFO     Epoch 44 [300/781]: loss = 3.156057596206665, lr = 0.0001\n",
            "2025-05-01 23:29:40 INFO     Epoch 44 [350/781]: loss = 3.8321425914764404, lr = 0.0001\n",
            "2025-05-01 23:29:54 INFO     Epoch 44 [400/781]: loss = 3.2037317752838135, lr = 0.0001\n",
            "2025-05-01 23:30:08 INFO     Epoch 44 [450/781]: loss = 3.277803659439087, lr = 0.0001\n",
            "2025-05-01 23:30:22 INFO     Epoch 44 [500/781]: loss = 3.320669412612915, lr = 0.0001\n",
            "2025-05-01 23:30:36 INFO     Epoch 44 [550/781]: loss = 2.7291061878204346, lr = 0.0001\n",
            "2025-05-01 23:30:50 INFO     Epoch 44 [600/781]: loss = 3.487272262573242, lr = 0.0001\n",
            "2025-05-01 23:31:04 INFO     Epoch 44 [650/781]: loss = 3.431600332260132, lr = 0.0001\n",
            "2025-05-01 23:31:17 INFO     Epoch 44 [700/781]: loss = 3.0282347202301025, lr = 0.0001\n",
            "2025-05-01 23:31:31 INFO     Epoch 44 [750/781]: loss = 3.0676403045654297, lr = 0.0001\n",
            "2025-05-01 23:31:41 INFO     Epoch 45 [0/781]: loss = 2.928666114807129, lr = 0.0001\n",
            "2025-05-01 23:31:55 INFO     Epoch 45 [50/781]: loss = 3.1994457244873047, lr = 0.0001\n",
            "2025-05-01 23:32:09 INFO     Epoch 45 [100/781]: loss = 3.1495485305786133, lr = 0.0001\n",
            "2025-05-01 23:32:23 INFO     Epoch 45 [150/781]: loss = 2.93479061126709, lr = 0.0001\n",
            "2025-05-01 23:32:37 INFO     Epoch 45 [200/781]: loss = 3.229278802871704, lr = 0.0001\n",
            "2025-05-01 23:32:50 INFO     Epoch 45 [250/781]: loss = 3.087162971496582, lr = 0.0001\n",
            "2025-05-01 23:33:04 INFO     Epoch 45 [300/781]: loss = 3.3986217975616455, lr = 0.0001\n",
            "2025-05-01 23:33:18 INFO     Epoch 45 [350/781]: loss = 3.244191884994507, lr = 0.0001\n",
            "2025-05-01 23:33:32 INFO     Epoch 45 [400/781]: loss = 3.2202017307281494, lr = 0.0001\n",
            "2025-05-01 23:33:46 INFO     Epoch 45 [450/781]: loss = 3.0737812519073486, lr = 0.0001\n",
            "2025-05-01 23:34:00 INFO     Epoch 45 [500/781]: loss = 3.233112335205078, lr = 0.0001\n",
            "2025-05-01 23:34:13 INFO     Epoch 45 [550/781]: loss = 3.199185609817505, lr = 0.0001\n",
            "2025-05-01 23:34:27 INFO     Epoch 45 [600/781]: loss = 3.1994102001190186, lr = 0.0001\n",
            "2025-05-01 23:34:41 INFO     Epoch 45 [650/781]: loss = 3.2073421478271484, lr = 0.0001\n",
            "2025-05-01 23:34:55 INFO     Epoch 45 [700/781]: loss = 2.7891712188720703, lr = 0.0001\n",
            "2025-05-01 23:35:09 INFO     Epoch 45 [750/781]: loss = 3.0627620220184326, lr = 0.0001\n",
            "2025-05-01 23:35:18 INFO     Epoch 46 [0/781]: loss = 3.052657127380371, lr = 0.0001\n",
            "2025-05-01 23:35:32 INFO     Epoch 46 [50/781]: loss = 3.4583346843719482, lr = 0.0001\n",
            "2025-05-01 23:35:46 INFO     Epoch 46 [100/781]: loss = 3.704071044921875, lr = 0.0001\n",
            "2025-05-01 23:36:00 INFO     Epoch 46 [150/781]: loss = 3.121236562728882, lr = 0.0001\n",
            "2025-05-01 23:36:14 INFO     Epoch 46 [200/781]: loss = 3.078899383544922, lr = 0.0001\n",
            "2025-05-01 23:36:28 INFO     Epoch 46 [250/781]: loss = 3.0214145183563232, lr = 0.0001\n",
            "2025-05-01 23:36:41 INFO     Epoch 46 [300/781]: loss = 3.281481981277466, lr = 0.0001\n",
            "2025-05-01 23:36:55 INFO     Epoch 46 [350/781]: loss = 3.131657838821411, lr = 0.0001\n",
            "2025-05-01 23:37:09 INFO     Epoch 46 [400/781]: loss = 3.1117022037506104, lr = 0.0001\n",
            "2025-05-01 23:37:23 INFO     Epoch 46 [450/781]: loss = 3.041822671890259, lr = 0.0001\n",
            "2025-05-01 23:37:37 INFO     Epoch 46 [500/781]: loss = 2.9981133937835693, lr = 0.0001\n",
            "2025-05-01 23:37:51 INFO     Epoch 46 [550/781]: loss = 2.977900505065918, lr = 0.0001\n",
            "2025-05-01 23:38:05 INFO     Epoch 46 [600/781]: loss = 3.195340871810913, lr = 0.0001\n",
            "2025-05-01 23:38:18 INFO     Epoch 46 [650/781]: loss = 3.0574381351470947, lr = 0.0001\n",
            "2025-05-01 23:38:32 INFO     Epoch 46 [700/781]: loss = 3.2792351245880127, lr = 0.0001\n",
            "2025-05-01 23:38:46 INFO     Epoch 46 [750/781]: loss = 3.0022246837615967, lr = 0.0001\n",
            "2025-05-01 23:38:56 INFO     Epoch 47 [0/781]: loss = 3.1248586177825928, lr = 0.0001\n",
            "2025-05-01 23:39:10 INFO     Epoch 47 [50/781]: loss = 3.3893356323242188, lr = 0.0001\n",
            "2025-05-01 23:39:24 INFO     Epoch 47 [100/781]: loss = 2.911130905151367, lr = 0.0001\n",
            "2025-05-01 23:39:38 INFO     Epoch 47 [150/781]: loss = 2.979275703430176, lr = 0.0001\n",
            "2025-05-01 23:39:52 INFO     Epoch 47 [200/781]: loss = 3.2775719165802, lr = 0.0001\n",
            "2025-05-01 23:40:05 INFO     Epoch 47 [250/781]: loss = 3.0719430446624756, lr = 0.0001\n",
            "2025-05-01 23:40:19 INFO     Epoch 47 [300/781]: loss = 2.9862449169158936, lr = 0.0001\n",
            "2025-05-01 23:40:33 INFO     Epoch 47 [350/781]: loss = 2.8380489349365234, lr = 0.0001\n",
            "2025-05-01 23:40:47 INFO     Epoch 47 [400/781]: loss = 2.950455904006958, lr = 0.0001\n",
            "2025-05-01 23:41:01 INFO     Epoch 47 [450/781]: loss = 3.4899470806121826, lr = 0.0001\n",
            "2025-05-01 23:41:15 INFO     Epoch 47 [500/781]: loss = 3.249727487564087, lr = 0.0001\n",
            "2025-05-01 23:41:28 INFO     Epoch 47 [550/781]: loss = 3.030101776123047, lr = 0.0001\n",
            "2025-05-01 23:41:42 INFO     Epoch 47 [600/781]: loss = 2.957601547241211, lr = 0.0001\n",
            "2025-05-01 23:41:56 INFO     Epoch 47 [650/781]: loss = 3.695183515548706, lr = 0.0001\n",
            "2025-05-01 23:42:10 INFO     Epoch 47 [700/781]: loss = 3.1621742248535156, lr = 0.0001\n",
            "2025-05-01 23:42:24 INFO     Epoch 47 [750/781]: loss = 3.1614513397216797, lr = 0.0001\n",
            "2025-05-01 23:42:33 INFO     Epoch 48 [0/781]: loss = 3.038649320602417, lr = 0.0001\n",
            "2025-05-01 23:42:47 INFO     Epoch 48 [50/781]: loss = 2.8760483264923096, lr = 0.0001\n",
            "2025-05-01 23:43:01 INFO     Epoch 48 [100/781]: loss = 2.3970677852630615, lr = 0.0001\n",
            "2025-05-01 23:43:15 INFO     Epoch 48 [150/781]: loss = 3.1643545627593994, lr = 0.0001\n",
            "2025-05-01 23:43:29 INFO     Epoch 48 [200/781]: loss = 2.584399938583374, lr = 0.0001\n",
            "2025-05-01 23:43:42 INFO     Epoch 48 [250/781]: loss = 3.099865198135376, lr = 0.0001\n",
            "2025-05-01 23:43:56 INFO     Epoch 48 [300/781]: loss = 3.0607388019561768, lr = 0.0001\n",
            "2025-05-01 23:44:10 INFO     Epoch 48 [350/781]: loss = 3.0654208660125732, lr = 0.0001\n",
            "2025-05-01 23:44:24 INFO     Epoch 48 [400/781]: loss = 3.502119302749634, lr = 0.0001\n",
            "2025-05-01 23:44:38 INFO     Epoch 48 [450/781]: loss = 3.3694241046905518, lr = 0.0001\n",
            "2025-05-01 23:44:52 INFO     Epoch 48 [500/781]: loss = 3.145167589187622, lr = 0.0001\n",
            "2025-05-01 23:45:06 INFO     Epoch 48 [550/781]: loss = 3.5327396392822266, lr = 0.0001\n",
            "2025-05-01 23:45:19 INFO     Epoch 48 [600/781]: loss = 3.1100635528564453, lr = 0.0001\n",
            "2025-05-01 23:45:33 INFO     Epoch 48 [650/781]: loss = 3.0025341510772705, lr = 0.0001\n",
            "2025-05-01 23:45:47 INFO     Epoch 48 [700/781]: loss = 3.4957635402679443, lr = 0.0001\n",
            "2025-05-01 23:46:01 INFO     Epoch 48 [750/781]: loss = 3.3330395221710205, lr = 0.0001\n",
            "2025-05-01 23:46:10 INFO     Epoch 49 [0/781]: loss = 2.703444242477417, lr = 0.0001\n",
            "2025-05-01 23:46:24 INFO     Epoch 49 [50/781]: loss = 3.318965196609497, lr = 0.0001\n",
            "2025-05-01 23:46:38 INFO     Epoch 49 [100/781]: loss = 3.0165903568267822, lr = 0.0001\n",
            "2025-05-01 23:46:52 INFO     Epoch 49 [150/781]: loss = 3.312258720397949, lr = 0.0001\n",
            "2025-05-01 23:47:06 INFO     Epoch 49 [200/781]: loss = 3.0095794200897217, lr = 0.0001\n",
            "2025-05-01 23:47:20 INFO     Epoch 49 [250/781]: loss = 3.2719268798828125, lr = 0.0001\n",
            "2025-05-01 23:47:33 INFO     Epoch 49 [300/781]: loss = 3.2988550662994385, lr = 0.0001\n",
            "2025-05-01 23:47:47 INFO     Epoch 49 [350/781]: loss = 3.24515700340271, lr = 0.0001\n",
            "2025-05-01 23:48:01 INFO     Epoch 49 [400/781]: loss = 3.271562337875366, lr = 0.0001\n",
            "2025-05-01 23:48:15 INFO     Epoch 49 [450/781]: loss = 3.113335371017456, lr = 0.0001\n",
            "2025-05-01 23:48:29 INFO     Epoch 49 [500/781]: loss = 3.3456881046295166, lr = 0.0001\n",
            "2025-05-01 23:48:43 INFO     Epoch 49 [550/781]: loss = 3.042523145675659, lr = 0.0001\n",
            "2025-05-01 23:48:56 INFO     Epoch 49 [600/781]: loss = 3.31830096244812, lr = 0.0001\n",
            "2025-05-01 23:49:10 INFO     Epoch 49 [650/781]: loss = 3.002218008041382, lr = 0.0001\n",
            "2025-05-01 23:49:24 INFO     Epoch 49 [700/781]: loss = 3.091057062149048, lr = 0.0001\n",
            "2025-05-01 23:49:38 INFO     Epoch 49 [750/781]: loss = 3.1723995208740234, lr = 0.0001\n",
            "2025-05-01 23:49:47 INFO     EMA: Switching from train to eval, backing up parameters and copying EMA params\n",
            "Downloading: \"https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth\n",
            "100% 91.2M/91.2M [00:00<00:00, 276MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/flow_matching/examples/image/train.py\", line 224, in <module>\n",
            "    main(args)\n",
            "  File \"/content/flow_matching/examples/image/train.py\", line 195, in main\n",
            "    eval_stats = eval_model(\n",
            "                 ^^^^^^^^^^^\n",
            "  File \"/content/flow_matching/examples/image/training/eval_loop.py\", line 138, in eval_model\n",
            "    synthetic_samples = solver.sample(\n",
            "                        ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flow_matching/solver/discrete_solver.py\", line 186, in sample\n",
            "    p_1t = self.model(x=x_t, t=t.repeat(x_t.shape[0]), **model_extras)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/flow_matching/examples/image/training/eval_loop.py\", line 53, in forward\n",
            "    cfg_scale == 0.0 or not is_discrete\n",
            "AssertionError: Cfg scaling does not work for the logit outputs of discrete models. Got cfg weight=0.2 and model <class 'models.ema.EMA'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Resume training:\n",
        "!python train.py \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=64 \\\n",
        "    --accum_iter=1 \\\n",
        "    --eval_frequency=50 \\\n",
        "    --epochs=500 \\\n",
        "    --use_ema \\\n",
        "    --discrete_flow_matching \\\n",
        "    --output_dir='/content/drive/MyDrive/flow_matching_checkpoints' \\\n",
        "    --resume='/content/drive/MyDrive/flow_matching_checkpoints/checkpoint_epoch_200.pth'"
      ],
      "metadata": {
        "id": "8h5TmsYdm8Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset cifar10 --output_dir output_cifar10 --batch_size 64 --accum_iter=1 --eval_frequency=100 --epochs=3000 --class_drop_prob=1.0 --cfg_scale=0.0 --compute_fid --ode_method heun2 --ode_options '{\"nfe\": 50}' --use_ema --edm_schedule --skewed_timesteps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JvqNqDftWtS",
        "outputId": "02975d3f-6d60-49a2-80a4-5d3e43f7fe92"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not using distributed mode\n",
            "2025-04-17 08:53:07 INFO     job dir: /content/flow_matching/examples/image\n",
            "2025-04-17 08:53:07 INFO     Namespace(batch_size=64,\n",
            "epochs=3000,\n",
            "accum_iter=1,\n",
            "lr=0.0001,\n",
            "optimizer_betas=[0.9,\n",
            "0.95],\n",
            "decay_lr=False,\n",
            "class_drop_prob=1.0,\n",
            "skewed_timesteps=True,\n",
            "edm_schedule=True,\n",
            "use_ema=True,\n",
            "dataset='cifar10',\n",
            "data_path='./data/image_generation',\n",
            "output_dir='output_cifar10',\n",
            "ode_method='heun2',\n",
            "ode_options={'nfe': 50},\n",
            "sym=0.0,\n",
            "temp=1.0,\n",
            "sym_func=False,\n",
            "sampling_dtype='float32',\n",
            "cfg_scale=0.0,\n",
            "fid_samples=50000,\n",
            "device='cuda',\n",
            "seed=0,\n",
            "resume='',\n",
            "start_epoch=0,\n",
            "eval_only=False,\n",
            "eval_frequency=100,\n",
            "compute_fid=True,\n",
            "save_fid_samples=False,\n",
            "num_workers=10,\n",
            "pin_mem=True,\n",
            "world_size=1,\n",
            "local_rank=-1,\n",
            "dist_on_itp=False,\n",
            "dist_url='env://',\n",
            "test_run=False,\n",
            "discrete_flow_matching=False,\n",
            "discrete_fm_steps=1024,\n",
            "distributed=False)\n",
            "2025-04-17 08:53:07 INFO     Saving args to output_cifar10/args.json\n",
            "2025-04-17 08:53:07 INFO     Initializing Dataset: cifar10\n",
            "100% 170M/170M [00:04<00:00, 41.0MB/s]\n",
            "2025-04-17 08:53:14 INFO     Dataset CIFAR10\n",
            "    Number of datapoints: 50000\n",
            "    Root location: ./data/image_generation\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "                 ToImage()\n",
            "                 RandomHorizontalFlip(p=0.5)\n",
            "                 ToDtype(scale=True)\n",
            "           )\n",
            "2025-04-17 08:53:14 INFO     Intializing DataLoader\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2025-04-17 08:53:14 INFO     <torch.utils.data.distributed.DistributedSampler object at 0x7bc46a52b410>\n",
            "2025-04-17 08:53:14 INFO     Initializing Model\n",
            "2025-04-17 08:53:15 INFO     EMA(\n",
            "  (model): UNetModel(in_channels=3, model_channels=128, out_channels=3, num_res_blocks=4, attention_resolutions=[2], dropout=0.3, channel_mult=[2, 2, 2], conv_resample=False, dims=2, num_classes=None, use_checkpoint=False, num_heads=1, num_head_channels=-1, num_heads_upsample=1, use_scale_shift_norm=True, resblock_updown=False, use_new_attention_order=True, with_fourier_features=False, ignore_time=False, input_projection=True, image_size=-1, _target_='lib.models.gd_unet.UNetModel')\n",
            "  (shadow_params): ParameterList(\n",
            "      (0): Parameter containing: [torch.float32 of size 512x128 (cuda:0)]\n",
            "      (1): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (2): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (3): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (4): Parameter containing: [torch.float32 of size 256x3x3x3 (cuda:0)]\n",
            "      (5): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (6): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (7): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (8): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (9): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (10): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (11): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (12): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (13): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (14): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (15): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (16): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (17): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (18): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (19): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (20): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (21): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (22): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (23): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (24): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (25): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (26): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (27): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (28): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (29): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (30): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (31): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (32): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (33): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (34): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (35): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (36): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (37): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (38): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (39): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (40): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (41): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (42): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (43): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (44): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (45): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (46): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (47): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (48): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (49): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (50): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (51): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (52): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (53): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (54): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (55): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (56): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (57): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (58): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (59): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (60): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (61): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (62): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (63): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (64): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (65): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (66): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (67): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (68): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (69): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (70): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (71): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (72): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (73): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (74): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (75): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (76): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (77): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (78): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (79): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (80): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (81): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (82): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (83): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (84): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (85): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (86): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (87): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (88): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (89): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (90): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (91): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (92): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (93): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (94): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (95): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (96): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (97): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (98): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (99): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (100): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (101): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (102): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (103): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (104): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (105): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (106): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (107): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (108): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (109): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (110): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (111): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (112): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (113): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (114): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (115): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (116): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (117): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (118): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (119): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (120): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (121): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (122): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (123): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (124): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (125): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (126): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (127): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (128): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (129): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (130): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (131): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (132): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (133): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (134): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (135): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (136): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (137): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (138): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (139): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (140): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (141): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (142): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (143): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (144): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (145): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (146): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (147): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (148): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (149): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (150): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (151): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (152): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (153): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (154): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (155): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (156): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (157): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (158): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (159): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (160): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (161): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (162): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (163): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (164): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (165): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (166): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (167): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (168): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (169): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (170): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (171): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (172): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (173): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (174): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (175): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (176): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (177): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (178): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (179): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (180): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (181): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (182): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (183): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (184): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (185): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (186): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (187): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (188): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (189): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (190): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (191): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (192): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (193): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (194): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (195): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (196): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (197): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (198): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (199): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (200): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (201): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (202): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (203): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (204): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (205): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (206): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (207): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (208): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (209): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (210): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (211): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (212): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (213): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (214): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (215): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (216): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (217): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (218): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (219): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (220): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (221): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (222): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (223): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (224): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (225): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (226): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (227): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (228): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (229): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (230): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (231): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (232): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (233): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (234): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (235): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (236): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (237): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (238): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (239): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (240): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (241): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (242): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (243): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (244): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (245): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (246): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (247): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (248): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (249): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (250): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (251): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (252): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (253): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (254): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (255): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (256): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (257): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (258): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (259): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (260): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (261): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (262): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (263): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (264): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (265): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (266): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (267): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (268): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (269): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (270): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (271): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (272): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (273): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (274): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (275): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (276): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (277): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (278): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (279): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (280): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (281): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (282): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (283): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (284): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (285): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (286): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (287): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (288): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (289): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (290): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (291): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (292): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (293): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (294): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (295): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (296): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (297): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (298): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (299): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (300): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (301): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (302): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (303): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (304): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (305): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (306): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (307): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (308): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (309): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (310): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (311): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (312): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (313): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (314): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (315): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (316): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (317): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (318): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (319): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (320): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (321): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (322): Parameter containing: [torch.float32 of size 768x256x1 (cuda:0)]\n",
            "      (323): Parameter containing: [torch.float32 of size 768 (cuda:0)]\n",
            "      (324): Parameter containing: [torch.float32 of size 256x256x1 (cuda:0)]\n",
            "      (325): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (326): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (327): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (328): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (329): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (330): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (331): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (332): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (333): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (334): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (335): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (336): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (337): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (338): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (339): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (340): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (341): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (342): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (343): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (344): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (345): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (346): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (347): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (348): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (349): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (350): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (351): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (352): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (353): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (354): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (355): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (356): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (357): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (358): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (359): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (360): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (361): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (362): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (363): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (364): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (365): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (366): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (367): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (368): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (369): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (370): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (371): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (372): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (373): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (374): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (375): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (376): Parameter containing: [torch.float32 of size 256x512x3x3 (cuda:0)]\n",
            "      (377): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (378): Parameter containing: [torch.float32 of size 512x512 (cuda:0)]\n",
            "      (379): Parameter containing: [torch.float32 of size 512 (cuda:0)]\n",
            "      (380): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (381): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (382): Parameter containing: [torch.float32 of size 256x256x3x3 (cuda:0)]\n",
            "      (383): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (384): Parameter containing: [torch.float32 of size 256x512x1x1 (cuda:0)]\n",
            "      (385): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (386): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (387): Parameter containing: [torch.float32 of size 256 (cuda:0)]\n",
            "      (388): Parameter containing: [torch.float32 of size 3x256x3x3 (cuda:0)]\n",
            "      (389): Parameter containing: [torch.float32 of size 3 (cuda:0)]\n",
            "  )\n",
            ")\n",
            "2025-04-17 08:53:15 INFO     Learning rate: 1.00e-04\n",
            "2025-04-17 08:53:15 INFO     Accumulate grad iterations: 1\n",
            "2025-04-17 08:53:15 INFO     Effective batch size: 64\n",
            "2025-04-17 08:53:15 INFO     Optimizer: AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: [0.9, 0.95]\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    initial_lr: 0.0001\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.01\n",
            ")\n",
            "2025-04-17 08:53:15 INFO     Learning-Rate Schedule: <torch.optim.lr_scheduler.ConstantLR object at 0x7bc461a04190>\n",
            "/content/flow_matching/examples/image/training/grad_scaler.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self._scaler = torch.cuda.amp.GradScaler()\n",
            "2025-04-17 08:53:15 INFO     Start from 0 to 3000 epochs\n",
            "/content/flow_matching/examples/image/training/train_loop.py:100: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "2025-04-17 08:53:20 INFO     Epoch 0 [0/781]: loss = 1.2690505981445312, lr = 0.0001\n",
            "2025-04-17 08:53:53 INFO     Epoch 0 [50/781]: loss = 0.39588260650634766, lr = 0.0001\n",
            "2025-04-17 08:54:26 INFO     Epoch 0 [100/781]: loss = 0.3167325258255005, lr = 0.0001\n",
            "2025-04-17 08:55:00 INFO     Epoch 0 [150/781]: loss = 0.2574637532234192, lr = 0.0001\n",
            "2025-04-17 08:55:34 INFO     Epoch 0 [200/781]: loss = 0.21366429328918457, lr = 0.0001\n",
            "2025-04-17 08:56:08 INFO     Epoch 0 [250/781]: loss = 0.2729591727256775, lr = 0.0001\n",
            "2025-04-17 08:56:42 INFO     Epoch 0 [300/781]: loss = 0.2141873836517334, lr = 0.0001\n",
            "2025-04-17 08:57:17 INFO     Epoch 0 [350/781]: loss = 0.22606389224529266, lr = 0.0001\n",
            "2025-04-17 08:57:51 INFO     Epoch 0 [400/781]: loss = 0.2152235209941864, lr = 0.0001\n",
            "2025-04-17 08:58:25 INFO     Epoch 0 [450/781]: loss = 0.22886864840984344, lr = 0.0001\n",
            "2025-04-17 08:58:59 INFO     Epoch 0 [500/781]: loss = 0.23081204295158386, lr = 0.0001\n",
            "2025-04-17 08:59:33 INFO     Epoch 0 [550/781]: loss = 0.2134130895137787, lr = 0.0001\n",
            "2025-04-17 09:00:07 INFO     Epoch 0 [600/781]: loss = 0.20946133136749268, lr = 0.0001\n",
            "2025-04-17 09:00:42 INFO     Epoch 0 [650/781]: loss = 0.2337268441915512, lr = 0.0001\n",
            "2025-04-17 09:01:16 INFO     Epoch 0 [700/781]: loss = 0.22273653745651245, lr = 0.0001\n",
            "2025-04-17 09:01:50 INFO     Epoch 0 [750/781]: loss = 0.2008974850177765, lr = 0.0001\n",
            "2025-04-17 09:02:12 INFO     Epoch 1 [0/781]: loss = 0.19051897525787354, lr = 0.0001\n",
            "2025-04-17 09:02:46 INFO     Epoch 1 [50/781]: loss = 0.21678398549556732, lr = 0.0001\n",
            "2025-04-17 09:03:20 INFO     Epoch 1 [100/781]: loss = 0.20141810178756714, lr = 0.0001\n",
            "2025-04-17 09:03:55 INFO     Epoch 1 [150/781]: loss = 0.20764145255088806, lr = 0.0001\n",
            "2025-04-17 09:04:29 INFO     Epoch 1 [200/781]: loss = 0.18706795573234558, lr = 0.0001\n",
            "2025-04-17 09:05:03 INFO     Epoch 1 [250/781]: loss = 0.23258349299430847, lr = 0.0001\n",
            "2025-04-17 09:05:37 INFO     Epoch 1 [300/781]: loss = 0.22095182538032532, lr = 0.0001\n",
            "2025-04-17 09:06:11 INFO     Epoch 1 [350/781]: loss = 0.20588165521621704, lr = 0.0001\n",
            "2025-04-17 09:06:45 INFO     Epoch 1 [400/781]: loss = 0.18197381496429443, lr = 0.0001\n",
            "2025-04-17 09:07:19 INFO     Epoch 1 [450/781]: loss = 0.19729745388031006, lr = 0.0001\n",
            "2025-04-17 09:07:53 INFO     Epoch 1 [500/781]: loss = 0.18707603216171265, lr = 0.0001\n",
            "2025-04-17 09:08:28 INFO     Epoch 1 [550/781]: loss = 0.2105555534362793, lr = 0.0001\n",
            "2025-04-17 09:09:02 INFO     Epoch 1 [600/781]: loss = 0.1953573077917099, lr = 0.0001\n",
            "2025-04-17 09:09:36 INFO     Epoch 1 [650/781]: loss = 0.18791460990905762, lr = 0.0001\n",
            "2025-04-17 09:10:10 INFO     Epoch 1 [700/781]: loss = 0.20253634452819824, lr = 0.0001\n",
            "2025-04-17 09:10:44 INFO     Epoch 1 [750/781]: loss = 0.23993274569511414, lr = 0.0001\n",
            "2025-04-17 09:11:07 INFO     Epoch 2 [0/781]: loss = 0.1836549937725067, lr = 0.0001\n",
            "2025-04-17 09:11:41 INFO     Epoch 2 [50/781]: loss = 0.19532375037670135, lr = 0.0001\n",
            "2025-04-17 09:12:15 INFO     Epoch 2 [100/781]: loss = 0.18377122282981873, lr = 0.0001\n",
            "2025-04-17 09:12:50 INFO     Epoch 2 [150/781]: loss = 0.16717159748077393, lr = 0.0001\n",
            "2025-04-17 09:13:24 INFO     Epoch 2 [200/781]: loss = 0.20628076791763306, lr = 0.0001\n",
            "2025-04-17 09:13:58 INFO     Epoch 2 [250/781]: loss = 0.19085656106472015, lr = 0.0001\n",
            "2025-04-17 09:14:32 INFO     Epoch 2 [300/781]: loss = 0.17578762769699097, lr = 0.0001\n",
            "2025-04-17 09:15:06 INFO     Epoch 2 [350/781]: loss = 0.2072685956954956, lr = 0.0001\n",
            "2025-04-17 09:15:40 INFO     Epoch 2 [400/781]: loss = 0.19337467849254608, lr = 0.0001\n",
            "2025-04-17 09:16:14 INFO     Epoch 2 [450/781]: loss = 0.21467474102973938, lr = 0.0001\n",
            "2025-04-17 09:16:48 INFO     Epoch 2 [500/781]: loss = 0.20417504012584686, lr = 0.0001\n",
            "2025-04-17 09:17:22 INFO     Epoch 2 [550/781]: loss = 0.20916643738746643, lr = 0.0001\n",
            "2025-04-17 09:17:57 INFO     Epoch 2 [600/781]: loss = 0.19796261191368103, lr = 0.0001\n",
            "2025-04-17 09:18:31 INFO     Epoch 2 [650/781]: loss = 0.22070658206939697, lr = 0.0001\n",
            "2025-04-17 09:19:05 INFO     Epoch 2 [700/781]: loss = 0.194630965590477, lr = 0.0001\n",
            "2025-04-17 09:19:39 INFO     Epoch 2 [750/781]: loss = 0.2237108200788498, lr = 0.0001\n",
            "2025-04-17 09:20:01 INFO     Epoch 3 [0/781]: loss = 0.21703355014324188, lr = 0.0001\n",
            "2025-04-17 09:20:35 INFO     Epoch 3 [50/781]: loss = 0.20931218564510345, lr = 0.0001\n",
            "2025-04-17 09:21:09 INFO     Epoch 3 [100/781]: loss = 0.1962609738111496, lr = 0.0001\n",
            "2025-04-17 09:21:43 INFO     Epoch 3 [150/781]: loss = 0.18569374084472656, lr = 0.0001\n",
            "2025-04-17 09:22:17 INFO     Epoch 3 [200/781]: loss = 0.19049876928329468, lr = 0.0001\n",
            "2025-04-17 09:22:51 INFO     Epoch 3 [250/781]: loss = 0.18748316168785095, lr = 0.0001\n",
            "2025-04-17 09:23:25 INFO     Epoch 3 [300/781]: loss = 0.19134342670440674, lr = 0.0001\n",
            "2025-04-17 09:23:59 INFO     Epoch 3 [350/781]: loss = 0.18596872687339783, lr = 0.0001\n",
            "2025-04-17 09:24:34 INFO     Epoch 3 [400/781]: loss = 0.18249867856502533, lr = 0.0001\n",
            "2025-04-17 09:25:08 INFO     Epoch 3 [450/781]: loss = 0.20058941841125488, lr = 0.0001\n",
            "2025-04-17 09:25:42 INFO     Epoch 3 [500/781]: loss = 0.2027120292186737, lr = 0.0001\n",
            "2025-04-17 09:26:16 INFO     Epoch 3 [550/781]: loss = 0.20231735706329346, lr = 0.0001\n",
            "2025-04-17 09:26:50 INFO     Epoch 3 [600/781]: loss = 0.20439958572387695, lr = 0.0001\n",
            "2025-04-17 09:27:24 INFO     Epoch 3 [650/781]: loss = 0.18566159904003143, lr = 0.0001\n",
            "2025-04-17 09:27:58 INFO     Epoch 3 [700/781]: loss = 0.2061748504638672, lr = 0.0001\n",
            "2025-04-17 09:28:32 INFO     Epoch 3 [750/781]: loss = 0.20343220233917236, lr = 0.0001\n",
            "2025-04-17 09:28:55 INFO     Epoch 4 [0/781]: loss = 0.19190876185894012, lr = 0.0001\n",
            "2025-04-17 09:29:29 INFO     Epoch 4 [50/781]: loss = 0.1891046166419983, lr = 0.0001\n",
            "2025-04-17 09:30:03 INFO     Epoch 4 [100/781]: loss = 0.1839616298675537, lr = 0.0001\n",
            "2025-04-17 09:30:37 INFO     Epoch 4 [150/781]: loss = 0.18303261697292328, lr = 0.0001\n",
            "2025-04-17 09:31:11 INFO     Epoch 4 [200/781]: loss = 0.18782281875610352, lr = 0.0001\n",
            "2025-04-17 09:31:45 INFO     Epoch 4 [250/781]: loss = 0.20793776214122772, lr = 0.0001\n",
            "2025-04-17 09:32:19 INFO     Epoch 4 [300/781]: loss = 0.175978422164917, lr = 0.0001\n",
            "2025-04-17 09:32:54 INFO     Epoch 4 [350/781]: loss = 0.1807139366865158, lr = 0.0001\n",
            "2025-04-17 09:33:28 INFO     Epoch 4 [400/781]: loss = 0.19041812419891357, lr = 0.0001\n",
            "2025-04-17 09:34:02 INFO     Epoch 4 [450/781]: loss = 0.16084079444408417, lr = 0.0001\n",
            "2025-04-17 09:34:36 INFO     Epoch 4 [500/781]: loss = 0.20923976600170135, lr = 0.0001\n",
            "2025-04-17 09:35:10 INFO     Epoch 4 [550/781]: loss = 0.19188305735588074, lr = 0.0001\n",
            "2025-04-17 09:35:44 INFO     Epoch 4 [600/781]: loss = 0.18772852420806885, lr = 0.0001\n",
            "2025-04-17 09:36:18 INFO     Epoch 4 [650/781]: loss = 0.19194619357585907, lr = 0.0001\n",
            "2025-04-17 09:36:52 INFO     Epoch 4 [700/781]: loss = 0.18795692920684814, lr = 0.0001\n",
            "2025-04-17 09:37:27 INFO     Epoch 4 [750/781]: loss = 0.191559836268425, lr = 0.0001\n",
            "2025-04-17 09:37:49 INFO     Epoch 5 [0/781]: loss = 0.19172146916389465, lr = 0.0001\n",
            "2025-04-17 09:38:23 INFO     Epoch 5 [50/781]: loss = 0.1819886416196823, lr = 0.0001\n",
            "2025-04-17 09:38:57 INFO     Epoch 5 [100/781]: loss = 0.18365070223808289, lr = 0.0001\n",
            "2025-04-17 09:39:31 INFO     Epoch 5 [150/781]: loss = 0.18155574798583984, lr = 0.0001\n",
            "2025-04-17 09:40:05 INFO     Epoch 5 [200/781]: loss = 0.20613281428813934, lr = 0.0001\n",
            "2025-04-17 09:40:40 INFO     Epoch 5 [250/781]: loss = 0.19818627834320068, lr = 0.0001\n",
            "2025-04-17 09:41:14 INFO     Epoch 5 [300/781]: loss = 0.1705714762210846, lr = 0.0001\n",
            "2025-04-17 09:41:48 INFO     Epoch 5 [350/781]: loss = 0.1712859869003296, lr = 0.0001\n",
            "2025-04-17 09:42:22 INFO     Epoch 5 [400/781]: loss = 0.18512040376663208, lr = 0.0001\n",
            "2025-04-17 09:42:56 INFO     Epoch 5 [450/781]: loss = 0.17423617839813232, lr = 0.0001\n",
            "2025-04-17 09:43:30 INFO     Epoch 5 [500/781]: loss = 0.20096322894096375, lr = 0.0001\n",
            "2025-04-17 09:44:05 INFO     Epoch 5 [550/781]: loss = 0.2231142818927765, lr = 0.0001\n",
            "2025-04-17 09:44:39 INFO     Epoch 5 [600/781]: loss = 0.18500111997127533, lr = 0.0001\n",
            "2025-04-17 09:45:13 INFO     Epoch 5 [650/781]: loss = 0.19109341502189636, lr = 0.0001\n",
            "2025-04-17 09:45:47 INFO     Epoch 5 [700/781]: loss = 0.206669420003891, lr = 0.0001\n",
            "2025-04-17 09:46:21 INFO     Epoch 5 [750/781]: loss = 0.17921707034111023, lr = 0.0001\n",
            "2025-04-17 09:46:43 INFO     Epoch 6 [0/781]: loss = 0.19302301108837128, lr = 0.0001\n",
            "2025-04-17 09:47:18 INFO     Epoch 6 [50/781]: loss = 0.18664507567882538, lr = 0.0001\n",
            "2025-04-17 09:47:52 INFO     Epoch 6 [100/781]: loss = 0.19506633281707764, lr = 0.0001\n",
            "2025-04-17 09:48:26 INFO     Epoch 6 [150/781]: loss = 0.18421494960784912, lr = 0.0001\n",
            "2025-04-17 09:49:00 INFO     Epoch 6 [200/781]: loss = 0.18035152554512024, lr = 0.0001\n",
            "2025-04-17 09:49:34 INFO     Epoch 6 [250/781]: loss = 0.19770073890686035, lr = 0.0001\n",
            "2025-04-17 09:50:08 INFO     Epoch 6 [300/781]: loss = 0.1943836808204651, lr = 0.0001\n",
            "2025-04-17 09:50:42 INFO     Epoch 6 [350/781]: loss = 0.1712065190076828, lr = 0.0001\n",
            "2025-04-17 09:51:16 INFO     Epoch 6 [400/781]: loss = 0.1639152467250824, lr = 0.0001\n",
            "2025-04-17 09:51:50 INFO     Epoch 6 [450/781]: loss = 0.17477063834667206, lr = 0.0001\n",
            "2025-04-17 09:52:24 INFO     Epoch 6 [500/781]: loss = 0.19122302532196045, lr = 0.0001\n",
            "2025-04-17 09:52:58 INFO     Epoch 6 [550/781]: loss = 0.1961708664894104, lr = 0.0001\n",
            "2025-04-17 09:53:32 INFO     Epoch 6 [600/781]: loss = 0.1814488172531128, lr = 0.0001\n",
            "2025-04-17 09:54:06 INFO     Epoch 6 [650/781]: loss = 0.18622741103172302, lr = 0.0001\n",
            "2025-04-17 09:54:40 INFO     Epoch 6 [700/781]: loss = 0.19513118267059326, lr = 0.0001\n",
            "2025-04-17 09:55:14 INFO     Epoch 6 [750/781]: loss = 0.19307929277420044, lr = 0.0001\n",
            "2025-04-17 09:55:36 INFO     Epoch 7 [0/781]: loss = 0.17231541872024536, lr = 0.0001\n",
            "2025-04-17 09:56:10 INFO     Epoch 7 [50/781]: loss = 0.18340007960796356, lr = 0.0001\n",
            "2025-04-17 09:56:44 INFO     Epoch 7 [100/781]: loss = 0.20542728900909424, lr = 0.0001\n",
            "2025-04-17 09:57:18 INFO     Epoch 7 [150/781]: loss = 0.17269472777843475, lr = 0.0001\n",
            "2025-04-17 09:57:52 INFO     Epoch 7 [200/781]: loss = 0.21998058259487152, lr = 0.0001\n",
            "2025-04-17 09:58:26 INFO     Epoch 7 [250/781]: loss = 0.19040118157863617, lr = 0.0001\n",
            "2025-04-17 09:59:00 INFO     Epoch 7 [300/781]: loss = 0.1739916056394577, lr = 0.0001\n",
            "2025-04-17 09:59:34 INFO     Epoch 7 [350/781]: loss = 0.19322258234024048, lr = 0.0001\n",
            "2025-04-17 10:00:09 INFO     Epoch 7 [400/781]: loss = 0.18947991728782654, lr = 0.0001\n",
            "2025-04-17 10:00:43 INFO     Epoch 7 [450/781]: loss = 0.16746798157691956, lr = 0.0001\n",
            "2025-04-17 10:01:17 INFO     Epoch 7 [500/781]: loss = 0.17832587659358978, lr = 0.0001\n",
            "2025-04-17 10:01:51 INFO     Epoch 7 [550/781]: loss = 0.18300525844097137, lr = 0.0001\n",
            "2025-04-17 10:02:25 INFO     Epoch 7 [600/781]: loss = 0.18154005706310272, lr = 0.0001\n",
            "2025-04-17 10:02:59 INFO     Epoch 7 [650/781]: loss = 0.20559941232204437, lr = 0.0001\n",
            "2025-04-17 10:03:33 INFO     Epoch 7 [700/781]: loss = 0.1907215118408203, lr = 0.0001\n",
            "2025-04-17 10:04:07 INFO     Epoch 7 [750/781]: loss = 0.1854335069656372, lr = 0.0001\n",
            "2025-04-17 10:04:29 INFO     Epoch 8 [0/781]: loss = 0.20283488929271698, lr = 0.0001\n",
            "2025-04-17 10:05:03 INFO     Epoch 8 [50/781]: loss = 0.18546846508979797, lr = 0.0001\n",
            "2025-04-17 10:05:37 INFO     Epoch 8 [100/781]: loss = 0.1961940973997116, lr = 0.0001\n",
            "2025-04-17 10:06:11 INFO     Epoch 8 [150/781]: loss = 0.18177299201488495, lr = 0.0001\n",
            "2025-04-17 10:06:44 INFO     Epoch 8 [200/781]: loss = 0.17395305633544922, lr = 0.0001\n",
            "2025-04-17 10:07:18 INFO     Epoch 8 [250/781]: loss = 0.19678586721420288, lr = 0.0001\n",
            "2025-04-17 10:07:52 INFO     Epoch 8 [300/781]: loss = 0.2043527066707611, lr = 0.0001\n",
            "2025-04-17 10:08:26 INFO     Epoch 8 [350/781]: loss = 0.17867235839366913, lr = 0.0001\n",
            "2025-04-17 10:09:00 INFO     Epoch 8 [400/781]: loss = 0.18099266290664673, lr = 0.0001\n",
            "2025-04-17 10:09:34 INFO     Epoch 8 [450/781]: loss = 0.15543508529663086, lr = 0.0001\n",
            "2025-04-17 10:10:08 INFO     Epoch 8 [500/781]: loss = 0.19663546979427338, lr = 0.0001\n",
            "2025-04-17 10:10:42 INFO     Epoch 8 [550/781]: loss = 0.1810828149318695, lr = 0.0001\n",
            "2025-04-17 10:11:15 INFO     Epoch 8 [600/781]: loss = 0.16483554244041443, lr = 0.0001\n",
            "2025-04-17 10:11:49 INFO     Epoch 8 [650/781]: loss = 0.20616072416305542, lr = 0.0001\n",
            "2025-04-17 10:12:23 INFO     Epoch 8 [700/781]: loss = 0.18997815251350403, lr = 0.0001\n",
            "2025-04-17 10:12:57 INFO     Epoch 8 [750/781]: loss = 0.1936555802822113, lr = 0.0001\n",
            "2025-04-17 10:13:19 INFO     Epoch 9 [0/781]: loss = 0.1767980307340622, lr = 0.0001\n",
            "2025-04-17 10:13:53 INFO     Epoch 9 [50/781]: loss = 0.1783907264471054, lr = 0.0001\n",
            "2025-04-17 10:14:27 INFO     Epoch 9 [100/781]: loss = 0.20202267169952393, lr = 0.0001\n",
            "2025-04-17 10:15:01 INFO     Epoch 9 [150/781]: loss = 0.18218904733657837, lr = 0.0001\n",
            "2025-04-17 10:15:35 INFO     Epoch 9 [200/781]: loss = 0.16778044402599335, lr = 0.0001\n",
            "2025-04-17 10:16:09 INFO     Epoch 9 [250/781]: loss = 0.19565360248088837, lr = 0.0001\n",
            "2025-04-17 10:16:43 INFO     Epoch 9 [300/781]: loss = 0.1887447088956833, lr = 0.0001\n",
            "2025-04-17 10:17:16 INFO     Epoch 9 [350/781]: loss = 0.1834096908569336, lr = 0.0001\n",
            "2025-04-17 10:17:50 INFO     Epoch 9 [400/781]: loss = 0.19651281833648682, lr = 0.0001\n",
            "2025-04-17 10:18:24 INFO     Epoch 9 [450/781]: loss = 0.16701172292232513, lr = 0.0001\n",
            "2025-04-17 10:18:58 INFO     Epoch 9 [500/781]: loss = 0.1977374255657196, lr = 0.0001\n",
            "2025-04-17 10:19:32 INFO     Epoch 9 [550/781]: loss = 0.17805258929729462, lr = 0.0001\n",
            "2025-04-17 10:20:06 INFO     Epoch 9 [600/781]: loss = 0.17720097303390503, lr = 0.0001\n",
            "2025-04-17 10:20:40 INFO     Epoch 9 [650/781]: loss = 0.19044332206249237, lr = 0.0001\n",
            "2025-04-17 10:21:14 INFO     Epoch 9 [700/781]: loss = 0.19674187898635864, lr = 0.0001\n",
            "2025-04-17 10:21:48 INFO     Epoch 9 [750/781]: loss = 0.19547538459300995, lr = 0.0001\n",
            "2025-04-17 10:22:10 INFO     Epoch 10 [0/781]: loss = 0.17076699435710907, lr = 0.0001\n",
            "2025-04-17 10:22:44 INFO     Epoch 10 [50/781]: loss = 0.1862916201353073, lr = 0.0001\n",
            "2025-04-17 10:23:18 INFO     Epoch 10 [100/781]: loss = 0.18606525659561157, lr = 0.0001\n",
            "2025-04-17 10:23:52 INFO     Epoch 10 [150/781]: loss = 0.18241676688194275, lr = 0.0001\n",
            "2025-04-17 10:24:26 INFO     Epoch 10 [200/781]: loss = 0.20786850154399872, lr = 0.0001\n",
            "2025-04-17 10:25:01 INFO     Epoch 10 [250/781]: loss = 0.19596070051193237, lr = 0.0001\n",
            "2025-04-17 10:25:35 INFO     Epoch 10 [300/781]: loss = 0.17397837340831757, lr = 0.0001\n",
            "2025-04-17 10:26:09 INFO     Epoch 10 [350/781]: loss = 0.18165133893489838, lr = 0.0001\n",
            "2025-04-17 10:26:43 INFO     Epoch 10 [400/781]: loss = 0.20199429988861084, lr = 0.0001\n",
            "2025-04-17 10:27:17 INFO     Epoch 10 [450/781]: loss = 0.18205194175243378, lr = 0.0001\n",
            "2025-04-17 10:27:51 INFO     Epoch 10 [500/781]: loss = 0.20143213868141174, lr = 0.0001\n",
            "2025-04-17 10:28:26 INFO     Epoch 10 [550/781]: loss = 0.21959921717643738, lr = 0.0001\n",
            "2025-04-17 10:29:00 INFO     Epoch 10 [600/781]: loss = 0.189347505569458, lr = 0.0001\n",
            "2025-04-17 10:29:34 INFO     Epoch 10 [650/781]: loss = 0.19349059462547302, lr = 0.0001\n",
            "2025-04-17 10:30:08 INFO     Epoch 10 [700/781]: loss = 0.1924455612897873, lr = 0.0001\n",
            "2025-04-17 10:30:42 INFO     Epoch 10 [750/781]: loss = 0.18420687317848206, lr = 0.0001\n",
            "2025-04-17 10:31:04 INFO     Epoch 11 [0/781]: loss = 0.1970309466123581, lr = 0.0001\n",
            "2025-04-17 10:31:39 INFO     Epoch 11 [50/781]: loss = 0.19105744361877441, lr = 0.0001\n",
            "2025-04-17 10:32:13 INFO     Epoch 11 [100/781]: loss = 0.1946110725402832, lr = 0.0001\n",
            "2025-04-17 10:32:47 INFO     Epoch 11 [150/781]: loss = 0.20001018047332764, lr = 0.0001\n",
            "2025-04-17 10:33:21 INFO     Epoch 11 [200/781]: loss = 0.18796232342720032, lr = 0.0001\n",
            "2025-04-17 10:33:55 INFO     Epoch 11 [250/781]: loss = 0.20737320184707642, lr = 0.0001\n",
            "2025-04-17 10:34:29 INFO     Epoch 11 [300/781]: loss = 0.17302647233009338, lr = 0.0001\n",
            "2025-04-17 10:35:04 INFO     Epoch 11 [350/781]: loss = 0.20097756385803223, lr = 0.0001\n",
            "2025-04-17 10:35:38 INFO     Epoch 11 [400/781]: loss = 0.18393635749816895, lr = 0.0001\n",
            "2025-04-17 10:36:12 INFO     Epoch 11 [450/781]: loss = 0.1680130958557129, lr = 0.0001\n",
            "2025-04-17 10:36:46 INFO     Epoch 11 [500/781]: loss = 0.1749754548072815, lr = 0.0001\n",
            "2025-04-17 10:37:21 INFO     Epoch 11 [550/781]: loss = 0.2028127759695053, lr = 0.0001\n",
            "2025-04-17 10:37:55 INFO     Epoch 11 [600/781]: loss = 0.18078309297561646, lr = 0.0001\n",
            "2025-04-17 10:38:29 INFO     Epoch 11 [650/781]: loss = 0.19002699851989746, lr = 0.0001\n",
            "2025-04-17 10:39:03 INFO     Epoch 11 [700/781]: loss = 0.18963387608528137, lr = 0.0001\n",
            "2025-04-17 10:39:37 INFO     Epoch 11 [750/781]: loss = 0.19054758548736572, lr = 0.0001\n",
            "2025-04-17 10:39:59 INFO     Epoch 12 [0/781]: loss = 0.18299934267997742, lr = 0.0001\n",
            "2025-04-17 10:40:34 INFO     Epoch 12 [50/781]: loss = 0.19226083159446716, lr = 0.0001\n",
            "2025-04-17 10:41:08 INFO     Epoch 12 [100/781]: loss = 0.18165633082389832, lr = 0.0001\n",
            "2025-04-17 10:41:42 INFO     Epoch 12 [150/781]: loss = 0.19421568512916565, lr = 0.0001\n",
            "2025-04-17 10:42:16 INFO     Epoch 12 [200/781]: loss = 0.1772063672542572, lr = 0.0001\n",
            "2025-04-17 10:42:51 INFO     Epoch 12 [250/781]: loss = 0.17164520919322968, lr = 0.0001\n",
            "2025-04-17 10:43:25 INFO     Epoch 12 [300/781]: loss = 0.17352989315986633, lr = 0.0001\n",
            "2025-04-17 10:43:59 INFO     Epoch 12 [350/781]: loss = 0.16142290830612183, lr = 0.0001\n",
            "2025-04-17 10:44:33 INFO     Epoch 12 [400/781]: loss = 0.1648297756910324, lr = 0.0001\n",
            "2025-04-17 10:45:07 INFO     Epoch 12 [450/781]: loss = 0.17734408378601074, lr = 0.0001\n",
            "2025-04-17 10:45:41 INFO     Epoch 12 [500/781]: loss = 0.17843878269195557, lr = 0.0001\n",
            "2025-04-17 10:46:16 INFO     Epoch 12 [550/781]: loss = 0.21346363425254822, lr = 0.0001\n",
            "2025-04-17 10:46:50 INFO     Epoch 12 [600/781]: loss = 0.16787652671337128, lr = 0.0001\n",
            "2025-04-17 10:47:24 INFO     Epoch 12 [650/781]: loss = 0.20377986133098602, lr = 0.0001\n",
            "2025-04-17 10:47:58 INFO     Epoch 12 [700/781]: loss = 0.19246743619441986, lr = 0.0001\n",
            "2025-04-17 10:48:33 INFO     Epoch 12 [750/781]: loss = 0.18310964107513428, lr = 0.0001\n",
            "2025-04-17 10:48:55 INFO     Epoch 13 [0/781]: loss = 0.18727481365203857, lr = 0.0001\n",
            "2025-04-17 10:49:29 INFO     Epoch 13 [50/781]: loss = 0.20609116554260254, lr = 0.0001\n",
            "2025-04-17 10:50:03 INFO     Epoch 13 [100/781]: loss = 0.15930838882923126, lr = 0.0001\n",
            "2025-04-17 10:50:38 INFO     Epoch 13 [150/781]: loss = 0.1911160945892334, lr = 0.0001\n",
            "2025-04-17 10:51:12 INFO     Epoch 13 [200/781]: loss = 0.1832084357738495, lr = 0.0001\n",
            "2025-04-17 10:51:46 INFO     Epoch 13 [250/781]: loss = 0.2035561203956604, lr = 0.0001\n",
            "2025-04-17 10:52:20 INFO     Epoch 13 [300/781]: loss = 0.17981939017772675, lr = 0.0001\n",
            "2025-04-17 10:52:54 INFO     Epoch 13 [350/781]: loss = 0.18905887007713318, lr = 0.0001\n",
            "2025-04-17 10:53:29 INFO     Epoch 13 [400/781]: loss = 0.15683454275131226, lr = 0.0001\n",
            "2025-04-17 10:54:03 INFO     Epoch 13 [450/781]: loss = 0.17625534534454346, lr = 0.0001\n",
            "2025-04-17 10:54:37 INFO     Epoch 13 [500/781]: loss = 0.18138353526592255, lr = 0.0001\n",
            "2025-04-17 10:55:11 INFO     Epoch 13 [550/781]: loss = 0.19378070533275604, lr = 0.0001\n",
            "2025-04-17 10:55:45 INFO     Epoch 13 [600/781]: loss = 0.18098410964012146, lr = 0.0001\n",
            "2025-04-17 10:56:20 INFO     Epoch 13 [650/781]: loss = 0.19760063290596008, lr = 0.0001\n",
            "2025-04-17 10:56:54 INFO     Epoch 13 [700/781]: loss = 0.1794654130935669, lr = 0.0001\n",
            "2025-04-17 10:57:28 INFO     Epoch 13 [750/781]: loss = 0.18214258551597595, lr = 0.0001\n",
            "2025-04-17 10:57:50 INFO     Epoch 14 [0/781]: loss = 0.18179833889007568, lr = 0.0001\n",
            "2025-04-17 10:58:24 INFO     Epoch 14 [50/781]: loss = 0.18179862201213837, lr = 0.0001\n",
            "2025-04-17 10:58:59 INFO     Epoch 14 [100/781]: loss = 0.17488645017147064, lr = 0.0001\n",
            "2025-04-17 10:59:33 INFO     Epoch 14 [150/781]: loss = 0.18776550889015198, lr = 0.0001\n",
            "2025-04-17 11:00:07 INFO     Epoch 14 [200/781]: loss = 0.18034110963344574, lr = 0.0001\n",
            "2025-04-17 11:00:41 INFO     Epoch 14 [250/781]: loss = 0.20491795241832733, lr = 0.0001\n",
            "2025-04-17 11:01:15 INFO     Epoch 14 [300/781]: loss = 0.17326991260051727, lr = 0.0001\n",
            "2025-04-17 11:01:49 INFO     Epoch 14 [350/781]: loss = 0.1834104061126709, lr = 0.0001\n",
            "2025-04-17 11:02:24 INFO     Epoch 14 [400/781]: loss = 0.16781489551067352, lr = 0.0001\n",
            "2025-04-17 11:02:58 INFO     Epoch 14 [450/781]: loss = 0.18514135479927063, lr = 0.0001\n",
            "2025-04-17 11:03:32 INFO     Epoch 14 [500/781]: loss = 0.19530169665813446, lr = 0.0001\n",
            "2025-04-17 11:04:06 INFO     Epoch 14 [550/781]: loss = 0.1928226351737976, lr = 0.0001\n",
            "2025-04-17 11:04:40 INFO     Epoch 14 [600/781]: loss = 0.1801549643278122, lr = 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "KW301QW7RqwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir output_cifar10\n"
      ],
      "metadata": {
        "id": "GGufxAzLRsmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install submitit"
      ],
      "metadata": {
        "id": "EC8oAM6hRv7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4350b6a-d7b1-4099-c828-66d81b9315c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: submitit in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from submitit) (3.1.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.11/dist-packages (from submitit) (4.13.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import uuid  # Import the uuid module (although it's already in your submitit_train.py)\n",
        "\n",
        "shared_dir = \"/content/shared_experiments\" # Choose a path within /content/\n",
        "\n",
        "if not Path(shared_dir).is_dir():\n",
        "    os.makedirs(shared_dir, exist_ok=True)\n",
        "\n",
        "def get_shared_folder(shared_dir: str) -> Path:\n",
        "    user = os.getenv(\"USER\", \"default_user\") # Colab might not always have USER set\n",
        "    p = Path(shared_dir) / user / \"experiments\"\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "    return p\n",
        "\n",
        "def get_init_file(shared_dir: str):\n",
        "    shared_folder = get_shared_folder(shared_dir)\n",
        "    init_file = shared_folder / f\"{uuid.uuid4().hex}_init\"\n",
        "    if init_file.exists():\n",
        "        os.remove(str(init_file))\n",
        "    return init_file\n",
        "\n",
        "# You can optionally run these lines to see the paths that will be used\n",
        "job_dir = get_shared_folder(shared_dir) / \"my_job\" # Example job directory\n",
        "print(f\"Job directory: {job_dir}\")\n",
        "init_file = get_init_file(shared_dir)\n",
        "print(f\"Init file: {init_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opZ2B51vax81",
        "outputId": "f8aea8ec-25ed-4eeb-8dc8-8d7c6079d1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job directory: /content/shared_experiments/default_user/experiments/my_job\n",
            "Init file: /content/shared_experiments/default_user/experiments/af6edabdc1e248e18abdf42794a7eaf6_init\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['USER'] = 'thesis_dfki'"
      ],
      "metadata": {
        "id": "H1_GpDqxniqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python submitit_train.py \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=64 \\\n",
        "    --nodes=1 \\\n",
        "    --accum_iter=1 \\\n",
        "    --eval_frequency=100 \\\n",
        "    --epochs=3000 \\\n",
        "    --class_drop_prob=1.0 \\\n",
        "    --cfg_scale=0.0 \\\n",
        "    --compute_fid \\\n",
        "    --ode_method heun2 \\\n",
        "    --ode_options '{\"nfe\": 50}' \\\n",
        "    --use_ema \\\n",
        "    --edm_schedule \\\n",
        "    --skewed_timesteps \\\n",
        "    --output_dir output_cifar10_submitit \\\n",
        "    --shared_dir \"/content/shared_experiments\""
      ],
      "metadata": {
        "id": "oAubohbgUUl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09580062-4dc8-4fce-ca93-c5496cb74831"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-21 18:40:36 INFO     Submitted job 5326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "args = {\n",
        "    \"output_dir\": Path(\"/tmp/some/path\"),\n",
        "    \"other_param\": 42,\n",
        "}\n",
        "\n",
        "with open(\"args.json\", \"w\") as f:\n",
        "    json.dump({k: str(v) if isinstance(v, Path) else v for k, v in args.items()}, f)\n"
      ],
      "metadata": {
        "id": "17jgxnM_qSPG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}